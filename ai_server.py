#!/usr/bin/env python3
"""
Serveur IA pour TradBOT - Gestion des pr√©dictions et analyses de march√©
Version: 2.1.0 - STABILIS√â
Corrections majeures:
- Ajout champ timestamp dans DecisionRequest (fix erreur 422)
- Correction gestion colonne timestamp dans adaptive_predict.py  
- Ajout endpoint /trend principal (fix erreur 404)
- D√©finition variable backend_available (fix NameError)
- Am√©lioration gestion des erreurs et logging
Compatible avec F_INX_robot4.mq5
"""

import os
import json
import time
import asyncio
import logging
import sys
import argparse
import traceback
import contextlib
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, List, Dict, Any, Tuple, Set
from fastapi import FastAPI, HTTPException, Request, Body, status
from starlette.requests import Request as StarletteRequest
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field

import uvicorn
import pandas as pd
import numpy as np
import requests
import joblib
from collections import deque

# Configurer le logger avant les imports d'am√©liorations
logger = logging.getLogger("tradbot_ai")

# Sur Render / Supabase, utiliser /tmp pour les mod√®les (accessible en √©criture)
if os.getenv("RENDER") or os.getenv("RENDER_SERVICE_ID") or os.getenv("SUPABASE_URL"):
    os.environ.setdefault("MODELS_DIR", "/tmp/models")

# ===== SYST√àME D'APPRENTISSAGE AUTOMATIQUE INT√âGR√â =====
# Importer le syst√®me ML int√©gr√©
try:
    from integrated_ml_trainer import ml_trainer
    ML_TRAINER_AVAILABLE = True
    logger.info("ü§ñ Syst√®me d'entra√Ænement continu int√©gr√© charg√©")
except ImportError as e:
    ML_TRAINER_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è Syst√®me d'entra√Ænement continu non disponible: {e}")

# Importer le syst√®me de recommandation ML
try:
    from ml_recommendation_system import MLRecommendationSystem
    ML_RECOMMENDATION_AVAILABLE = True
    logger.info("üéØ Syst√®me de recommandation ML charg√© avec succ√®s")
except ImportError as e:
    ML_RECOMMENDATION_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è Syst√®me de recommandation ML non disponible: {e}")

# Initialiser le syst√®me de recommandation ML
if ML_TRAINER_AVAILABLE and ML_RECOMMENDATION_AVAILABLE:
    ml_recommendation_system = MLRecommendationSystem(ml_trainer)
    logger.info("üöÄ Syst√®me de recommandation ML initialis√©")
else:
    ml_recommendation_system = None
    logger.warning("‚ö†Ô∏è Syst√®me de recommandation ML non initialis√©")

# Importer le syst√®me ML de d√©cision
try:
    from ml_trading_system import ml_enhancer
    ML_AVAILABLE = True
    logger.info("üß† Syst√®me ML charg√© avec succ√®s")
except ImportError as e:
    ML_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è Syst√®me ML non disponible: {e}")

# Fonction pour am√©liorer les d√©cisions avec ML (Random Forest, ml_enhancer, etc.)
def enhance_decision_with_ml(symbol: str, decision: str, confidence: float, market_data: dict = None) -> dict:
    """Am√©liorer une d√©cision avec les mod√®les ML (Random Forest d'abord, puis ml_enhancer)"""
    base = {
        "original_decision": decision,
        "original_confidence": confidence,
        "enhanced_decision": decision,
        "enhanced_confidence": confidence,
        "ml_reason": "no_model",
        "ml_applied": False
    }
    market_data = market_data or {}
    # 1. Random Forest (integrated_ml_trainer) si mod√®le disponible
    if ML_TRAINER_AVAILABLE:
        try:
            pred = ml_trainer.predict(symbol, "M1", market_data)
            if pred:
                base["enhanced_decision"] = pred["action"]
                base["enhanced_confidence"] = pred.get("confidence", confidence)
                base["ml_reason"] = pred.get("model", "random_forest")
                base["ml_applied"] = True
                return base
        except Exception as e:
            logger.debug(f"Predict RF skip: {e}")
    # 2. ml_enhancer (ml_trading_system) si ML_AVAILABLE
    if not ML_AVAILABLE:
        return base
    try:
        return ml_enhancer.enhance_decision(symbol, decision, confidence, market_data)
    except Exception as e:
        logger.error(f"‚ùå Erreur enhancement ML: {e}")
        return {
            "original_decision": decision,
            "original_confidence": confidence,
            "enhanced_decision": decision,
            "enhanced_confidence": confidence,
            "ml_reason": "error",
            "ml_applied": False
        }

# ========== MODE SIMPLIFI√â POUR ROBOCOP v2 ==========
# Activer le mode simplifi√© pour RoboCop v2 (plus stable, moins de d√©pendances)
SIMPLIFIED_MODE = True  # Mettre √† False pour utiliser le mode complet

if SIMPLIFIED_MODE:
    logger.info("üöÄ MODE SIMPLIFI√â ACTIV√â - RoboCop v2 compatible")
    logger.info("   ‚Ä¢ Analyse technique bas√©e sur RSI + EMA")
    logger.info("   ‚Ä¢ Pas de ML complexe - Stabilit√© maximale")
    logger.info("   ‚Ä¢ Endpoints: /decision, /trades/feedback")
else:
    logger.info("üîß MODE COMPLET ACTIV√â - Toutes les fonctionnalit√©s")

# ========== CONFIGURATIONS AM√âLIORATIONS PRIORITAIRES ==========
# Seuils de confiance minimum pour √©viter les signaux trop faibles
MIN_CONFIDENCE_THRESHOLD = 0.55  # 55% minimum (plus r√©aliste)
FORCE_HOLD_THRESHOLD = 0.40      # Force HOLD si confiance < 40% (plus flexible)

# Prompt syst√®me am√©lior√© pour Boom/Crash
BOOM_CRASH_SYSTEM_PROMPT = """
Tu es un trader expert sp√©cialis√© sur les indices synth√©tiques Deriv (Boom & Crash 50/100/300/600/900/1000).

R√àGLES STRICTES POUR BOOM/CRASH:
1. Confiance MINIMUM 68% pour tout signal BUY/SELL. En dessous ‚Üí HOLD obligatoire.
2. SUR BOOM: Privil√©gie BUY quand RSI < 40 + EMA crossover haussier SANS spike r√©cent.
3. SUR CRASH: Privil√©gie SELL quand RSI > 60 + EMA crossover baissier SANS spike r√©cent.
4. JAMAIS de signal si ATR derni√®re bougie > 2.8√óATR moyen ‚Üí risque spike trop √©lev√©.
5. D√©tecte les patterns de spike: bougie > 3√órange moyen + volume √©lev√©.

FORMAT DE R√âPONSE OBLIGATOIRE:
- action: "buy"/"sell"/"hold" 
- confidence: 0.68-1.0 (jamais en dessous de 0.68)
- reason: phrase courte et pr√©cise
- metadata: RSI, EMA, ATR ratio, spike_risk
"""

# Cache court pour √©viter les analyses r√©p√©t√©es
decision_cache = {}
cache_timestamps = {}
CACHE_DURATION = 30  # 30 secondes

# Importer les fonctions am√©lior√©es
try:
    from ai_server_improvements import (
        calculate_advanced_confidence,
        predict_prices_advanced,
        validate_multi_timeframe,
        adapt_prediction_for_symbol,
        detect_support_resistance_levels,
        is_boom_crash_symbol,
        is_volatility_symbol
    )
    IMPROVEMENTS_AVAILABLE = True
    logger.info("‚úÖ Module ai_server_improvements charg√© avec succ√®s")
except ImportError:
    IMPROVEMENTS_AVAILABLE = False
    logger.warning(
        "‚ö†Ô∏è Module ai_server_improvements non disponible - "
        "utilisation des fonctions de base"
    )

# PostgreSQL async support for feedback loop
try:
    import asyncpg
    ASYNCPG_AVAILABLE = True
except ImportError:
    ASYNCPG_AVAILABLE = False
    logger_placeholder = logging.getLogger("tradbot_ai")
    logger_placeholder.warning("asyncpg non disponible - installer avec: pip install asyncpg")

# Machine Learning imports (Phase 2) - seront initialis√©s apr√®s logger
ML_AVAILABLE = False

# Import yfinance pour les donn√©es de march√© (compatible cloud)
try:
    import yfinance as yf
    YFINANCE_AVAILABLE = True
    logger.info("‚úÖ yfinance disponible pour les donn√©es de march√©")
except ImportError:
    YFINANCE_AVAILABLE = False
    logger.warning("‚ö†Ô∏è yfinance non disponible")

# Variables globales pour le suivi en mode simplifi√©
decision_count = 0
feedback_count = 0

# ========== FONCTIONS UTILITAIRES AM√âLIORATIONS ==========
def apply_confidence_thresholds(action: str, confidence: float, reason: str) -> tuple:
    """
    Applique les seuils de confiance minimum pour √©viter les signaux trop faibles.
    Force HOLD si confiance < 60%, applique plancher 68% pour les signaux.
    """
    # Forcer un plancher de confiance √† 68%
    confidence = max(confidence, 0.68)
    
    # Forcer HOLD si confiance encore trop faible apr√®s plancher
    if confidence < 0.68:
        return "hold", 0.68, f"{reason} (confiance trop faible ‚Üí hold forc√©)"
    
    # Si action non-hold mais confiance < 68%, forcer HOLD
    if action != "hold" and confidence < 0.68:
        return "hold", 0.68, f"{reason} (confiance < 68% ‚Üí hold)"
    
    # Forcer un minimum de 68% pour les signaux buy/sell
    if action != "hold" and confidence < 0.68:
        confidence = 0.68
        reason += f" (confiance forc√©e √† 68%)"
    
    return action, confidence, reason

def get_cached_decision(symbol: str) -> Optional[Dict]:
    """V√©rifie le cache pour une d√©cision r√©cente."""
    current_time = time.time()
    if symbol in decision_cache:
        cache_age = current_time - cache_timestamps.get(symbol, 0)
        if cache_age < CACHE_DURATION:
            logger.debug(f"‚úÖ Cache trouv√© pour {symbol} (√¢ge: {cache_age:.1f}s)")
            return decision_cache[symbol]
        else:
            # Cache expir√©, supprimer
            del decision_cache[symbol]
            del cache_timestamps[symbol]
    return None

def cache_decision(symbol: str, decision_data: Dict):
    """Stocke une d√©cision dans le cache."""
    decision_cache[symbol] = decision_data
    cache_timestamps[symbol] = time.time()
    logger.debug(f"üíæ D√©cision mise en cache pour {symbol}")

def calculate_boom_crash_metadata(df: pd.DataFrame, symbol: str, request) -> Dict:
    """
    Calcule les m√©tadonn√©es sp√©cifiques pour Boom/Crash.
    Garantit les m√©tadonn√©es de base pour le filtre local renforc√©.
    """
    metadata = {}
    
    try:
        # RSI (priorit√©: df calcul√© > request > d√©faut)
        current_rsi = None
        if 'rsi' in df.columns and len(df) > 0:
            current_rsi = float(df['rsi'].iloc[-1])
        elif hasattr(request, 'rsi') and request.rsi is not None:
            current_rsi = request.rsi
        else:
            current_rsi = 50.0  # D√©faut neutre
        
        metadata['rsi'] = current_rsi
        
        # EMA fast/slow avec valeurs par d√©faut si erreur
        try:
            if len(df) > 21:  # Assez de donn√©es pour EMA
                ema_fast = df['close'].ewm(span=9).mean()
                ema_slow = df['close'].ewm(span=21).mean()
                ema_fast_val = float(ema_fast.iloc[-1])
                ema_slow_val = float(ema_slow.iloc[-1])
                
                metadata['ema_fast'] = ema_fast_val
                metadata['ema_slow'] = ema_slow_val
                metadata['ema_trend'] = "bullish" if ema_fast_val > ema_slow_val else "bearish"
                metadata['ema_crossover'] = ema_fast_val > ema_slow_val
            else:
                # Pas assez de donn√©es - utiliser prix actuel
                current_price = float(df['close'].iloc[-1]) if len(df) > 0 else 0.0
                metadata['ema_fast'] = current_price
                metadata['ema_slow'] = current_price
                metadata['ema_trend'] = "neutral"
                metadata['ema_crossover'] = False
        except Exception as ema_err:
            logger.warning(f"‚ö†Ô∏è Erreur calcul EMA: {ema_err}")
            metadata['ema_fast'] = 0.0
            metadata['ema_slow'] = 0.0
            metadata['ema_trend'] = "neutral"
            metadata['ema_crossover'] = False
        
        # ATR et ratio avec valeurs par d√©faut
        try:
            if len(df) > 20:
                atr = calculate_atr(df)
                atr_mean = atr.rolling(20).mean().iloc[-1]
                atr_current = atr.iloc[-1]
                atr_ratio = float(atr_current / atr_mean) if atr_mean > 0 else 1.0
            else:
                atr_ratio = 1.0  # D√©faut normal
            
            metadata['atr_ratio'] = atr_ratio
        except Exception as atr_err:
            logger.warning(f"‚ö†Ô∏è Erreur calcul ATR: {atr_err}")
            metadata['atr_ratio'] = 1.0
        
        # D√©tection de risque de spike avec valeurs par d√©faut
        try:
            if len(df) > 20:
                range_mean = df['high'].sub(df['low']).rolling(20).mean().iloc[-1]
                current_range = df['high'].iloc[-1] - df['low'].iloc[-1]
                spike_detected = current_range > (2.8 * range_mean)
            else:
                spike_detected = False
            
            metadata['spike_risk'] = spike_detected
        except Exception as spike_err:
            logger.warning(f"‚ö†Ô∏è Erreur d√©tection spike: {spike_err}")
            metadata['spike_risk'] = False
        
        # SL/TP sugg√©r√©s bas√©s sur le risque
        if metadata.get('spike_risk', False):
            metadata['suggested_sl_pips'] = 60  # Plus large pour spike
            metadata['suggested_tp_pips'] = 150
        else:
            metadata['suggested_sl_pips'] = 35
            metadata['suggested_tp_pips'] = 90
            
        # M√©tadonn√©es additionnelles pour le filtre local
        metadata['symbol'] = symbol
        metadata['is_boom'] = 'boom' in symbol.lower()
        metadata['is_crash'] = 'crash' in symbol.lower()
        metadata['timestamp'] = datetime.now().isoformat()
            
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erreur calcul m√©tadonn√©es: {e}")
        # Garantir les m√©tadonn√©es de base m√™me en cas d'erreur
        metadata = {
            'rsi': getattr(request, 'rsi', 50.0),
            'atr_ratio': 1.0,
            'spike_risk': False,
            'ema_trend': 'neutral',
            'ema_fast': 0.0,
            'ema_slow': 0.0,
            'ema_crossover': False,
            'error': str(e),
            'symbol': symbol,
            'timestamp': datetime.now().isoformat()
        }
    
    return metadata

def calculate_atr(df: pd.DataFrame, period: int = 14) -> pd.Series:
    """Calcule l'ATR (Average True Range)."""
    high_low = df['high'] - df['low']
    high_close = (df['high'] - df['close'].shift()).abs()
    low_close = (df['low'] - df['close'].shift()).abs()
    
    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    return true_range.rolling(window=period).mean()

def convert_numpy_to_python(obj):
    """
    Convertit les types numpy en types Python standards pour la s√©rialisation JSON.
    R√©cursif pour les dictionnaires et listes.
    """
    import numpy as np
    
    if isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_to_python(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_to_python(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(convert_numpy_to_python(item) for item in obj)
    else:
        return obj

def calculate_rsi(prices: pd.Series, period: int = 14) -> pd.Series:
    """Calcule le RSI."""
    delta = prices.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    
    return rsi

# Cache pour les donn√©es historiques (fallback cloud)
_history_cache: Dict[str, pd.DataFrame] = {}

# =========================
# Fonctions de d√©tection de spikes Boom/Crash
# =========================
def is_boom_crash_symbol(symbol: str) -> bool:
    """V√©rifie si le symbole est un indice Boom ou Crash (tous indices Deriv)"""
    s = symbol.lower()
    return ("boom" in s and "index" in s) or ("crash" in s and "index" in s)

def detect_spike_pattern(df: pd.DataFrame, symbol: str) -> Dict[str, Any]:
    """
    D√©tecte les patterns de spikes pour Boom/Crash
    
    Args:
        df: DataFrame avec les donn√©es OHLCV
        symbol: Symbole √† analyser
        
    Returns:
        Dict avec informations de spike d√©tect√©
    """
    if len(df) < 10:
        return {"has_spike": False, "reason": "Donn√©es insuffisantes"}
    
    # Debug: v√©rifier les colonnes disponibles
    logger.info(f"Colonnes disponibles dans DataFrame: {list(df.columns)}")
    
    # S'assurer que les colonnes requises existent
    required_columns = ['open', 'high', 'low', 'close', 'tick_volume']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        logger.error(f"Colonnes manquantes: {missing_columns}")
        return {"has_spike": False, "reason": f"Colonnes manquantes: {missing_columns}"}
    
    # Calculer les indicateurs de volatilit√©
    df['price_change'] = df['close'] - df['open']
    df['price_change_pct'] = (df['price_change'] / df['open']) * 100
    
    # Ajouter le changement inter-bougies (plus important pour les spikes)
    df['close_change'] = df['close'] - df['close'].shift(1)
    df['close_change_pct'] = (df['close_change'] / df['close'].shift(1)) * 100
    
    df['range'] = df['high'] - df['low']
    df['range_pct'] = (df['range'] / df['open']) * 100
    df['volume_ma'] = df['tick_volume'].rolling(window=5).mean()
    df['volume_ratio'] = df['tick_volume'] / df['volume_ma']
    
    # Derni√®res bougies
    last_candle = df.iloc[-1]
    prev_candle = df.iloc[-2]
    
    # Seuils sp√©cifiques Boom/Crash
    is_boom = "Boom" in symbol
    is_crash = "Crash" in symbol
    
    # Crit√®res de spike
    spike_criteria = {
        "price_spike": abs(last_candle['close_change_pct']) > (0.8 if is_boom else 1.2),  # % de changement inter-bougies
        "range_spike": last_candle['range_pct'] > (1.0 if is_boom else 1.5),  # Volatilit√© intraday
        "volume_spike": last_candle['volume_ratio'] > 2.0,  # Volume 2x la moyenne
        "momentum_spike": False
    }
    
    # Calculer le momentum
    rsi_period = 14
    df['rsi'] = calculate_rsi(df['close'], rsi_period)
    
    if len(df) >= rsi_period + 1:
        rsi_current = df['rsi'].iloc[-1]
        rsi_prev = df['rsi'].iloc[-2]
        
        # Spike de momentum: RSI change brusquement
        rsi_change = abs(rsi_current - rsi_prev)
        spike_criteria["momentum_spike"] = rsi_change > 10
        
        # RSI extremes pour confirmation
        if is_boom:
            spike_criteria["rsi_oversold"] = rsi_current < 30
        else:  # Crash
            spike_criteria["rsi_overbought"] = rsi_current > 70
    
    # Compter les crit√®res remplis
    criteria_met = sum(1 for k, v in spike_criteria.items() if v and not k.startswith("rsi_"))
    has_spike = criteria_met >= 2  # Au moins 2 crit√®res sur 3
    
    # Direction du spike
    spike_direction = None
    if has_spike:
        if last_candle['close_change_pct'] > 0:
            spike_direction = "BUY"
        else:
            spike_direction = "SELL"
        
        # Validation direction pour Boom/Crash
        if is_boom and spike_direction == "SELL":
            has_spike = False  # Pas de SELL sur Boom
        elif is_crash and spike_direction == "BUY":
            has_spike = False  # Pas de BUY sur Crash
    
    # Calculer la confiance du spike
    spike_confidence = 0.0
    if has_spike:
        base_confidence = min(85.0, criteria_met * 25.0)  # 25% par crit√®re
        
        # Bonus pour volume √©lev√©
        if spike_criteria["volume_spike"]:
            base_confidence += 10.0
        
        # Bonus pour momentum extr√™me
        if spike_criteria["momentum_spike"]:
            base_confidence += 10.0
        
        spike_confidence = min(95.0, base_confidence)
    
    return {
        "has_spike": bool(has_spike),
        "direction": spike_direction,
        "confidence": float(spike_confidence),
        "criteria": {k: bool(v) for k, v in spike_criteria.items()},
        "price_change_pct": float(last_candle['close_change_pct']) if pd.notna(last_candle['close_change_pct']) else 0.0,
        "range_pct": float(last_candle['range_pct']) if pd.notna(last_candle['range_pct']) else 0.0,
        "volume_ratio": float(last_candle['volume_ratio']) if pd.notna(last_candle['volume_ratio']) else 0.0,
        "rsi": float(df['rsi'].iloc[-1]) if len(df) >= rsi_period and pd.notna(df['rsi'].iloc[-1]) else None,
        "timestamp": int(last_candle['time']) if 'time' in df.columns and pd.notna(last_candle['time']) else None
    }

def calculate_rsi(prices: pd.Series, period: int = 14) -> pd.Series:
    """Calcule le RSI"""
    delta = prices.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return rsi

def generate_boom_crash_signal(symbol: str, df: pd.DataFrame) -> Dict[str, Any]:
    """
    G√©n√®re un signal de trading pour Boom/Crash bas√© sur la d√©tection de spikes
    
    Args:
        symbol: Symbole Boom/Crash
        df: DataFrame avec donn√©es OHLCV
        
    Returns:
        Dict avec signal de trading
    """
    if not is_boom_crash_symbol(symbol):
        return {"has_signal": False, "reason": "Pas un symbole Boom/Crash"}
    
    # D√©tecter le spike
    spike_info = detect_spike_pattern(df, symbol)
    
    if not spike_info["has_spike"]:
        return {
            "has_signal": False,
            "reason": "Aucun spike d√©tect√©",
            "spike_info": spike_info
        }
    
    # Calculer SL/TP pour les spikes
    last_candle = df.iloc[-1]
    current_price = last_candle['close']
    atr = calculate_atr(df, 14)
    
    # SL/TP serr√©s pour les spikes
    if spike_info["direction"] == "BUY":
        stop_loss = current_price - (atr * 0.5)  # SL tr√®s serr√©
        take_profit = current_price + (atr * 1.5)  # TP plus large
    else:  # SELL
        stop_loss = current_price + (atr * 0.5)
        take_profit = current_price - (atr * 1.5)
    
    return {
        "has_signal": bool(spike_info["has_signal"]),
        "signal": spike_info["direction"],
        "confidence": float(spike_info["confidence"]),
        "source": "boom_crash_spike",
        "stop_loss": round(float(stop_loss), 2) if pd.notna(stop_loss) else None,
        "take_profit": round(float(take_profit), 2) if pd.notna(take_profit) else None,
        "position_size": 0.01,  # Taille fixe pour les spikes
        "reasoning": [
            f"Spike {spike_info['direction']} d√©tect√©",
            f"Changement prix: {spike_info['price_change_pct']:.2f}%",
            f"Volume ratio: {spike_info['volume_ratio']:.1f}x",
            f"Confiance: {spike_info['confidence']:.0f}%"
        ],
        "spike_info": {
            k: (bool(v) if isinstance(v, (bool, np.bool_)) else float(v) if isinstance(v, (int, float, np.number)) else v)
            for k, v in spike_info.items()
            if k != 'criteria'
        },
        "timestamp": datetime.now().isoformat()
    }

def calculate_atr(df: pd.DataFrame, period: int = 14) -> float:
    """Calcule l'Average True Range"""
    high_low = df['high'] - df['low']
    high_close = abs(df['high'] - df['close'].shift())
    low_close = abs(df['low'] - df['close'].shift())
    
    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    atr = true_range.rolling(window=period).mean()
    
    return atr.iloc[-1] if not atr.empty else 0.0

def draw_predictive_channel(df: pd.DataFrame, symbol: str, lookback_period: int = 50) -> Dict[str, Any]:
    """
    Dessine un canal pr√©dictif bas√© sur l'analyse technique des tendances
    
    Args:
        df: DataFrame avec donn√©es OHLCV
        symbol: Symbole √† analyser
        lookback_period: P√©riode de r√©trospection pour l'analyse
        
    Returns:
        Dict avec informations du canal pr√©dictif
    """
    if len(df) < lookback_period + 10:
        return {"has_channel": False, "reason": f"Donn√©es insuffisantes (besoin de {lookback_period + 10} bougies)"}
    
    try:
        # Extraire les donn√©es pertinentes
        recent_data = df.tail(lookback_period).copy()
        highs = recent_data['high'].values
        lows = recent_data['low'].values
        closes = recent_data['close'].values
        times = recent_data.index if 'time' not in recent_data.columns else recent_data['time']
        
        # Calculer les lignes de tendance sup√©rieure et inf√©rieure
        # Utiliser r√©gression lin√©aire pour trouver les tendances
        
        # Ligne de tendance sup√©rieure (bas√©e sur les highs)
        x_high = np.arange(len(highs))
        coeffs_high = np.polyfit(x_high, highs, 1)  # R√©gression lin√©aire degr√© 1
        trend_high = np.polyval(coeffs_high, x_high)
        
        # Ligne de tendance inf√©rieure (bas√©e sur les lows)
        x_low = np.arange(len(lows))
        coeffs_low = np.polyfit(x_low, lows, 1)
        trend_low = np.polyval(coeffs_low, x_low)
        
        # Ligne de tendance centrale (bas√©e sur les closes)
        x_close = np.arange(len(closes))
        coeffs_close = np.polyfit(x_close, closes, 1)
        trend_close = np.polyval(coeffs_close, x_close)
        
        # Calculer la largeur du canal (moyenne des √©carts)
        channel_width = np.mean(trend_high - trend_low)
        
        # D√©tecter si le canal est trop serr√© (consolidation)
        price_range = np.max(highs) - np.min(lows)
        relative_width = channel_width / np.mean(closes)
        is_consolidating = relative_width < 0.002  # Moins de 0.2% de largeur relative
        
        # Projeter le canal dans le futur (5 prochaines p√©riodes)
        future_periods = 5
        x_future = np.arange(len(closes), len(closes) + future_periods)
        
        # Projection des tendances
        future_high = np.polyval(coeffs_high, x_future)
        future_low = np.polyval(coeffs_low, x_future)
        future_close = np.polyval(coeffs_close, x_future)
        
        # Prix actuel
        current_price = closes[-1]
        
        # D√©terminer la position actuelle dans le canal
        if trend_high[-1] - trend_low[-1] > 0:
            current_position = (current_price - trend_low[-1]) / (trend_high[-1] - trend_low[-1])
        else:
            current_position = 0.5  # Position neutre si canal plat
        current_position = max(0, min(1, current_position))  # Clamp entre 0 et 1
        
        # Calculer les signaux bas√©s sur le canal
        signal = None
        confidence = 0.0
        reasoning = []
        
        # Ajouter d√©tection de consolidation
        if is_consolidating:
            reasoning.append("March√© en consolidation (canal tr√®s serr√©)")
            # En consolidation, utiliser des seuils plus stricts
            upper_threshold = 0.15
            lower_threshold = 0.85
        else:
            upper_threshold = 0.2
            lower_threshold = 0.8
        
        # Si le prix est pr√®s de la borne inf√©rieure -> signal BUY
        if current_position < upper_threshold:
            signal = "BUY"
            confidence = (upper_threshold - current_position) / upper_threshold
            reasoning.append(f"Prix proche de la borne inf√©rieure du canal ({current_position:.1%})")
        
        # Si le prix est pr√®s de la borne sup√©rieure -> signal SELL
        elif current_position > lower_threshold:
            signal = "SELL"
            confidence = (current_position - lower_threshold) / (1 - lower_threshold)
            reasoning.append(f"Prix proche de la borne sup√©rieure du canal ({current_position:.1%})")
        
        # Si le prix est au centre -> signal NEUTRAL
        else:
            signal = "NEUTRAL"
            confidence = 0.5
            reasoning.append(f"Prix au centre du canal ({current_position:.1%})")
        
        # Ajouter la pente du canal √† l'analyse
        slope = coeffs_close[0]
        if abs(slope) > 0.0005:  # Seuil plus √©lev√© pour consid√©rer la pente significative
            if slope > 0:
                reasoning.append(f"Canal haussier (pente: {slope:.4f})")
                if signal == "BUY":
                    confidence += 0.15  # Bonus plus √©lev√© pour signal align√©
            else:
                reasoning.append(f"Canal baissier (pente: {slope:.4f})")
                if signal == "SELL":
                    confidence += 0.15
        else:
            reasoning.append(f"Canal lat√©ral (pente: {slope:.4f})")
            # R√©duire la confiance en cas de canal lat√©ral
            if signal != "NEUTRAL":
                confidence *= 0.7
        
        # Calculer les niveaux de support/r√©sistance projet√©s
        projected_support = future_low[-1]
        projected_resistance = future_high[-1]
        
        # Calculer SL/TP bas√©s sur le canal
        if signal == "BUY":
            stop_loss = max(trend_low[-1], current_price - channel_width * 0.5)
            take_profit = min(trend_high[-1], current_price + channel_width * 1.5)
        elif signal == "SELL":
            stop_loss = min(trend_high[-1], current_price + channel_width * 0.5)
            take_profit = max(trend_low[-1], current_price - channel_width * 1.5)
        else:
            stop_loss = None
            take_profit = None
        
        confidence = min(0.95, confidence)  # Limiter la confiance maximale
        
        return {
            "has_channel": True,
            "symbol": symbol,
            "current_price": float(current_price),
            "signal": signal,
            "confidence": float(confidence),
            "channel_info": {
                "upper_line": {
                    "current": float(trend_high[-1]),
                    "slope": float(coeffs_high[0]),
                    "projected": [float(val) for val in future_high]
                },
                "lower_line": {
                    "current": float(trend_low[-1]),
                    "slope": float(coeffs_low[0]),
                    "projected": [float(val) for val in future_low]
                },
                "center_line": {
                    "current": float(trend_close[-1]),
                    "slope": float(coeffs_close[0]),
                    "projected": [float(val) for val in future_close]
                },
                "width": float(channel_width),
                "position_in_channel": float(current_position),
                "is_consolidating": bool(is_consolidating),
                "relative_width": float(relative_width),
                "upper_threshold": float(upper_threshold),
                "lower_threshold": float(lower_threshold)
            },
            "support_resistance": {
                "support": float(projected_support),
                "resistance": float(projected_resistance)
            },
            "stop_loss": float(stop_loss) if stop_loss is not None else None,
            "take_profit": float(take_profit) if take_profit is not None else None,
            "reasoning": reasoning,
            "lookback_period": lookback_period,
            "future_periods": future_periods,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Erreur lors du dessin du canal pr√©dictif pour {symbol}: {e}")
        return {
            "has_channel": False,
            "reason": f"Erreur technique: {str(e)}",
            "symbol": symbol
        }


def get_prediction_channel_5000(symbol: str, timeframe: str = "M1", future_bars: int = 5000) -> dict:
    """
    Canal de pr√©diction ML sur N prochaines bougies (jusqu'√† 5000).
    Analyse les prix historiques, r√©gression lin√©aire, projection future.
    Utilise les m√©triques Supabase (feedback) pour ajuster la largeur du canal.
    """
    lookback = 500
    period_seconds = 60 if timeframe == "M1" else (300 if timeframe == "M5" else 900 if timeframe == "M15" else 3600)
    try:
        df = get_historical_data_mt5(symbol, timeframe, lookback)
        if df is None or len(df) < 100:
            df = get_recent_historical_data(symbol, lookback)
        if df is None or len(df) < 100:
            return {"ok": False, "reason": "donn√©es insuffisantes"}

        if "time" in df.columns:
            times = df["time"]
        else:
            times = pd.date_range(end=datetime.now(), periods=len(df), freq=f"{period_seconds}s")
        highs = df["high"].values
        lows = df["low"].values
        closes = df["close"].values
        n = len(closes)

        x = np.arange(n)
        coeffs_high = np.polyfit(x, highs, 1)
        coeffs_low = np.polyfit(x, lows, 1)
        channel_width = np.mean(highs - lows)

        # Feedback Supabase: ajuster la largeur selon la pr√©cision du mod√®le (m√©triques)
        width_mult = 1.0
        try:
            import os
            import httpx
            supabase_url = os.getenv("SUPABASE_URL", "https://bpzqnooiisgadzicwupi.supabase.co")
            supabase_key = os.getenv("SUPABASE_ANON_KEY")
            if supabase_key:
                r = httpx.get(
                    f"{supabase_url}/rest/v1/model_metrics?symbol=eq.{symbol}&order=created_at.desc&limit=1",
                    headers={"apikey": supabase_key, "Authorization": f"Bearer {supabase_key}"},
                    timeout=5,
                )
                if r.status_code == 200 and r.json():
                    row = r.json()[0]
                    acc = row.get("accuracy") or row.get("accuracy_score")
                    if acc is not None:
                        if acc < 0.6:
                            width_mult = 1.4
                        elif acc < 0.75:
                            width_mult = 1.2
                pred_acc = get_prediction_accuracy_score(symbol) if symbol else 0.5
                if pred_acc < 0.6:
                    width_mult = max(width_mult, 1.3)
        except Exception:
            pass

        future_bars = min(max(1, future_bars), 5000)
        x_start = n
        x_end = n + future_bars
        upper_start = float(np.polyval(coeffs_high, x_start))
        upper_end = float(np.polyval(coeffs_high, x_end))
        lower_start = float(np.polyval(coeffs_low, x_start))
        lower_end = float(np.polyval(coeffs_low, x_end))
        half_w = (channel_width * (width_mult - 1)) / 2
        upper_start += half_w
        upper_end += half_w
        lower_start -= half_w
        lower_end -= half_w

        if hasattr(times, "iloc"):
            last_ts = times.iloc[-1]
        else:
            last_ts = times[-1]
        if hasattr(last_ts, "timestamp"):
            time_start = int(last_ts.timestamp())
        else:
            time_start = int(pd.Timestamp(last_ts).timestamp())

        return {
            "ok": True,
            "symbol": symbol,
            "timeframe": timeframe,
            "time_start": time_start,
            "period_seconds": period_seconds,
            "future_bars": future_bars,
            "upper_start": round(upper_start, 8),
            "upper_end": round(upper_end, 8),
            "lower_start": round(lower_start, 8),
            "lower_end": round(lower_end, 8),
            "width_mult": width_mult,
        }
    except Exception as e:
        logger.error(f"Erreur canal pr√©diction 5000 pour {symbol}: {e}")
        return {"ok": False, "reason": str(e)[:200]}


# =========================
# Fonctions de r√©cup√©ration de donn√©es cloud
# =========================
def get_market_data_cloud(symbol: str, period: str = "5d", interval: str = "1m") -> pd.DataFrame:
    """R√©cup√®re les donn√©es via yfinance (compatible cloud)"""
    try:
        if not YFINANCE_AVAILABLE:
            return generate_simulated_data(symbol, 100)
        
        # Mapping des symboles pour yfinance
        symbol_map = {
            "EURUSD": "EURUSD=X",
            "GBPUSD": "GBPUSD=X",
            "USDJPY": "USDJPY=X",
            "Boom 500 Index": "^GSPC",
            "Boom 300 Index": "^GSPC",
            "Boom 600 Index": "^GSPC",
            "Boom 900 Index": "^GSPC",
            "Boom 1000 Index": "^GSPC",
            "Crash 300 Index": "^VIX",
            "Crash 500 Index": "^VIX",
            "Crash 900 Index": "^VIX",
            "Crash 1000 Index": "^VIX",
            "Volatility 75 Index": "^VIX",
            "Volatility 100 Index": "^VIX",
            "Volatility 25 Index": "^VIX",
            "Step Index": "^GSPC",
        }
        
        yf_symbol = symbol_map.get(symbol, symbol)
        
        # R√©cup√©rer les donn√©es
        ticker = yf.Ticker(yf_symbol)
        data = ticker.history(period=period, interval=interval)
        
        if data.empty:
            return generate_simulated_data(symbol, 100)
        
        # Standardiser les colonnes
        df = data.reset_index()
        df = df.rename(columns={
            'Open': 'open',
            'High': 'high', 
            'Low': 'low',
            'Close': 'close',
            'Volume': 'volume'
        })
        
        # Ajouter colonne time
        df['time'] = df['Datetime'].astype(np.int64) // 10**9
        
        return df[['time', 'open', 'high', 'low', 'close', 'volume']]
        
    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration donn√©es cloud pour {symbol}: {e}")
        return generate_simulated_data(symbol, 100)

def generate_simulated_data(symbol: str, periods: int = 100) -> pd.DataFrame:
    """G√©n√®re des donn√©es de march√© simul√©es avec spikes r√©alistes pour Boom/Crash"""
    try:
        np.random.seed(hash(symbol) % 2**32)
        
        base_prices = {
            "EURUSD": 1.0850,
            "GBPUSD": 1.2750,
            "USDJPY": 148.50,
            "Boom 300 Index": 300,
            "Boom 500 Index": 5000,
            "Boom 600 Index": 600,
            "Boom 900 Index": 900,
            "Boom 1000 Index": 1000,
            "Crash 300 Index": 300,
            "Crash 500 Index": 500,
            "Crash 900 Index": 900,
            "Crash 1000 Index": 1000,
            "Volatility 25 Index": 25,
            "Volatility 75 Index": 75,
            "Volatility 100 Index": 100,
            "Step Index": 1000,
        }
        
        base_price = base_prices.get(symbol, 100)
        
        # V√©rifier si c'est un symbole Boom/Crash pour g√©n√©rer des spikes
        is_boom_crash = is_boom_crash_symbol(symbol)
        
        if is_boom_crash:
            # G√©n√©rer des donn√©es avec spikes pour Boom/Crash
            returns = np.random.normal(0, 0.001, periods)  # Volatilit√© de base plus faible
            
            # Ajouter quelques spikes al√©atoires (10-15% de chance par bougie)
            spike_probability = 0.12
            for i in range(periods):
                if np.random.random() < spike_probability:
                    # G√©n√©rer un spike
                    spike_direction = 1 if "Boom" in symbol else -1  # Boom monte, Crash descend
                    spike_magnitude = np.random.uniform(0.008, 0.025)  # 0.8% √† 2.5% de spike
                    returns[i] = spike_direction * spike_magnitude
            
            # Ajouter de la volatilit√© autour des spikes
            volatility_boost = np.random.normal(0, 0.002, periods)
            returns += volatility_boost
        else:
            # Donn√©es normales pour les autres symboles
            returns = np.random.normal(0, 0.002, periods)
        
        prices = [base_price]
        
        for ret in returns:
            new_price = prices[-1] * (1 + ret)
            prices.append(new_price)
        
        prices = prices[1:]
        
        timestamps = pd.date_range(end=datetime.now(), periods=periods, freq='1min')
        
        # G√©n√©rer les OHLC avec des spreads r√©alistes
        if is_boom_crash:
            # Spread plus large pour Boom/Crash pendant les spikes
            spreads = [abs(np.random.normal(0.002, 0.001)) for _ in range(periods)]
        else:
            spreads = [abs(np.random.normal(0.0005, 0.0002)) for _ in range(periods)]
        
        df = pd.DataFrame({
            'time': timestamps.astype(np.int64) // 10**9,
            'open': prices,
            'high': [p * (1 + spreads[i]) for i, p in enumerate(prices)],
            'low': [p * (1 - spreads[i]) for i, p in enumerate(prices)],
            'close': prices,
            'tick_volume': np.random.randint(5000, 50000, periods) if is_boom_crash else np.random.randint(1000, 10000, periods)
        })
        
        # Ajouter le volume column pour compatibilit√©
        df['volume'] = df['tick_volume']
        
        return df
        
    except Exception as e:
        logger.error(f"Erreur g√©n√©ration donn√©es simul√©es: {e}")
        return pd.DataFrame()

def get_market_data(symbol: str, timeframe: str = "M1", count: int = 1000) -> pd.DataFrame:
    """R√©cup√®re les donn√©es en utilisant la meilleure source disponible"""
    cache_key = f"{symbol}_{timeframe}"
    
    # V√©rifier le cache en premier
    if cache_key in _history_cache:
        cached_data = _history_cache[cache_key]
        if not cached_data.empty:
            logger.info(
                f"Donn√©es r√©cup√©r√©es depuis cache: "
                f"{len(cached_data)} bougies pour {symbol}"
            )
            return cached_data
    
    # Essayer MT5 d'abord
    if MT5_AVAILABLE and mt5_initialized:
        try:
            # Mapping des timeframes
            tf_map = {
                "M1": mt5.TIMEFRAME_M1,
                "M5": mt5.TIMEFRAME_M5,
                "M15": mt5.TIMEFRAME_M15,
                "M30": mt5.TIMEFRAME_M30,
                "H1": mt5.TIMEFRAME_H1,
                "H4": mt5.TIMEFRAME_H4,
                "D1": mt5.TIMEFRAME_D1,
            }
            
            mt5_tf = tf_map.get(timeframe, mt5.TIMEFRAME_M1)
            
            # R√©cup√©rer les donn√©es
            rates = mt5.copy_rates_from_pos(symbol, mt5_tf, 0, count)
            
            if rates is not None and len(rates) > 0:
                df = pd.DataFrame(rates)
                df['time'] = pd.to_datetime(df['time'], unit='s')
                _history_cache[cache_key] = df
                logger.info(f"Donn√©es r√©cup√©r√©es depuis MT5: {len(df)} bougies pour {symbol}")
                return df
        except Exception as e:
            logger.warning(f"Erreur MT5 pour {symbol}: {e}")
    
    # Fallback vers yfinance
    data = get_market_data_cloud(symbol)
    if not data.empty:
        _history_cache[cache_key] = data
        logger.info(f"Donn√©es r√©cup√©r√©es depuis yfinance: {len(data)} bougies pour {symbol}")
        return data
    
    # Dernier recours: donn√©es simul√©es
    data = generate_simulated_data(symbol, count)
    _history_cache[cache_key] = data
    logger.info(f"Donn√©es simul√©es g√©n√©r√©es: {len(data)} bougies pour {symbol}")
    return data

# Charger les variables d'environnement
try:
    from dotenv import load_dotenv
    base_dir = Path(__file__).parent
    env_path = base_dir / '.env'
    supabase_env_path = base_dir / '.env.supabase'
    if env_path.exists():
        load_dotenv(env_path)
        logger.info(f"‚úÖ Fichier .env charg√© depuis: {env_path}")
    elif supabase_env_path.exists():
        load_dotenv(supabase_env_path)
        logger.info(f"‚úÖ Fichier .env.supabase charg√© depuis: {supabase_env_path}")
    else:
        load_dotenv()  # Essaie de charger depuis le r√©pertoire courant
        logger.info(
            "‚úÖ Variables d'environnement charg√©es "
            "(aucun fichier .env/.env.supabase trouv√©, utilisation des variables syst√®me)"
        )
except ImportError:
    logger.warning(
        "‚ö†Ô∏è python-dotenv non disponible - "
        "utilisation des variables d'environnement syst√®me uniquement"
    )
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Erreur lors du chargement du .env: {e}")

# Configuration PostgreSQL pour feedback loop
DATABASE_URL = os.getenv("DATABASE_URL", "")
DB_AVAILABLE = bool(DATABASE_URL and ASYNCPG_AVAILABLE)

# Fonctions d'aide pour les indicateurs
def calculate_rsi(prices: pd.Series, period: int = 14) -> pd.Series:
    delta = prices.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

def calculate_atr(df: pd.DataFrame, period: int = 14) -> pd.Series:
    high_low = df['high'] - df['low']
    high_close = (df['high'] - df['close'].shift()).abs()
    low_close = (df['low'] - df['close'].shift()).abs()
    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    return true_range.rolling(window=period).mean()

def calculate_macd(
    prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9
) -> pd.Series:
    exp1 = prices.ewm(span=fast, adjust=False).mean()
    exp2 = prices.ewm(span=slow, adjust=False).mean()
    macd = exp1 - exp2
    signal_line = macd.ewm(span=signal, adjust=False).mean()
    return macd - signal_line

def calculate_bollinger_bands(
    prices: pd.Series, window: int = 20, num_std: int = 2
) -> Dict[str, pd.Series]:
    sma = prices.rolling(window=window).mean()
    std = prices.rolling(window=window).std()
    return {
        'upper': sma + (std * num_std),
        'middle': sma,
        'lower': sma - (std * num_std)
    }

def convert_numpy_types(data: Dict[str, Any]) -> Dict[str, Any]:
    """Convertit les types NumPy en types Python natifs.
    
    Args:
        data: Dictionnaire contenant des valeurs NumPy
        
    Returns:
        Dictionnaire avec des types Python natifs
    """
    import numpy as np
    
    converted = {}
    for key, value in data.items():
        if isinstance(value, (np.integer, np.floating)):
            converted[key] = value.item()
        elif isinstance(value, np.ndarray):
            converted[key] = value.tolist()
        else:
            converted[key] = value
    return converted

def get_mt5_indicators(symbol: str, timeframe: str, count: int = 100) -> Optional[Dict[str, Any]]:
    """R√©cup√®re les indicateurs MT5 pour un symbole et une p√©riode donn√©s
    
    Args:
        symbol: Symbole du march√© (ex: "EURUSD")
        timeframe: P√©riode (M1, M5, M15, H1, H4, D1)
        count: Nombre de bougies √† analyser
        
    Returns:
        Dictionnaire des indicateurs techniques ou None en cas d'erreur
    """
    if not mt5.initialize():
        logger.error("√âchec de l'initialisation MT5")
        return None
    
    try:
        # Conversion du timeframe MT5
        tf_map = {
            'M1': mt5.TIMEFRAME_M1,
            'M5': mt5.TIMEFRAME_M5,
            'M15': mt5.TIMEFRAME_M15,
            'M30': mt5.TIMEFRAME_M30,
            'H1': mt5.TIMEFRAME_H1,
            'H4': mt5.TIMEFRAME_H4,
            'D1': mt5.TIMEFRAME_D1,
            'W1': mt5.TIMEFRAME_W1
        }
        
        mt5_timeframe = tf_map.get(timeframe, mt5.TIMEFRAME_M1)
        
        # R√©cup√©ration des donn√©es OHLC
        rates = mt5.copy_rates_from_pos(symbol, mt5_timeframe, 0, count)
        if rates is None or len(rates) == 0:
            logger.error(f"Impossible de r√©cup√©rer les donn√©es pour {symbol} {timeframe}")
            return None
            
        # Conversion en DataFrame
        df = pd.DataFrame(rates)
        if df.empty:
            logger.error(f"Aucune donn√©e re√ßue pour {symbol} {timeframe}")
            return None
            
        df['time'] = pd.to_datetime(df['time'], unit='s')
        df.set_index('time', inplace=True)
        
        # V√©rification des donn√©es manquantes
        if df.isnull().values.any():
            logger.warning(
                f"Donn√©es manquantes d√©tect√©es pour {symbol} {timeframe}, "
                "tentative de remplissage..."
            )
            df = df.ffill().bfill()
            
            # Si des valeurs manquantes persistent, on les remplace par la derni√®re valeur valide
            if df.isnull().values.any():
                df = df.fillna(method='ffill')
        
        # Calcul des indicateurs avec gestion des erreurs
        indicators = {}
        try:
            # Prix et volumes
            indicators.update({
                'current_price': df['close'].iloc[-1],
                'open': df['open'].iloc[-1],
                'high': df['high'].iloc[-1],
                'low': df['low'].iloc[-1],
                'volume': df['tick_volume'].iloc[-1],
                'spread': df['spread'].iloc[-1] if 'spread' in df.columns else 0
            })
            
            # Moyennes mobiles
            for period in [5, 10, 20, 50, 100, 200]:
                if len(df) >= period:
                    indicators[f'sma_{period}'] = df['close'].rolling(window=period).mean().iloc[-1]
                    indicators[f'ema_{period}'] = df['close'].ewm(span=period, adjust=False).mean().iloc[-1]
            
            # RSI
            if len(df) >= 14:  # P√©riode minimale pour RSI
                indicators['rsi'] = calculate_rsi(df['close'], 14).iloc[-1]
            
            # ATR
            if len(df) >= 14:  # P√©riode minimale pour ATR
                indicators['atr'] = calculate_atr(df, 14).iloc[-1]
            
            # MACD
            if len(df) >= 26:  # P√©riode minimale pour MACD
                ema12 = df['close'].ewm(span=12, adjust=False).mean()
                ema26 = df['close'].ewm(span=26, adjust=False).mean()
                macd_line = ema12 - ema26
                signal_line = macd_line.ewm(span=9, adjust=False).mean()
                indicators['macd'] = (macd_line - signal_line).iloc[-1]
            
            # Bandes de Bollinger
            if len(df) >= 20:  # P√©riode minimale pour les bandes de Bollinger
                bb = calculate_bollinger_bands(df['close'])
                indicators.update({
                    'bb_upper': bb['upper'].iloc[-1],
                    'bb_middle': bb['middle'].iloc[-1],
                    'bb_lower': bb['lower'].iloc[-1],
                    'bb_width': (
                        (bb['upper'].iloc[-1] - bb['lower'].iloc[-1]) / 
                        bb['middle'].iloc[-1] if bb['middle'].iloc[-1] != 0 else 0
                    )
                })
            
            # Volume moyen sur 20 p√©riodes
            if len(df) >= 20:
                indicators['volume_sma_20'] = df['tick_volume'].rolling(window=20).mean().iloc[-1]
            
            # Conversion des types numpy en types Python natifs
            indicators = convert_numpy_types(indicators)
            
            return indicators
            
        except Exception as e:
            logger.error(f"Erreur lors du calcul des indicateurs pour {symbol} {timeframe}: {e}")
            return None
            
    except Exception as e:
        logger.error(f"Erreur dans get_mt5_indicators pour {symbol} {timeframe}: {e}")
        return None
        
    finally:
        # Toujours essayer de fermer la connexion MT5
        try:
            mt5.shutdown()
        except:
            pass

# Nouveaux imports pour Gemma (optionnel)
GEMMA_AVAILABLE = False
gemma_processor = None
gemma_model = None
torch = None
Image = None
AutoProcessor = None
AutoModelForImageTextToText = None
AutoModelForCausalLM = None

# PIL peut √™tre utilis√© ind√©pendamment de torch/transformers (ex: lecture d'images export√©es).
# On l'importe s√©par√©ment pour √©viter que l'√©chec de torch d√©sactive aussi PIL.
try:
    from PIL import Image as _PILImage  # type: ignore
    Image = _PILImage
except Exception:
    Image = None

# Configuration des r√©pertoires via variables d'environnement
# V√©rification si on est sur Supabase
RUNNING_ON_SUPABASE = bool(os.getenv("SUPABASE_URL") or os.getenv("SUPABASE_PROJECT_ID"))

# Fonction pour cr√©er un r√©pertoire avec gestion des erreurs
def safe_makedirs(path, mode=0o755):
    try:
        os.makedirs(path, mode=mode, exist_ok=True)
        # V√©rification des permissions
        test_file = os.path.join(path, f".test_{int(time.time())}")
        with open(test_file, 'w') as f:
            f.write("test")
        os.remove(test_file)
        return True
    except Exception as e:
        logger.error(f"Impossible d'√©crire dans {path}: {str(e)}")
        return False

# Configuration des chemins
try:
    if RUNNING_ON_SUPABASE:
        # Sur Render, on utilise le r√©pertoire temporaire du syst√®me
        import tempfile
        base_temp_dir = tempfile.gettempdir()
        app_temp_dir = os.path.join(base_temp_dir, 'tradbot_ai')
        
        # Cr√©ation des chemins de base
        DEFAULT_DATA_DIR = os.path.join(app_temp_dir, 'data')
        DEFAULT_MODELS_DIR = os.path.join(app_temp_dir, 'models')
        
        # Essayer de cr√©er les r√©pertoires principaux
        if not safe_makedirs(DEFAULT_DATA_DIR) or not safe_makedirs(DEFAULT_MODELS_DIR):
            # Fallback vers /tmp direct si √©chec
            logger.warning("Utilisation de /tmp direct comme fallback")
            DEFAULT_DATA_DIR = "/tmp/tradbot_data"
            DEFAULT_MODELS_DIR = "/tmp/tradbot_models"
            safe_makedirs(DEFAULT_DATA_DIR)
            safe_makedirs(DEFAULT_MODELS_DIR)
    else:
        # En local, on utilise les dossiers du projet
        DEFAULT_DATA_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data")
        DEFAULT_MODELS_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "models")
        safe_makedirs(DEFAULT_DATA_DIR)
        safe_makedirs(DEFAULT_MODELS_DIR)
        
    # D√©finition des chemins des mod√®les et fichiers
    GEMMA_MODEL_PATH = os.path.join(DEFAULT_MODELS_DIR, "gemma")
    MT5_FILES_DIR = os.path.join(DEFAULT_DATA_DIR, "mt5_files")
    
    # Cr√©ation des sous-r√©pertoires
    safe_makedirs(GEMMA_MODEL_PATH)
    safe_makedirs(MT5_FILES_DIR)
    
    logger.info(f"R√©pertoire des donn√©es: {DEFAULT_DATA_DIR}")
    logger.info(f"R√©pertoire des mod√®les: {DEFAULT_MODELS_DIR}")
    logger.info(f"Chemin du mod√®le Gemma: {GEMMA_MODEL_PATH}")
    logger.info(f"R√©pertoire des fichiers MT5: {MT5_FILES_DIR}")
    
except Exception as e:
    logger.error(f"Erreur lors de la configuration des r√©pertoires: {e}")
    raise

try:
    import torch
    from transformers import AutoProcessor, AutoModelForImageTextToText, AutoModelForCausalLM
    print(f"Chargement du mod√®le Gemma depuis {GEMMA_MODEL_PATH}...")
    # Chargement conditionnel pour ne pas bloquer si les libs manquent ou le chemin est faux
    if os.path.exists(GEMMA_MODEL_PATH):
        try:
            # Chargement du processeur et du mod√®le en mode texte uniquement
            gemma_processor = AutoProcessor.from_pretrained(GEMMA_MODEL_PATH)
            gemma_model = AutoModelForCausalLM.from_pretrained(
                GEMMA_MODEL_PATH,
                torch_dtype=torch.float16,
                load_in_8bit=True,
                device_map="auto"
            )
            print("Mod√®le Gemma (Texte seul) charg√© avec succ√®s !")

            GEMMA_AVAILABLE = True
        except Exception as load_err:
             print(f"Erreur interne chargement Gemma: {load_err}")
             GEMMA_AVAILABLE = False
    else:
        print(f"Chemin du mod√®le introuvable: {GEMMA_MODEL_PATH}")
except Exception as e:
    print(f"Impossible de charger le mod√®le Gemma: {e}")
    GEMMA_AVAILABLE = False


# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ai_server.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger("tradbot_ai")

# Machine Learning imports (Phase 2)
try:
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
    from sklearn.neural_network import MLPClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score
    ML_AVAILABLE = True
    logger.info("scikit-learn disponible - Phase 2 ML features activ√©es")
except ImportError:
    ML_AVAILABLE = False
    logger.warning("scikit-learn non disponible - Phase 2 ML features d√©sactiv√©es")

# Tentative d'importation de MetaTrader5 (optionnel)
try:
    import MetaTrader5 as mt5
    MT5_AVAILABLE = True
    logger.info("MetaTrader5 disponible")
except ImportError:
    MT5_AVAILABLE = False
    logger.info(
        "MetaTrader5 n'est pas install√© - "
        "le serveur fonctionnera en mode API uniquement (sans connexion MT5)"
    )

# Configuration Mistral AI (d√©sactiv√©e dans cette version d√©ploy√©e)
MISTRAL_AVAILABLE = False
mistral_client = None

# Gemini totalement d√©sactiv√© pour le d√©ploiement Render
GEMINI_AVAILABLE = False
gemini_model = None

# Alpha Vantage API pour analyse fondamentale
ALPHAVANTAGE_API_KEY = os.getenv("ALPHAVANTAGE_API_KEY", "IU9I5J595Q5LO61B")
ALPHAVANTAGE_AVAILABLE = bool(ALPHAVANTAGE_API_KEY)
if ALPHAVANTAGE_AVAILABLE:
    logger.info("Alpha Vantage API disponible pour analyse fondamentale")
else:
    logger.info("Alpha Vantage API: Non configur√© (ALPHAVANTAGE_API_KEY manquant)")

# Deriv API WebSocket pour donn√©es de march√© (fallback)
DERIV_APP_ID = os.getenv("DERIV_APP_ID", "1089")  # 1089 = test app_id
DERIV_API_TOKEN = os.getenv("DERIV_API_TOKEN", "")
DERIV_WS_URL = f"wss://ws.derivws.com/websockets/v3?app_id={DERIV_APP_ID}"
DERIV_AVAILABLE = True
logger.info(f"Deriv API WebSocket disponible (app_id: {DERIV_APP_ID})")

# Compteur de requ√™tes Alpha Vantage (limite: 25/jour gratuit)
alphavantage_request_count = 0
ALPHAVANTAGE_DAILY_LIMIT = 25

# Indicateur global de disponibilit√© du backend ML
BACKEND_AVAILABLE = False

# Indicateur global de disponibilit√© du backend ML
backend_available = False

# Tentative d'importation des modules backend (optionnel, mais non bloquant pour l'API)
sys.path.insert(0, str(Path(__file__).parent / "backend"))

# 1) Pr√©dicteurs avanc√©s (RandomForest, etc.) - facultatifs pour Render
try:
    from advanced_ml_predictor import AdvancedMLPredictor
    from spike_predictor import AdvancedSpikePredictor
    from backend.mt5_connector import get_ohlc as get_historical_data
    logger.info("Pr√©dicteurs avanc√©s backend import√©s avec succ√®s")
except ImportError as e:
    AdvancedMLPredictor = None  # type: ignore
    AdvancedSpikePredictor = None  # type: ignore
    get_historical_data = None  # type: ignore
    logger.warning(f"Pr√©dicteurs avanc√©s non disponibles (ceci est non bloquant pour Render): {e}")

# 2) Router adaptatif multi‚Äëactifs (XGBoost) charg√© directement depuis backend/adaptive_predict.py
try:
    import importlib.util
    adaptive_predict_path = Path(__file__).parent / "backend" / "adaptive_predict.py"
    if adaptive_predict_path.exists():
        spec = importlib.util.spec_from_file_location("adaptive_predict", adaptive_predict_path)
        adaptive_predict_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(adaptive_predict_module)  # type: ignore
        predict_adaptive = adaptive_predict_module.predict_adaptive
        get_symbol_category = adaptive_predict_module.get_symbol_category
        ADAPTIVE_PREDICT_AVAILABLE = True
        logger.info("Module adaptive_predict charg√© directement (mod√®les multi-actifs)")
    else:
        raise ImportError(f"Fichier adaptive_predict.py non trouv√©: {adaptive_predict_path}")
except Exception as e:
    predict_adaptive = None  # type: ignore
    get_symbol_category = None  # type: ignore
    ADAPTIVE_PREDICT_AVAILABLE = False
    logger.warning(f"Module adaptive_predict non disponible: {e}")

# 3) D√©tecteur de spikes ML (facultatif)
try:
    from backend.spike_detector import predict_spike_ml, detect_spikes, get_realtime_spike_analysis
    SPIKE_DETECTOR_AVAILABLE = True
    logger.info("Module spike_detector disponible")
except ImportError as e:
    SPIKE_DETECTOR_AVAILABLE = False
    logger.warning(f"Module spike_detector non disponible: {e}")

# 4) Syst√®me d'apprentissage continu (feedback loop)
try:
    from backend.continuous_learning import ContinuousLearning
    CONTINUOUS_LEARNING_AVAILABLE = True
    # Initialiser le syst√®me d'apprentissage continu
    continuous_learner = ContinuousLearning(
        min_new_samples=50,  # Minimum 50 trades pour r√©entra√Æner
        retrain_interval_days=1,  # R√©entra√Æner au moins une fois par jour
        db_url=DATABASE_URL
    )
    logger.info("‚úÖ Module continuous_learning charg√© avec succ√®s")
except ImportError as e:
    ContinuousLearning = None  # type: ignore
    continuous_learner = None
    CONTINUOUS_LEARNING_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è Module continuous_learning non disponible: {e}")

# Le backend ML est consid√©r√© comme disponible si au moins l'un des modules cl√©s est pr√™t
if ADAPTIVE_PREDICT_AVAILABLE or SPIKE_DETECTOR_AVAILABLE:
    BACKEND_AVAILABLE = True
    logger.info("Modules backend disponibles (BACKEND_AVAILABLE = True)")
else:
    BACKEND_AVAILABLE = False
    logger.warning("Aucun module backend ML disponible (BACKEND_AVAILABLE = False)")

# Import du d√©tecteur avanc√© depuis ai_server_improvements
try:
    from ai_server_improvements import (
        AdvancedSpikeDetector,
        calculate_advanced_entry_score,
        calculate_momentum_score,
        detect_divergence,
        detect_candle_patterns
    )
    ADVANCED_SPIKE_DETECTOR_AVAILABLE = True
    ADVANCED_ENTRY_SCORING_AVAILABLE = True
    advanced_spike_detector = AdvancedSpikeDetector()
    logger.info("AdvancedSpikeDetector et syst√®me de scoring avanc√© initialis√©s")
except ImportError as e:
    ADVANCED_SPIKE_DETECTOR_AVAILABLE = False
    ADVANCED_ENTRY_SCORING_AVAILABLE = False
    advanced_spike_detector = None
    calculate_advanced_entry_score = None
    calculate_momentum_score = None
    detect_divergence = None
    detect_candle_patterns = None
    logger.warning(f"AdvancedSpikeDetector et scoring avanc√© non disponibles: {e}")

# Tentative d'importation de ai_indicators
try:
    sys.path.insert(0, str(Path(__file__).parent / "python"))
    from ai_indicators import AdvancedIndicators, analyze_market_data
    AI_INDICATORS_AVAILABLE = True
    logger.info("Module ai_indicators disponible")
except ImportError as e:
    AI_INDICATORS_AVAILABLE = False
    logger.warning(f"Module ai_indicators non disponible: {e}")
    AdvancedIndicators = None
    analyze_market_data = None

# Tentative d'importation des outils de r√®gles d'association (optionnel)
try:
    sys.path.insert(0, str(Path(__file__).parent / "python"))
    from association_mining import mine_rules_for_symbol  # type: ignore
    ASSOCIATION_MINING_AVAILABLE = True
except Exception as e:
    ASSOCIATION_MINING_AVAILABLE = False
    logger.warning(f"association_mining non disponible (facultatif) : {e}")

# R√®gles d'association pr√©-calcul√©es (charg√©es depuis JSON si dispo)
ASSOCIATION_RULES: Dict[str, List[Dict[str, Any]]] = {}
ASSOCIATION_RULES_PATH = Path(__file__).parent / "association_rules.json"


def load_association_rules() -> None:
    """Charge des r√®gles d'association pr√©-calcul√©es depuis un JSON (facultatif)."""
    global ASSOCIATION_RULES
    if not ASSOCIATION_RULES_PATH.exists():
        logger.info("Aucune r√®gle d'association trouv√©e (association_rules.json manquant)")
        ASSOCIATION_RULES = {}
        return

    try:
        with ASSOCIATION_RULES_PATH.open("r", encoding="utf-8") as f:
            data = json.load(f)
        if isinstance(data, dict):
            ASSOCIATION_RULES = data
            logger.info(
                "R√®gles d'association charg√©es pour symboles: %s",
                ", ".join(ASSOCIATION_RULES.keys()),
            )
        else:
            logger.warning("Format de association_rules.json invalide (dict attendu)")
            ASSOCIATION_RULES = {}
    except Exception as e:
        logger.error(f"Erreur chargement association_rules.json: {e}", exc_info=True)
        ASSOCIATION_RULES = {}


def build_items_from_request(req: "DecisionRequest") -> Set[str]:
    """
    Construit un ensemble d'items (bool√©ens) √† partir de la requ√™te courante.
    Doit rester coh√©rent avec la logique utilis√©e pour miner les r√®gles.
    """
    items: Set[str] = set()

    # Type de symbole (Boom/Crash/Volatility/Forex)
    sym = req.symbol or ""
    s_low = sym.lower()
    if "boom" in s_low:
        items.add("sym_boom")
    if "crash" in s_low:
        items.add("sym_crash")
    if "volatility" in s_low:
        items.add("sym_volatility")

    # RSI
    if req.rsi is not None:
        if req.rsi < 30:
            items.add("rsi_low")
        elif req.rsi > 70:
            items.add("rsi_high")

    # EMA H1
    if req.ema_fast_h1 is not None and req.ema_slow_h1 is not None:
        if req.ema_fast_h1 > req.ema_slow_h1:
            items.add("trend_up_H1")
        elif req.ema_fast_h1 < req.ema_slow_h1:
            items.add("trend_down_H1")

    # EMA M1 (via dir_rule si disponible)
    # dir_rule: 1=BUY, -1=SELL, 0=neutre (d√©fini c√¥t√© EA)
    if req.dir_rule == 1:
        items.add("trend_up_M1_rule")
    elif req.dir_rule == 0:
        items.add("trend_down_M1_rule")

    return items


def adjust_decision_with_rules(
    symbol: str,
    action: str,
    confidence: float,
    base_reason: str,
    items: Set[str],
) -> Tuple[str, float, str]:
    """
    Ajuste (l√©g√®rement) l'action / la confiance en fonction des r√®gles d'association pr√©-calcul√©es.

    - Si une r√®gle pour ce symbole (ou '*') avec consequent 'trade_win' a ses items inclus dans
      l'√©tat courant, et que cette r√®gle est coh√©rente avec l'action (BUY/SELL),
      la confiance est augment√©e l√©g√®rement.
    - L'impact est volontairement mod√©r√© pour ne pas casser la logique principale.
    """
    if not ASSOCIATION_RULES:
        return action, confidence, base_reason

    rules_for_symbol: List[Dict[str, Any]] = []
    if symbol in ASSOCIATION_RULES:
        rules_for_symbol.extend(ASSOCIATION_RULES[symbol])
    if "*" in ASSOCIATION_RULES:
        rules_for_symbol.extend(ASSOCIATION_RULES["*"])

    if not rules_for_symbol:
        return action, confidence, base_reason

    bonus = 0.0
    applied_rules: List[str] = []

    for r in rules_for_symbol:
        antecedent = set(r.get("antecedent", []))
        if not antecedent:
            continue
        if not antecedent.issubset(items):
            continue

        conf = float(r.get("confidence", 0.0))
        lift = float(r.get("lift", 1.0) or 1.0)

        if action != "hold" and conf >= 0.7 and lift >= 1.0:
            bonus += min((conf - 0.5) * 0.1, 0.05)  # max +0.05 par r√®gle
            rule_str = (
                f"{','.join(sorted(antecedent))} "
                f"(conf={conf:.2f},lift={lift:.2f})"
            )
            applied_rules.append(rule_str)

    if bonus != 0.0:
        new_conf = max(0.0, min(1.0, confidence + bonus))
        reason = base_reason
        if applied_rules:
            reason = f"{base_reason} | R√®glesAssoc:+{bonus:.2f} via {len(applied_rules)} r√®gle(s)"
        return action, new_conf, reason

    return action, confidence, base_reason

# Charger les √©ventuelles r√®gles d'association au d√©marrage
load_association_rules()

# Configuration de l'application
app = FastAPI(
    title="TradBOT AI Server",
    description="API de pr√©diction et d'analyse pour le robot de trading TradBOT",
    version="2.0.0"
)

# Configuration CORS pour permettre les requ√™tes depuis MT5
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Middleware pour logger toutes les requ√™tes entrantes
@app.middleware("http")
async def log_requests(request: Request, call_next):
    """Log toutes les requ√™tes entrantes pour debugging"""
    start_time = time.time()
    
    # Logger le path et la m√©thode avec INFO pour √™tre visible dans les logs Render
    logger.info(f"üì• {request.method} {request.url.path}")
    
    response = await call_next(request)
    
    process_time = time.time() - start_time
    # Logger toutes les r√©ponses avec INFO pour √™tre visible dans les logs Render
    if process_time > 1.0 or response.status_code >= 400:
        logger.warning(f"‚ö†Ô∏è {request.method} {request.url.path} - {response.status_code} - Temps: {process_time:.3f}s")
    else:
        logger.info(f"üì§ {request.method} {request.url.path} - {response.status_code} - Temps: {process_time:.3f}s")
    
    return response

# ===== POSTGRESQL CONNECTION POOL FOR FEEDBACK LOOP =====
async def get_db_pool():
    """Get or create database connection pool"""
    if not hasattr(app.state, "db_pool"):
        if not DB_AVAILABLE:
            logger.warning(
        "PostgreSQL non disponible - "
        "DATABASE_URL manquant ou asyncpg non install√©"
    )
            return None
        try:
            # Pour Render PostgreSQL, il faut ajouter SSL
            # Parse la DATABASE_URL pour ajouter sslmode si n√©cessaire
            dsn = DATABASE_URL
            if "render.com" in DATABASE_URL.lower() and "sslmode" not in DATABASE_URL.lower():
                # Ajouter sslmode=require pour Render PostgreSQL
                separator = "?" if "?" not in dsn else "&"
                dsn = f"{dsn}{separator}sslmode=require"
                logger.info("üìù Ajout de sslmode=require pour Render PostgreSQL")
            
            app.state.db_pool = await asyncpg.create_pool(
                dsn=dsn,
                min_size=1,
                max_size=5,
                command_timeout=30,  # Timeout r√©duit √† 30s
                server_settings={
                    'application_name': 'tradbot_ai_server'
                }
            )
            logger.info("‚úÖ Pool de connexions PostgreSQL cr√©√©")
        except asyncio.TimeoutError:
            logger.error(
        "‚ùå Timeout lors de la cr√©ation du pool PostgreSQL - "
        "V√©rifiez la connexion r√©seau"
    )
            app.state.db_pool = None
            return None
        except Exception as e:
            logger.error(f"‚ùå Erreur cr√©ation pool PostgreSQL: {e}", exc_info=True)
            app.state.db_pool = None
            return None
    return app.state.db_pool

# SQL pour cr√©er la table de feedback
CREATE_FEEDBACK_TABLE_SQL = """
CREATE TABLE IF NOT EXISTS trade_feedback (
    id SERIAL PRIMARY KEY,
    symbol TEXT NOT NULL,
    open_time TIMESTAMPTZ NOT NULL,
    close_time TIMESTAMPTZ NOT NULL,
    entry_price DOUBLE PRECISION NOT NULL,
    exit_price DOUBLE PRECISION NOT NULL,
    profit DOUBLE PRECISION NOT NULL,
    ai_confidence DOUBLE PRECISION,
    coherent_confidence DOUBLE PRECISION,
    decision TEXT NOT NULL,
    is_win BOOLEAN NOT NULL,
    created_at TIMESTAMPTZ DEFAULT now()
);

CREATE INDEX IF NOT EXISTS idx_trade_feedback_symbol ON trade_feedback(symbol);
CREATE INDEX IF NOT EXISTS idx_trade_feedback_created_at ON trade_feedback(created_at DESC);
"""

@app.on_event("startup")
async def startup_event():
    """Initialize database on startup"""
    if not DB_AVAILABLE:
        logger.info("üìä Mode sans PostgreSQL - feedback loop d√©sactiv√©")
    
    try:
        pool = await get_db_pool()
        if pool:
            async with pool.acquire() as conn:
                await conn.execute(CREATE_FEEDBACK_TABLE_SQL)
                logger.info("‚úÖ Table trade_feedback cr√©√©e/v√©rifi√©e")
    except Exception as e:
        logger.error(f"‚ùå Erreur initialisation base de donn√©es: {e}", exc_info=True)
    
    # Entra√Æner automatiquement les mod√®les ML pour les symboles principaux
    await train_models_on_startup()

@app.on_event("shutdown")
async def shutdown_event():
    """Close database pool on shutdown"""
    if hasattr(app.state, "db_pool") and app.state.db_pool:
        await app.state.db_pool.close()
        logger.info("üîí Pool PostgreSQL ferm√©")


async def train_models_on_startup():
    """
    Entra√Æne automatiquement les mod√®les ML pour les symboles principaux en arri√®re-plan
    Version optimis√©e pour √©viter les timeouts de d√©ploiement
    """
    # V√©rifier la variable d'environnement pour d√©sactiver l'entra√Ænement
    disable_training = os.getenv("DISABLE_ML_TRAINING", "false").lower() == "true"
    
    if disable_training:
        logger.info("‚ö†Ô∏è Entra√Ænement ML d√©sactiv√© via DISABLE_ML_TRAINING=true")
        return
    
    logger.info("üöÄ Planification de l'entra√Ænement automatique des mod√®les ML en arri√®re-plan...")
    
    if not ML_TRAINER_AVAILABLE:
        logger.warning("‚ö†Ô∏è integrated_ml_trainer non disponible - entra√Ænement ML d√©sactiv√©")
        return
    
    # D√©marrer l'entra√Ænement en arri√®re-plan pour ne pas bloquer le d√©marrage
    asyncio.create_task(train_models_background())
    
    logger.info("‚úÖ Entra√Ænement des mod√®les ML planifi√© en arri√®re-plan - Le serveur est pr√™t")

async def train_models_background():
    """
    Entra√Æne les mod√®les ML en arri√®re-plan apr√®s le d√©marrage du serveur
    """
    # Attendre que le serveur soit compl√®tement d√©marr√©
    await asyncio.sleep(5)  # Attendre 5 secondes
    
    logger.info("üîÑ D√©but de l'entra√Ænement des mod√®les ML en arri√®re-plan...")
    
    # Symboles principaux √† entra√Æner automatiquement (r√©duit pour acc√©l√©rer)
    priority_symbols = [
        "EURUSD", "GBPUSD",  # Forex majeurs uniquement
        "Boom 300 Index", "Boom 600 Index"  # Boom principaux uniquement
    ]
    
    timeframes = ["M1", "M5"]  # Timeframes r√©duits
    
    total_training_tasks = len(priority_symbols) * len(timeframes)
    completed_tasks = 0
    
    models_dir = getattr(ml_trainer, "models_dir", "models") if ML_TRAINER_AVAILABLE else "models"
    
    for symbol in priority_symbols:
        for timeframe in timeframes:
            try:
                model_key = f"{symbol}_{timeframe}"
                model_path = os.path.join(models_dir, f"{model_key}_rf.joblib")
                if os.path.exists(model_path):
                    logger.info(f"‚úÖ Mod√®le d√©j√† existant pour {model_key}")
                    completed_tasks += 1
                    continue
                
                logger.info(f"üìä Entra√Ænement du mod√®le pour {symbol} {timeframe}...")
                
                try:
                    if not ML_TRAINER_AVAILABLE:
                        logger.warning(f"‚ö†Ô∏è integrated_ml_trainer non disponible - skip {model_key}")
                        continue
                    df = await asyncio.wait_for(
                        ml_trainer.fetch_training_data_simple(symbol, timeframe),
                        timeout=30.0
                    )
                    if df is None or len(df) < ml_trainer.min_samples_for_retraining:
                        logger.debug(f"Donn√©es insuffisantes pour {model_key}")
                        continue
                    train_result = await asyncio.wait_for(
                        asyncio.to_thread(ml_trainer.train_model_simple, df, symbol, timeframe),
                        timeout=60.0
                    )
                    if train_result:
                        logger.info(f"‚úÖ Mod√®le entra√Æn√© avec succ√®s pour {model_key}")
                        completed_tasks += 1
                        
                except asyncio.TimeoutError:
                    logger.warning(f"‚è∞ Timeout entra√Ænement {symbol} {timeframe} - Passage au suivant")
                    continue
                
            except Exception as e:
                logger.error(f"‚ùå Erreur entra√Ænement mod√®le {symbol} {timeframe}: {e}")
    
    logger.info(f"üéØ Entra√Ænement en arri√®re-plan termin√©: {completed_tasks}/{total_training_tasks} mod√®les entra√Æn√©s")


# Parser les arguments en ligne de commande
parser = argparse.ArgumentParser(description='Serveur AI TradBOT')
parser.add_argument('--port', type=int, default=8000, help='Port sur lequel d√©marrer le serveur')
parser.add_argument(
    '--host', 
    type=str, 
    default='127.0.0.1', 
    help='Adresse IP sur laquelle √©couter'
)
args = parser.parse_args()

# Variables globales
API_PORT = int(os.getenv('API_PORT', args.port))
HOST = os.getenv('HOST', args.host)
CACHE_DURATION = 30  # secondes
# Dossiers de pr√©dictions / m√©triques MT5
RUNNING_ON_RENDER = bool(os.getenv("RENDER") or os.getenv("RENDER_SERVICE_ID"))

if RUNNING_ON_SUPABASE:
    # Sur Render, on utilise le dossier temporaire par d√©faut
    # qui est garanti d'√™tre accessible en √©criture
    # On utilise /tmp/ comme racine pour les donn√©es et mod√®les
    DATA_DIR = Path("/tmp/data")
    MODELS_DIR = Path("/tmp/models")
    
    # Cr√©er les r√©pertoires s'ils n'existent pas
    os.makedirs(DATA_DIR, exist_ok=True)
    os.makedirs(MODELS_DIR, exist_ok=True)
    
    logger.info(f"Mode Render activ√© - Utilisation des dossiers temporaires:")
    logger.info(f"- Donn√©es: {DATA_DIR}")
    logger.info(f"- Mod√®les: {MODELS_DIR}")
    
    # Liste des dossiers √† cr√©er dans DATA_DIR
    required_dirs = ["mt5_files", "predictions", "metrics"]
    for dir_name in required_dirs:
        dir_path = DATA_DIR / dir_name
        os.makedirs(dir_path, exist_ok=True)
        logger.info(f"Cr√©√© le r√©pertoire: {dir_path}")
    
    # Chercher un r√©pertoire accessible en √©criture
    possible_roots = [
        "/tmp",
        "/var/tmp",
        "/opt/render/project/src",
        str(Path.home()),
        ".",
    ]
    selected_root = "."  # Valeur par d√©faut
    for root_dir in possible_roots:
        test_dir = Path(root_dir)
        test_file = test_dir / ".write_test"
        try:
            test_dir.mkdir(parents=True, exist_ok=True)
            with open(test_file, 'w') as f:
                f.write("test")
            os.remove(test_file)
            selected_root = root_dir
            logger.info(f"R√©pertoire accessible en √©criture trouv√©: {test_dir}")
            break
        except Exception as e:
            logger.debug(f"Impossible d'√©crire dans {test_dir}: {e}")
    
    # D√©finir les chemins des dossiers
    base_dir = Path(selected_root)
    DATA_DIR = base_dir / "data"
    MODELS_DIR = base_dir / "models"
    
    # Cr√©er les dossiers avec gestion d'erreur
    try:
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        MODELS_DIR.mkdir(parents=True, exist_ok=True)
        logger.info(f"Dossiers configur√©s: DATA_DIR={DATA_DIR}, MODELS_DIR={MODELS_DIR}")
    except Exception as e:
        logger.error(f"Erreur critique: Impossible de cr√©er les dossiers n√©cessaires: {e}")
        raise
else:
    # Mode d√©veloppement local
    DATA_DIR = Path("data")
    MODELS_DIR = Path("models")

LOG_FILE = Path("ai_server.log")
FEEDBACK_FILE = DATA_DIR / "trade_feedback.jsonl"

if RUNNING_ON_SUPABASE:
    # Mode cloud: tout est stock√© dans le r√©pertoire data/ du serveur
    MT5_PREDICTIONS_DIR = DATA_DIR / "Predictions"
    MT5_RESULTS_DIR = DATA_DIR / "Results"
else:
    # Mode local: utiliser les chemins Windows partag√©s avec MT5
    # Exemple fourni par l'utilisateur :
    # C:\Users\USER\AppData\Roaming\MetaQuotes\Terminal\Common\Files\Predictions
    MT5_PREDICTIONS_DIR = Path(
        r"C:\Users\USER\AppData\Roaming\MetaQuotes\Terminal\Common\Files\Predictions"
    )
    # Dossier pour sauvegarder les m√©triques de pr√©diction
    MT5_RESULTS_DIR = Path(
        r"C:\Users\USER\AppData\Roaming\MetaQuotes\Terminal\Common\Files\Results"
    )
try:
    MT5_PREDICTIONS_DIR.mkdir(parents=True, exist_ok=True)
    MT5_RESULTS_DIR.mkdir(parents=True, exist_ok=True)
except Exception as _e:
    # On log uniquement en warning, le serveur peut continuer sans ce stockage
    logging.getLogger("tradbot_ai").warning(
        f"Impossible de cr√©er le dossier de pr√©dictions/r√©sultats MT5: {_e}"
    )
DEFAULT_SYMBOL = "Volatility 75 Index"

# Cr√©ation des r√©pertoires si n√©cessaire
for directory in [DATA_DIR, MODELS_DIR]:
    directory.mkdir(exist_ok=True)

# Cache pour les pr√©dictions
prediction_cache = {}
last_updated = {}

# ===== SYST√àME DE D√âTECTION DE MOUVEMENT EN TEMPS R√âEL =====
# Suivi des prix pour d√©tecter les mouvements haussiers/baissiers en temps r√©el
# {symbol: [{"price": float, "timestamp": float}]}
realtime_price_history: Dict[str, List[Dict[str, float]]] = {}
MAX_PRICE_HISTORY = 10  # Garder les 10 derniers prix
MIN_PRICE_CHANGE_PERCENT = 0.05  # 0.05% de changement minimum pour d√©tecter un mouvement
REALTIME_MOVEMENT_WINDOW = 30  # Fen√™tre de 30 secondes pour d√©tecter un mouvement

def detect_realtime_movement(symbol: str, current_price: float) -> Dict[str, Any]:
    """
    D√©tecte les mouvements de prix en temps r√©el (haussier/baissier)
    
    Args:
        symbol: Symbole du march√©
        current_price: Prix actuel (mid_price)
        
    Returns:
        Dict avec 'direction' ('up', 'down', 'neutral'), 'strength' (0-1), 'price_change_percent'
    """
    current_time = datetime.now().timestamp()
    
    # Initialiser l'historique si n√©cessaire
    if symbol not in realtime_price_history:
        realtime_price_history[symbol] = []
    
    # Ajouter le prix actuel
    realtime_price_history[symbol].append({
        "price": current_price,
        "timestamp": current_time
    })
    
    # Garder seulement les prix r√©cents (derni√®res 30 secondes)
    cutoff_time = current_time - REALTIME_MOVEMENT_WINDOW
    realtime_price_history[symbol] = [
        p for p in realtime_price_history[symbol] 
        if p["timestamp"] >= cutoff_time
    ]
    
    # Limiter le nombre d'entr√©es
    if len(realtime_price_history[symbol]) > MAX_PRICE_HISTORY:
        realtime_price_history[symbol] = realtime_price_history[symbol][-MAX_PRICE_HISTORY:]
    
    history = realtime_price_history[symbol]
    
    # Besoin d'au moins 2 prix pour d√©tecter un mouvement
    if len(history) < 2:
        return {
            "direction": "neutral",
            "strength": 0.0,
            "price_change_percent": 0.0,
            "trend_consistent": False
        }
    
    # Calculer le changement de prix depuis le premier prix de la fen√™tre
    first_price = history[0]["price"]
    price_change = current_price - first_price
    price_change_percent = (price_change / first_price * 100) if first_price > 0 else 0.0
    
    # Calculer la tendance (combien de mouvements sont dans la m√™me direction)
    up_moves = 0
    down_moves = 0
    for i in range(1, len(history)):
        if history[i]["price"] > history[i-1]["price"]:
            up_moves += 1
        elif history[i]["price"] < history[i-1]["price"]:
            down_moves += 1
    
    # D√©terminer la direction
    if abs(price_change_percent) >= MIN_PRICE_CHANGE_PERCENT:
        if price_change_percent > 0:
            direction = "up"
            strength = min(abs(price_change_percent) / (MIN_PRICE_CHANGE_PERCENT * 2), 1.0)
        else:
            direction = "down"
            strength = min(abs(price_change_percent) / (MIN_PRICE_CHANGE_PERCENT * 2), 1.0)
    else:
        direction = "neutral"
        strength = 0.0
    
    # V√©rifier la coh√©rence de la tendance (au moins 60% des mouvements dans la m√™me direction)
    total_moves = up_moves + down_moves
    trend_consistent = False
    if total_moves > 0:
        if direction == "up" and up_moves / total_moves >= 0.6:
            trend_consistent = True
        elif direction == "down" and down_moves / total_moves >= 0.6:
            trend_consistent = True
    
    return {
        "direction": direction,
        "strength": strength,
        "price_change_percent": price_change_percent,
        "trend_consistent": trend_consistent,
        "up_moves": up_moves,
        "down_moves": down_moves
    }

# ===== CACHE POUR DONN√âES HISTORIQUES UPLOAD√âES DEPUIS MT5 =====
# Stockage des donn√©es historiques envoy√©es par MT5 via le bridge
# Format: {f"{symbol}_{timeframe}": {"data": DataFrame, "timestamp": datetime}}
mt5_uploaded_history_cache: Dict[str, Dict[str, Any]] = {}
MT5_HISTORY_CACHE_TTL = 300  # TTL de 5 minutes (les donn√©es sont rafra√Æchies r√©guli√®rement)

# ===== SYST√àME DE VALIDATION ET CALIBRATION DES PR√âDICTIONS =====
# Stockage des pr√©dictions historiques pour validation
prediction_history: Dict[str, List[Dict[str, Any]]] = {}  # {symbol: [predictions]}
PREDICTION_VALIDATION_FILE = DATA_DIR / "prediction_validation.json"
MIN_VALIDATION_BARS = 10  # Minimum 10 bougies pour valider
MIN_ACCURACY_THRESHOLD = 0.55  # lowered from 60% to 55%  # Seuil minimum de pr√©cision (60%)
MAX_HISTORICAL_PREDICTIONS = 100  # Maximum 100 pr√©dictions par symbole

def load_prediction_history():
    """Charge l'historique des pr√©dictions depuis le fichier"""
    global prediction_history
    if PREDICTION_VALIDATION_FILE.exists():
        try:
            with open(PREDICTION_VALIDATION_FILE, 'r', encoding='utf-8') as f:
                prediction_history = json.load(f)
            pred_count = sum(len(v) for v in prediction_history.values())
            logger.info(f"‚úÖ Historique des pr√©dictions charg√©: {pred_count} pr√©dictions")
        except Exception as e:
            logger.warning(f"Erreur chargement historique pr√©dictions: {e}")
            prediction_history = {}

def save_prediction_history():
    """Sauvegarde l'historique des pr√©dictions dans le fichier"""
    try:
        with open(PREDICTION_VALIDATION_FILE, 'w', encoding='utf-8') as f:
            json.dump(prediction_history, f, indent=2, ensure_ascii=False)
    except Exception as e:
        logger.error(f"Erreur sauvegarde historique pr√©dictions: {e}")

def store_prediction(
    symbol: str, 
    predicted_prices: List[float], 
    current_price: float, 
    timeframe: str
):
    """Stocke une pr√©diction pour validation future"""
    if symbol not in prediction_history:
        prediction_history[symbol] = []
    
    prediction_id = f"{symbol}_{datetime.now().timestamp()}"
    prediction = {
        "id": prediction_id,
        "timestamp": datetime.now().isoformat(),
        "predicted_prices": predicted_prices,
        "current_price": current_price,
        "timeframe": timeframe,
        "bars_predicted": len(predicted_prices),
        "accuracy_score": None,
        "is_validated": False,
        "validation_timestamp": None
    }
    
    prediction_history[symbol].append(prediction)
    
    # Limiter le nombre de pr√©dictions stock√©es
    if len(prediction_history[symbol]) > MAX_HISTORICAL_PREDICTIONS:
        prediction_history[symbol] = prediction_history[symbol][-MAX_HISTORICAL_PREDICTIONS:]
    
    save_prediction_history()
    
    # Mettre √† jour le cache temps r√©el
    cache_key = f"{symbol}_{timeframe}"
    accuracy_score = get_prediction_accuracy_score(symbol)
    realtime_predictions[cache_key] = {
        "symbol": symbol,
        "timeframe": timeframe,
        "timestamp": prediction["timestamp"],
        "predicted_prices": predicted_prices[:50],  # Limiter pour la r√©ponse
        "current_price": current_price,
        "accuracy_score": round(accuracy_score, 3),
        "validation_count": sum(1 for p in prediction_history[symbol] if p.get("is_validated", False)),
        "reliability": (
            "HIGH" if accuracy_score >= 0.80 
            else "MEDIUM" if accuracy_score >= 0.60 
            else "LOW"
        )
    }

def calculate_prediction_accuracy(
    predicted_prices: List[float], 
    real_prices: List[float]
) -> float:
    """Calcule la pr√©cision d'une pr√©diction en comparant avec les prix r√©els"""
    if len(predicted_prices) == 0 or len(real_prices) == 0:
        return 0.0
    
    min_len = min(len(predicted_prices), len(real_prices))
    if min_len < MIN_VALIDATION_BARS:
        return 0.0
    
    total_error = 0.0
    valid_comparisons = 0
    
    for i in range(min_len):
        if predicted_prices[i] > 0 and real_prices[i] > 0:
            # Calculer l'erreur relative en pourcentage
            error_percent = abs(predicted_prices[i] - real_prices[i]) / real_prices[i]
            total_error += error_percent
            valid_comparisons += 1
    
    if valid_comparisons < MIN_VALIDATION_BARS:
        return 0.0
    
    # Calculer l'erreur moyenne
    avg_error = total_error / valid_comparisons
    
    # Convertir en score de pr√©cision (0.0 = 0% pr√©cision, 1.0 = 100% pr√©cision)
    # Erreur de 10% = pr√©cision 0%
    accuracy = 1.0 - min(avg_error * 10.0, 1.0)
    
    return max(0.0, min(1.0, accuracy))

def validate_predictions(symbol: str, timeframe: str = "M1"):
    """Valide les pr√©dictions pass√©es en comparant avec les prix r√©els"""
    if symbol not in prediction_history:
        return
    
    if not MT5_AVAILABLE or not mt5_initialized:
        return
    
    try:
        import MetaTrader5 as mt5_module
        period_map = {
            "M1": mt5_module.TIMEFRAME_M1,
            "M5": mt5_module.TIMEFRAME_M5,
            "M15": mt5_module.TIMEFRAME_M15,
            "H1": mt5_module.TIMEFRAME_H1,
            "H4": mt5_module.TIMEFRAME_H4,
            "D1": mt5_module.TIMEFRAME_D1
        }
        period = period_map.get(timeframe, mt5_module.TIMEFRAME_M1)
        
        validated_count = 0
        total_accuracy = 0.0
        
        for pred in prediction_history[symbol]:
            if pred["is_validated"]:
                continue
            
            # Calculer combien de bougies se sont √©coul√©es
            pred_time = datetime.fromisoformat(pred["timestamp"])
            elapsed_minutes = (datetime.now() - pred_time).total_seconds() / 60
            
            if elapsed_minutes < MIN_VALIDATION_BARS:
                continue  # Pas assez de temps √©coul√©
            
            # R√©cup√©rer les prix r√©els
            bars_to_get = min(int(elapsed_minutes), pred["bars_predicted"])
            rates = mt5_module.copy_rates_from_pos(symbol, period, 0, bars_to_get)
            
            if rates is None or len(rates) < MIN_VALIDATION_BARS:
                continue
            
            # Extraire les prix r√©els (en ordre chronologique)
            real_prices = [rate['close'] for rate in reversed(rates[:bars_to_get])]
            predicted_prices = pred["predicted_prices"][:len(real_prices)]
            
            # Calculer la pr√©cision
            accuracy = calculate_prediction_accuracy(predicted_prices, real_prices)
            
            if accuracy > 0.0:
                pred["accuracy_score"] = accuracy
                pred["is_validated"] = True
                pred["validation_timestamp"] = datetime.now().isoformat()
                total_accuracy += accuracy
                validated_count += 1
                
                logger.info(f"‚úÖ Pr√©diction valid√©e pour {symbol}: Pr√©cision = {accuracy*100:.1f}%")
        
        if validated_count > 0:
            save_prediction_history()
            avg_accuracy = total_accuracy / validated_count
            logger.info(f"üìä Pr√©cision moyenne pour {symbol}: {avg_accuracy*100:.1f}% ({validated_count} validations)")
            
    except Exception as e:
        logger.error(f"Erreur validation pr√©dictions pour {symbol}: {e}")

def get_prediction_accuracy_score(symbol: str) -> float:
    """Retourne le score de pr√©cision moyen pour un symbole"""
    if symbol not in prediction_history:
        return 0.5  # Score neutre si pas de donn√©es
    
    validated = [
        p for p in prediction_history[symbol] 
        if p.get("is_validated") and p.get("accuracy_score") is not None
    ]
    
    if len(validated) == 0:
        return 0.5  # Score neutre si pas de validations
    
    total_accuracy = sum(p["accuracy_score"] for p in validated)
    return total_accuracy / len(validated)

def get_prediction_confidence_multiplier(symbol: str) -> float:
    """Retourne un multiplicateur de confiance bas√© sur la pr√©cision historique"""
    accuracy = get_prediction_accuracy_score(symbol)
    
    if accuracy >= 0.80:
        return 1.0  # Confiance normale
    elif accuracy >= 0.60:
        return 0.8  # R√©duire confiance de 20%
    elif accuracy >= 0.40:
        return 0.5  # R√©duire confiance de 50%
    else:
        return 0.3  # Tr√®s faible pr√©cision


# ===== CALIBRATION ADAPTATIVE (r√©duction d√©calage pr√©diction/mouvement r√©el) =====
# Stockage persistant de la calibration par symbole (drift, pr√©cision, ajustements)
CALIBRATION_FILE = DATA_DIR / "symbol_calibration.json"
_symbol_calibration: Dict[str, Dict[str, Any]] = {}
_calibration_loaded = False

def _ensure_calibration_loaded():
    """Charge la calibration depuis le fichier au premier acc√®s"""
    global _symbol_calibration, _calibration_loaded
    if not _calibration_loaded and CALIBRATION_FILE.exists():
        try:
            with open(CALIBRATION_FILE, "r", encoding="utf-8") as f:
                _symbol_calibration.update(json.load(f))
            _calibration_loaded = True
            logger.info(f"‚úÖ Calibration charg√©e: {len(_symbol_calibration)} symboles")
        except Exception as e:
            logger.warning(f"Erreur chargement calibration: {e}")
            _calibration_loaded = True

def _save_calibration():
    """Sauvegarde la calibration sur disque"""
    try:
        CALIBRATION_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(CALIBRATION_FILE, "w", encoding="utf-8") as f:
            json.dump(_symbol_calibration, f, indent=2, ensure_ascii=False)
    except Exception as e:
        logger.warning(f"Erreur sauvegarde calibration: {e}")

def get_symbol_calibration(symbol: str, timeframe: str = "M1") -> Dict[str, Any]:
    """
    Retourne la calibration pour un symbole (ML feedback + pr√©diction accuracy).
    Utilis√© par /decision pour ajuster confiance et r√©duire le d√©calage.
    """
    _ensure_calibration_loaded()
    cal = _symbol_calibration.get(symbol, {})
    pred_acc = get_prediction_accuracy_score(symbol)
    pred_mult = get_prediction_confidence_multiplier(symbol)
    # ML metrics (si disponible via _compute_ml_metrics)
    ml_min_conf = 0.60  # d√©faut
    try:
        ml = _compute_ml_metrics(symbol, timeframe)
        ml_min_conf = float(ml.get("recommendations", {}).get("min_confidence", 0.60))
    except Exception:
        pass
    return {
        "min_confidence": max(0.45, min(0.85, ml_min_conf)),
        "confidence_multiplier": pred_mult,
        "prediction_accuracy": pred_acc,
        "drift_factor": cal.get("drift_factor", 1.0),
        "last_updated": cal.get("last_updated"),
    }

def apply_calibration_to_decision(symbol: str, action: str, confidence: float, reason: str, timeframe: str = "M1") -> Tuple[str, float, str]:
    """
    Applique la calibration (feedback + pr√©diction) pour r√©duire le d√©calage.
    Ajuste la confiance et force HOLD si pr√©cision historique trop faible.
    """
    cal = get_symbol_calibration(symbol, timeframe)
    mult = cal["confidence_multiplier"]
    min_conf = cal["min_confidence"]
    pred_acc = cal["prediction_accuracy"]
    new_confidence = confidence * mult
    if action != "hold":
        if new_confidence < min_conf:
            return "hold", max(0.50, min_conf), f"{reason} | Calibration: conf ajust√©e ({pred_acc*100:.0f}% pr√©cision) ‚Üí hold"
        new_confidence = max(new_confidence, min_conf)
    return action, min(0.98, new_confidence), f"{reason} | Cal: x{mult:.2f}" if mult < 1.0 else reason

def update_calibration_from_feedback(symbol: str, is_win: bool, profit: float, side: str = ""):
    """Met √† jour la calibration apr√®s un feedback de trade (appel√© par /trades/feedback)"""
    _ensure_calibration_loaded()
    if symbol not in _symbol_calibration:
        _symbol_calibration[symbol] = {"wins": 0, "total": 0, "drift_factor": 1.0}
    c = _symbol_calibration[symbol]
    c["total"] = c.get("total", 0) + 1
    if is_win:
        c["wins"] = c.get("wins", 0) + 1
    win_rate = c["wins"] / c["total"] if c["total"] > 0 else 0.5
    # drift_factor: si win_rate bas, r√©duire la confiance future
    c["drift_factor"] = max(0.7, min(1.2, 0.8 + win_rate * 0.4))
    c["last_updated"] = datetime.now().isoformat()
    _save_calibration()

# Stockage des derni√®res pr√©dictions en temps r√©el
realtime_predictions: Dict[str, Dict[str, Any]] = {}  # {symbol: {prediction_data}}

def save_prediction_metrics(symbol: str, metrics: Dict[str, Any]):
    """Sauvegarde les m√©triques de pr√©diction dans le dossier Results"""
    try:
        safe_symbol = symbol.replace(" ", "_").replace("(", "").replace(")", "").replace("%", "")
        metrics_file = MT5_RESULTS_DIR / f"{safe_symbol}_metrics.json"
        
        # Charger les m√©triques existantes
        if metrics_file.exists():
            try:
                with open(metrics_file, 'r', encoding='utf-8') as f:
                    all_metrics = json.load(f)
            except:
                all_metrics = {"history": [], "summary": {}}
        else:
            all_metrics = {"history": [], "summary": {}}
        
        # Ajouter timestamp
        metrics["timestamp"] = datetime.now().isoformat()
        
        # Ajouter √† l'historique
        all_metrics["history"].append(metrics)
        
        # Garder seulement les 1000 derni√®res entr√©es
        if len(all_metrics["history"]) > 1000:
            all_metrics["history"] = all_metrics["history"][-1000:]
        
        # Calculer le r√©sum√©
        validated = [m for m in all_metrics["history"] if m.get("accuracy_score") is not None]
        if validated:
            accuracies = [m["accuracy_score"] for m in validated]
            all_metrics["summary"] = {
                "total_validations": len(validated),
                "average_accuracy": round(sum(accuracies) / len(accuracies), 3),
                "min_accuracy": round(min(accuracies), 3),
                "max_accuracy": round(max(accuracies), 3),
                "last_update": datetime.now().isoformat()
            }
        
        # Sauvegarder
        with open(metrics_file, 'w', encoding='utf-8') as f:
            json.dump(all_metrics, f, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úÖ M√©triques sauvegard√©es pour {symbol} dans {metrics_file}")
        
    except Exception as e:
        logger.error(f"Erreur sauvegarde m√©triques pour {symbol}: {e}")

def validate_prediction_with_realtime_data(
    symbol: str, 
    real_prices: List[float], 
    prediction_id: Optional[str] = None
) -> Dict[str, Any]:
    """Valide une pr√©diction avec les donn√©es r√©elles envoy√©es"""
    try:
        # V√©rifier que prediction_history est initialis√©
        global prediction_history
        if not isinstance(prediction_history, dict):
            prediction_history = {}
        
        # V√©rifier que real_prices est valide
        if not real_prices or not isinstance(real_prices, list):
            return {"error": "Liste de prix r√©els invalide ou vide"}
        
        if not all(isinstance(p, (int, float)) and p > 0 for p in real_prices):
            return {"error": "Les prix r√©els doivent √™tre des nombres positifs"}
        
        # Si prediction_id est fourni, chercher la pr√©diction sp√©cifique
        pred = None
        if prediction_id:
            if symbol not in prediction_history:
                return {"error": f"Aucune pr√©diction trouv√©e pour le symbole {symbol}"}
            for p in prediction_history[symbol]:
                if p.get("id") == prediction_id:
                    pred = p
                    break
            if not pred:
                return {"error": f"Pr√©diction avec l'ID {prediction_id} non trouv√©e"}
            if pred.get("is_validated"):
                return {"error": "Cette pr√©diction a d√©j√† √©t√© valid√©e"}
        else:
            # Prendre la derni√®re pr√©diction non valid√©e
            if symbol not in prediction_history or not prediction_history[symbol]:
                return {"error": f"Aucune pr√©diction √† valider pour le symbole {symbol}"}
            pred = prediction_history[symbol][-1]
            if pred.get("is_validated"):
                return {"error": "Toutes les pr√©dictions sont d√©j√† valid√©es"}
        
        # V√©rifier que la pr√©diction a les cl√©s n√©cessaires
        if not isinstance(pred, dict):
            return {"error": "Format de pr√©diction invalide"}
        
        if "predicted_prices" not in pred:
            return {"error": "La pr√©diction ne contient pas de prix pr√©dits"}
        
        predicted_prices = pred.get("predicted_prices", [])
        if not isinstance(predicted_prices, list) or len(predicted_prices) == 0:
            return {"error": "La liste des prix pr√©dits est vide ou invalide"}
        
        if not all(isinstance(p, (int, float)) and p > 0 for p in predicted_prices):
            return {"error": "Les prix pr√©dits doivent √™tre des nombres positifs"}
        
        min_len = min(len(predicted_prices), len(real_prices))
        
        if min_len < MIN_VALIDATION_BARS:
            return {"error": f"Pas assez de donn√©es (minimum {MIN_VALIDATION_BARS} bougies, re√ßu {min_len})"}
        
        # Calculer la pr√©cision
        try:
            accuracy = calculate_prediction_accuracy(predicted_prices[:min_len], real_prices[:min_len])
        except Exception as e:
            logger.error(f"Erreur lors du calcul de la pr√©cision: {e}")
            return {"error": f"Erreur lors du calcul de la pr√©cision: {str(e)}"}
        
        # Mettre √† jour la pr√©diction
        pred["accuracy_score"] = accuracy
        pred["is_validated"] = True
        pred["validation_timestamp"] = datetime.now().isoformat()
        pred["real_prices"] = real_prices[:min_len]
        
        # Sauvegarder l'historique
        try:
            save_prediction_history()
        except Exception as e:
            logger.warning(f"Erreur lors de la sauvegarde de l'historique: {e}")
        
        # Sauvegarder les m√©triques
        try:
            metrics = {
                "symbol": symbol,
                "prediction_id": pred.get("id", "unknown"),
                "accuracy_score": accuracy,
                "bars_validated": min_len,
                "predicted_prices_count": len(predicted_prices),
                "real_prices_count": len(real_prices),
                "timeframe": pred.get("timeframe", "M1")
            }
            save_prediction_metrics(symbol, metrics)
        except Exception as e:
            logger.warning(f"Erreur lors de la sauvegarde des m√©triques: {e}")
        
        logger.info(f"‚úÖ Pr√©diction valid√©e pour {symbol}: Pr√©cision = {accuracy*100:.1f}%")
        
        return {
            "success": True,
            "accuracy_score": accuracy,
            "bars_validated": min_len,
            "timestamp": datetime.now().isoformat()
        }
        
    except KeyError as e:
        error_msg = f"Cl√© manquante dans la pr√©diction: {str(e)}"
        logger.error(f"Erreur validation pr√©diction: {error_msg}")
        return {"error": error_msg}
    except Exception as e:
        error_msg = f"Erreur validation pr√©diction avec donn√©es r√©elles: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return {"error": error_msg}

# Charger l'historique au d√©marrage
load_prediction_history()

# Initialisation MT5 si disponible
mt5_initialized = False
if MT5_AVAILABLE:
    try:
        mt5_login = int(os.getenv('MT5_LOGIN', 0))
        mt5_password = os.getenv('MT5_PASSWORD', '')
        mt5_server = os.getenv('MT5_SERVER', '')
        
        if mt5_login and mt5_password and mt5_server:
            if mt5.initialize(login=mt5_login, password=mt5_password, server=mt5_server):
                mt5_initialized = True
                logger.info("MT5 initialis√© avec succ√®s")
            else:
                logger.warning("√âchec de l'initialisation MT5")
        else:
            logger.info("MT5: Non configur√© (variables d'environnement manquantes)")
    except Exception as e:
        logger.error(f"Erreur lors de l'initialisation MT5: {e}")

# Initialisation des pr√©dicteurs ML si disponibles
ml_predictor = None
spike_predictor = None
if BACKEND_AVAILABLE:
    try:
        ml_predictor = AdvancedMLPredictor()
        spike_predictor = AdvancedSpikePredictor()
        logger.info("Pr√©dicteurs ML initialis√©s")
    except Exception as e:
        logger.warning(f"Impossible d'initialiser les pr√©dicteurs ML: {e}")

# Dictionnaire pour stocker les instances d'AdvancedIndicators par symbole/tf
indicators_cache = {}

# Mod√®les Pydantic pour les requ√™tes/r√©ponses
class DecisionRequest(BaseModel):
    symbol: Optional[str] = "UNKNOWN"
    bid: Optional[float] = None
    ask: Optional[float] = None
    rsi: Optional[float] = 50.0  # Valeur neutre par d√©faut
    ema_fast_h1: Optional[float] = None
    ema_slow_h1: Optional[float] = None
    ema_fast_m1: Optional[float] = None
    ema_slow_m1: Optional[float] = None
    ema_fast_m5: Optional[float] = None
    ema_slow_m5: Optional[float] = None
    atr: Optional[float] = 0.0
    dir_rule: int = 0  # 0 = neutre par d√©faut
    is_spike_mode: bool = False
    vwap: Optional[float] = None
    vwap_distance: Optional[float] = None
    above_vwap: Optional[bool] = None
    supertrend_trend: Optional[int] = 0  # 0 = neutre par d√©faut
    supertrend_line: Optional[float] = None
    volatility_regime: Optional[int] = 0  # 0 = neutre par d√©faut
    volatility_ratio: Optional[float] = 1.0  # 1.0 = neutre par d√©faut
    image_filename: Optional[str] = None # Filename of the chart screenshot in MT5 Files
    deriv_patterns: Optional[str] = None  # R√©sum√© des patterns Deriv d√©tect√©s
    deriv_patterns_bullish: Optional[int] = None  # Nombre de patterns bullish
    deriv_patterns_bearish: Optional[int] = None  # Nombre de patterns bearish
    deriv_patterns_confidence: Optional[float] = None  # Confiance moyenne des patterns
    timestamp: Optional[str] = None  # Timestamp de la requ√™te (ajout√© pour corriger l'erreur 422)

# ===== MOD√àLES POUR FEEDBACK LOOP =====
class TradeFeedback(BaseModel):
    """Mod√®le pour recevoir les r√©sultats de trade du robot MT5"""
    symbol: str
    open_time: str  # ISO format datetime string
    close_time: str  # ISO format datetime string
    entry_price: float
    exit_price: float
    profit: float
    ai_confidence: float
    coherent_confidence: float
    decision: str  # "BUY" ou "SELL"
    is_win: bool


class DecisionResponse(BaseModel):
    action: str  # "buy", "sell", "hold"
    confidence: float  # 0.0-1.0
    reason: str
    spike_prediction: bool = False
    spike_zone_price: Optional[float] = None
    stop_loss: Optional[float] = None
    take_profit: Optional[float] = None
    spike_direction: Optional[bool] = None  # True=BUY, False=SELL
    early_spike_warning: bool = False
    early_spike_zone_price: Optional[float] = None
    early_spike_direction: Optional[bool] = None
    buy_zone_low: Optional[float] = None
    buy_zone_high: Optional[float] = None
    sell_zone_low: Optional[float] = None
    sell_zone_high: Optional[float] = None
    timestamp: Optional[str] = None
    model_used: Optional[str] = None
    technical_analysis: Optional[Dict[str, Any]] = None
    gemma_analysis: Optional[str] = None  # Analyse compl√®te Gemma+Gemini
    metadata: Optional[Dict[str, Any]] = None  # M√©tadonn√©es enrichies (RSI, EMA, ATR, etc.)

class TrendlineData(BaseModel):
    start: Dict[str, Any]  # {"time": timestamp, "price": float}
    end: Dict[str, Any]    # {"time": timestamp, "price": float}

class AnalysisRequest(BaseModel):
    symbol: str
    timeframe: Optional[str] = None
    request_type: Optional[str] = None

class AnalysisResponse(BaseModel):
    symbol: str
    timestamp: str
    h1: Dict[str, Any] = {}
    h4: Dict[str, Any] = {}
    m15: Dict[str, Any] = {}
    ete: Optional[Dict[str, Any]] = None

class TrendRequest(BaseModel):
    symbol: str
    timeframe: Optional[str] = "M1"

class TimeWindowsResponse(BaseModel):
    symbol: str
    preferred_hours: List[int]  # Liste d'heures 0-23
    forbidden_hours: List[int]  # Liste d'heures 0-23

class CoherentAnalysisRequest(BaseModel):
    symbol: str
    timeframes: Optional[List[str]] = ["D1", "H4", "H1", "M30", "M15", "M5", "M1"]

class CoherentAnalysisResponse(BaseModel):
    status: str
    symbol: str
    decision: str
    decision_type: str
    confidence: float
    stability: str
    bullish_pct: float
    bearish_pct: float
    neutral_pct: float
    trends: Dict[str, Any]
    timestamp: str
    message: Optional[str] = None

class DashboardStatsResponse(BaseModel):
    timestamp: str
    model_performance: Dict[str, Any]
    trading_stats: Dict[str, Any]
    robot_performance: Dict[str, Any]
    coherent_analysis: Optional[CoherentAnalysisResponse] = None

# ========== FONCTION SIMPLIFI√âE POUR ROBOCOP v2 ==========
# Modifier la fonction decision_simplified pour utiliser le ML
async def decision_simplified(request: DecisionRequest):
    """
    Fonction de d√©cision simplifi√©e avec am√©lioration ML
    """
    global decision_count
    decision_count += 1
    
    logger.info(f"üéØ MODE SIMPLIFI√â + ML - Requ√™te d√©cision pour {request.symbol}")
    logger.info(f"   Bid: {request.bid}, Ask: {request.ask}, RSI: {request.rsi}")
    
    # Analyse technique de base
    action = "hold"
    confidence = 0.5
    reason = "Analyse technique multi-timeframe"
    
    # Scores pond√©r√©s par timeframe
    buy_score = 0.0
    sell_score = 0.0
    
    # 1. Analyse RSI (poids: 15%)
    if request.rsi:
        if request.rsi < 30:
            buy_score += 0.15
            reason += f"RSI survent√© ({request.rsi:.1f}). "
        elif request.rsi > 70:
            sell_score += 0.15
            reason += f"RSI surachat ({request.rsi:.1f}). "
        elif 30 <= request.rsi <= 40:
            buy_score += 0.08
            reason += f"RSI zone survente ({request.rsi:.1f}). "
        elif 60 <= request.rsi <= 70:
            sell_score += 0.08
            reason += f"RSI zone surachat ({request.rsi:.1f}). "
    
    # 2. Analyse EMA M1 (poids: 20%)
    if request.ema_fast_m1 and request.ema_slow_m1:
        ema_diff_m1 = request.ema_fast_m1 - request.ema_slow_m1
        ema_strength_m1 = abs(ema_diff_m1) / request.ema_slow_m1 if request.ema_slow_m1 > 0 else 0
        
        if ema_diff_m1 > 0:
            buy_score += 0.20 * min(1.0, ema_strength_m1 * 100)
            reason += f"EMA M1 haussi√®re (+{ema_strength_m1*100:.1f}%). "
        else:
            sell_score += 0.20 * min(1.0, ema_strength_m1 * 100)
            reason += f"EMA M1 baissi√®re ({ema_strength_m1*100:.1f}%). "
    
    # 3. Analyse EMA H1 (poids: 35%)
    if request.ema_fast_h1 and request.ema_slow_h1:
        ema_diff_h1 = request.ema_fast_h1 - request.ema_slow_h1
        ema_strength_h1 = abs(ema_diff_h1) / request.ema_slow_h1 if request.ema_slow_h1 > 0 else 0
        
        if ema_diff_h1 > 0:
            buy_score += 0.35 * min(1.0, ema_strength_h1 * 50)
            reason += f"EMA H1 haussi√®re (+{ema_strength_h1*50:.1f}%). "
        else:
            sell_score += 0.35 * min(1.0, ema_strength_h1 * 50)
            reason += f"EMA H1 baissi√®re ({ema_strength_h1*50:.1f}%). "
    
    # 4. Analyse EMA M5 (poids: 25%)
    if request.ema_fast_m5 and request.ema_slow_m5:
        ema_diff_m5 = request.ema_fast_m5 - request.ema_slow_m5
        ema_strength_m5 = abs(ema_diff_m5) / request.ema_slow_m5 if request.ema_slow_m5 > 0 else 0
        
        if ema_diff_m5 > 0:
            buy_score += 0.25 * min(1.0, ema_strength_m5 * 75)
            reason += f"EMA M5 haussi√®re (+{ema_strength_m5*75:.1f}%). "
        else:
            sell_score += 0.25 * min(1.0, ema_strength_m5 * 75)
            reason += f"EMA M5 baissi√®re ({ema_strength_m5*75:.1f}%). "
    
    # 5. D√©cision technique de base
    if buy_score > sell_score:
        base_action = "buy"
        base_confidence = 0.5 + (buy_score - sell_score) / 2
    elif sell_score > buy_score:
        base_action = "sell"
        base_confidence = 0.5 + (sell_score - buy_score) / 2
    else:
        base_action = "hold"
        base_confidence = 0.5
    
    # 6. AM√âLIORATION AVEC ML
    market_data = {
        "symbol": request.symbol,
        "bid": request.bid,
        "ask": request.ask,
        "rsi": request.rsi,
        "ema_fast_m1": request.ema_fast_m1,
        "ema_slow_m1": request.ema_slow_m1,
        "ema_fast_h1": request.ema_fast_h1,
        "ema_slow_h1": request.ema_slow_h1,
        "ema_fast_m5": request.ema_fast_m5,
        "ema_slow_m5": request.ema_slow_m5,
        "atr": request.atr,
        "timestamp": request.timestamp
    }
    
    ml_result = enhance_decision_with_ml(request.symbol, base_action, base_confidence, market_data)
    
    # Utiliser la d√©cision am√©lior√©e par ML
    action = ml_result["enhanced_decision"]
    confidence = ml_result["enhanced_confidence"]
    
    # Ajouter la raison ML √† la raison technique
    if ml_result["ml_applied"]:
        reason += f"[ML: {ml_result['ml_reason']}] "
        logger.info(f"üß† ML Enhancement: {base_action} ‚Üí {action} ({base_confidence:.2f} ‚Üí {confidence:.2f})")
    
    # 7. Ajustements finaux
    if action == "hold":
        confidence = max(0.3, confidence - 0.2)
    
    # 8. Confiance pour MT5: envoyer d√©cimale 0-1 (l'EA attend 0-1 et affiche *100)
    confidence_percentage = confidence
    
    # 9. Calcul SL/TP
    stop_loss = None
    take_profit = None
    
    if action == "buy" and request.bid:
        atr = request.atr if request.atr and request.atr > 0 else 0.0020
        stop_loss = request.bid - atr * 2
        take_profit = request.bid + atr * 3
    elif action == "sell" and request.ask:
        atr = request.atr if request.atr and request.atr > 0 else 0.0020
        stop_loss = request.ask + atr * 2
        take_profit = request.ask - atr * 3
    
    # 10. Cr√©er la r√©ponse enrichie
    response = DecisionResponse(
        action=action,
        confidence=confidence_percentage,  # D√©cimale 0-1 (MT5 affiche *100)
        reason=reason,
        stop_loss=stop_loss,
        take_profit=take_profit,
        timestamp=datetime.now().isoformat(),
        model_used="technical_ml_enhanced",
        metadata={
            "original_decision": ml_result["original_decision"],
            "original_confidence": ml_result["original_confidence"],
            "ml_enhanced": ml_result["ml_applied"],
            "ml_reason": ml_result["ml_reason"],
            "base_scores": {"buy": buy_score, "sell": sell_score},
            "market_data": market_data,
            "confidence_decimal": confidence,  # Garder la valeur d√©cimale pour r√©f√©rence
            "confidence_percentage": confidence_percentage
        }
    )
    
    # 11. Sauvegarder la d√©cision dans Supabase (local OU cloud) si les cl√©s sont disponibles
    try:
        await save_decision_to_supabase(request, response, ml_result)
    except Exception as e:
        logger.error(f"‚ùå Erreur sauvegarde d√©cision Supabase: {e}")
    
    return response

async def save_decision_to_supabase(request: DecisionRequest, response: DecisionResponse, ml_result: dict):
    """Sauvegarder la d√©cision am√©lior√©e dans Supabase"""
    import httpx
    
    supabase_url = os.getenv("SUPABASE_URL", "https://bpzqnooiisgadzicwupi.supabase.co")
    supabase_key = os.getenv("SUPABASE_ANON_KEY")
    if not supabase_url or not supabase_key:
        logger.debug("Supabase non configur√© (SUPABASE_URL ou SUPABASE_ANON_KEY manquant) - saut de la sauvegarde.")
        return
    
    headers = {
        "apikey": supabase_key,
        "Authorization": f"Bearer {supabase_key}",
        "Content-Type": "application/json",
        "Prefer": "return=representation"
    }
    
    decision_data = {
        "symbol": request.symbol,
        "timeframe": "M1",
        "prediction": response.action,
        "confidence": response.confidence,  # D√©j√† 0-1 pour Supabase
        "reason": response.reason,
        "model_used": "technical_ml_enhanced",
        "metadata": {
            "original_decision": ml_result["original_decision"],
            "original_confidence": ml_result["original_confidence"],
            "ml_enhanced": ml_result["ml_applied"],
            "ml_reason": ml_result["ml_reason"],
            "request_data": {
                "bid": request.bid,
                "ask": request.ask,
                "rsi": request.rsi,
                "ema_fast_m1": request.ema_fast_m1,
                "ema_slow_m1": request.ema_slow_m1,
                "ema_fast_h1": request.ema_fast_h1,
                "ema_slow_h1": request.ema_slow_h1,
                "ema_fast_m5": request.ema_fast_m5,
                "ema_slow_m5": request.ema_slow_m5,
                "atr": request.atr
            }
        }
    }
    
    async with httpx.AsyncClient() as client:
        try:
            resp = await client.post(
                f"{supabase_url}/rest/v1/predictions",
                json=decision_data,
                headers=headers,
                timeout=10.0
            )
            
            if resp.status_code == 201:
                logger.info(f"‚úÖ D√©cision ML sauvegard√©e dans Supabase pour {request.symbol}")
            else:
                logger.error(f"‚ùå Erreur sauvegarde d√©cision: {resp.status_code} - {resp.text}")
                
        except Exception as e:
            logger.error(f"‚ùå Erreur connexion Supabase: {e}")

    # Enregistrer √©galement une m√©trique simple dans model_metrics pour activer l'apprentissage continu
    try:
        if supabase_key:
            # Extraire une "accuracy" proxy √† partir de la confiance (d√©cimale)
            accuracy_decimal = None
            meta = getattr(response, "metadata", None)
            if isinstance(meta, dict) and "confidence_decimal" in meta:
                try:
                    accuracy_decimal = float(meta.get("confidence_decimal"))
                except (TypeError, ValueError):
                    accuracy_decimal = None
            if accuracy_decimal is None:
                try:
                    # response.confidence est renvoy√©e en pourcentage (0-100)
                    accuracy_decimal = float(response.confidence) / 100.0
                except Exception:
                    accuracy_decimal = 0.5

            if not (0.0 <= accuracy_decimal <= 1.0):
                accuracy_decimal = 0.5

            # Sauvegarder l'accuracy en POURCENTAGE (0-100) pour coller √† l'affichage MT5
            metrics_payload = {
                "symbol": request.symbol,
                "timeframe": "M1",
                "accuracy": float(accuracy_decimal * 100.0),
                "metadata": {
                    "model_used": response.model_used or "technical_ml_enhanced",
                    "last_action": response.action,
                    "last_confidence_pct": float(response.confidence),
                    "reason_sample": response.reason[:240] if isinstance(response.reason, str) else "",
                },
            }

            try:
                async with httpx.AsyncClient() as client:
                    r_metrics = await client.post(
                        f"{supabase_url}/rest/v1/model_metrics",
                        json=metrics_payload,
                        headers=headers,
                        timeout=10.0,
                    )
                    if r_metrics.status_code not in (200, 201):
                        logger.debug(
                            f"Supabase model_metrics: statut {r_metrics.status_code} "
                            f"body={r_metrics.text}"
                        )
                    else:
                        logger.debug(
                            f"‚úÖ model_metrics ins√©r√©e pour {request.symbol} "
                            f"accuracy={metrics_payload['accuracy']:.3f}"
                        )
            except Exception as e:
                logger.debug(f"Supabase model_metrics: {e}")
    except Exception as e:
        logger.debug(f"Erreur lors de la sauvegarde dans model_metrics: {e}")


async def fetch_supabase_ml_context(symbol: str, timeframe: str = "M1") -> Dict[str, Any]:
    """
    Requ√™te Supabase: model_metrics, symbol_calibration, trade_feedback pour ce symbole.
    Utilis√© pour que le robot prenne ses d√©cisions sur la base du ML et apprenne des erreurs.
    """
    import httpx
    supabase_url = os.getenv("SUPABASE_URL", "https://bpzqnooiisgadzicwupi.supabase.co")
    supabase_key = os.getenv("SUPABASE_ANON_KEY")
    if not supabase_key:
        return {}
    sym_enc = symbol.replace(" ", "%20")
    headers = {"apikey": supabase_key, "Authorization": f"Bearer {supabase_key}"}
    out = {
        "model_accuracy": 0.5,
        "calibration_wins": 0,
        "calibration_total": 0,
        "drift_factor": 1.0,
        "recent_win_rate": 0.5,
        "recent_count": 0,
    }
    async with httpx.AsyncClient() as client:
        try:
            # Derni√®re m√©trique mod√®le pour ce symbole
            r1 = await client.get(
                f"{supabase_url}/rest/v1/model_metrics",
                params={"symbol": f"eq.{symbol}", "timeframe": f"eq.{timeframe}", "order": "training_date.desc", "limit": "1"},
                headers=headers,
                timeout=5.0,
            )
            if r1.status_code == 200 and r1.json():
                row = r1.json()[0]
                out["model_accuracy"] = float(row.get("accuracy", 0.5))
                meta = row.get("metadata")
                if isinstance(meta, dict):
                    out["drift_factor"] = float(meta.get("drift_factor", 1.0))
                elif isinstance(meta, str):
                    try:
                        m = json.loads(meta)
                        out["drift_factor"] = float(m.get("drift_factor", 1.0))
                    except Exception:
                        pass
        except Exception as e:
            logger.debug(f"Supabase model_metrics: {e}")
        try:
            r2 = await client.get(
                f"{supabase_url}/rest/v1/symbol_calibration",
                params={"symbol": f"eq.{symbol}", "limit": "1"},
                headers=headers,
                timeout=5.0,
            )
            if r2.status_code == 200 and r2.json():
                row = r2.json()[0]
                out["calibration_wins"] = int(row.get("wins", 0))
                out["calibration_total"] = int(row.get("total", 0))
                out["drift_factor"] = float(row.get("drift_factor", 1.0))
        except Exception as e:
            logger.debug(f"Supabase symbol_calibration: {e}")
        try:
            r3 = await client.get(
                f"{supabase_url}/rest/v1/trade_feedback",
                params={"symbol": f"eq.{symbol}", "order": "created_at.desc", "limit": "50"},
                headers=headers,
                timeout=5.0,
            )
            if r3.status_code == 200 and r3.json():
                rows = r3.json()
                wins = sum(1 for x in rows if x.get("is_win") is True)
                out["recent_count"] = len(rows)
                out["recent_win_rate"] = wins / len(rows) if rows else 0.5
        except Exception as e:
            logger.debug(f"Supabase trade_feedback: {e}")
    return out



async def root():
    """Endpoint racine pour v√©rifier que le serveur fonctionne"""
    return {
        "status": "running",
        "service": "TradBOT AI Server",
        "version": "2.0.1",
        "mt5_available": MT5_AVAILABLE,
        "ml_trainer_available": ML_TRAINER_AVAILABLE,
        "ml_recommendation_available": ML_RECOMMENDATION_AVAILABLE,
        "endpoints": [
            "/health (GET)",
            "/dashboard (GET) - Tableau de bord complet pour le robot",
            "/analyze (POST)",
            "/mt5/symbols (GET)",
            "/mt5/account (GET)",
            "/mt5/positions (GET)",
            "/mt5/close_position (POST)",
            "/mt5/place_order (POST)",
            "/ml/metrics (GET)",
            "/ml/start (POST)",
            "/ml/stop (POST)",
            "/ml/retrain (POST)",
            "/ml/recommendations (GET)",
            "/ml/recommendations/{symbol} (GET)",
            "/ml/opportunities (GET)",
            "/validate (POST)",
            "/test (POST)"
        ]
    }

@app.get("/health")
async def health_check():
    """Endpoint de sant√© pour Render et monitoring"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "service": "TradBOT AI Server",
        "version": "2.0.1",
        "mt5_available": MT5_AVAILABLE,
        "ml_trainer_available": ML_TRAINER_AVAILABLE,
        "ml_recommendation_available": ML_RECOMMENDATION_AVAILABLE
    }

@app.get("/ml/metrics")
async def get_ml_metrics():
    """Endpoint pour r√©cup√©rer les m√©triques ML en temps r√©el"""
    if not ML_TRAINER_AVAILABLE:
        raise HTTPException(status_code=503, detail="Syst√®me ML non disponible")
    
    return ml_trainer.get_current_metrics()

@app.post("/ml/start")
async def start_ml_trainer():
    """D√©marre le syst√®me d'entra√Ænement continu"""
    if not ML_TRAINER_AVAILABLE:
        raise HTTPException(status_code=503, detail="Syst√®me ML non disponible")
    
    await ml_trainer.start()
    return {"status": "started", "message": "Syst√®me d'entra√Ænement continu d√©marr√©"}

@app.post("/ml/stop")
async def stop_ml_trainer():
    """Arr√™te le syst√®me d'entra√Ænement continu"""
    if not ML_TRAINER_AVAILABLE:
        raise HTTPException(status_code=503, detail="Syst√®me ML non disponible")
    
    await ml_trainer.stop()
    return {"status": "stopped", "message": "Syst√®me d'entra√Ænement continu arr√™t√©"}

@app.post("/ml/retrain")
async def force_retrain():
    """Force un r√©entra√Ænement imm√©diat de tous les mod√®les"""
    if not ML_TRAINER_AVAILABLE:
        raise HTTPException(status_code=503, detail="Syst√®me ML non disponible")
    
    # Forcer le r√©entra√Ænement
    models = ml_trainer.load_existing_models()
    retrained_count = 0
    
    for model_key, model_info in models.items():
        symbol = model_info['symbol']
        timeframe = model_info['timeframe']
        
        # R√©cup√©rer les donn√©es et r√©entra√Æner
        df = await ml_trainer.fetch_training_data_simple(symbol, timeframe)
        if df is not None and len(df) >= ml_trainer.min_samples_for_retraining:
            new_metrics = ml_trainer.train_model_simple(df, symbol, timeframe)
            if new_metrics:
                await ml_trainer.save_metrics_to_supabase(new_metrics)
                retrained_count += 1
    
    return {
        "status": "completed",
        "retrained_models": retrained_count,
        "message": f"{retrained_count} mod√®les r√©entra√Æn√©s avec succ√®s"
    }

@app.get("/ml/recommendations")
async def get_ml_recommendations(symbol: Optional[str] = None, limit: int = 10):
    """
    Endpoint pour obtenir les recommandations de trading intelligentes bas√©es sur ML

    Args:
        symbol: Symbole sp√©cifique (optionnel, tous les symboles si None)
        limit: Nombre maximum de recommandations √† retourner

    Returns:
        Recommandations compl√®tes avec actions, opportunit√©s, risques, etc.
    """
    if not ML_TRAINER_AVAILABLE or not ML_RECOMMENDATION_AVAILABLE:
        raise HTTPException(status_code=503, detail="Syst√®me de recommandation ML non disponible")

    try:
        # Analyser les m√©triques ML et g√©n√©rer les recommandations
        recommendations_data = ml_recommendation_system.analyze_ml_metrics()

        # Filtrer par symbole si demand√©
        if symbol:
            filtered_recommendations = [
                rec for rec in recommendations_data["recommendations"]
                if rec["symbol"] == symbol
            ]
            recommendations_data["recommendations"] = filtered_recommendations[:limit]
        else:
            recommendations_data["recommendations"] = recommendations_data["recommendations"][:limit]

        return {
            "status": "success",
            "data": recommendations_data,
            "message": f"Recommandations ML g√©n√©r√©es pour {len(recommendations_data['recommendations'])} symboles"
        }
    except Exception as e:
        logger.error(f"‚ùå Erreur g√©n√©ration recommandations: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur g√©n√©ration recommandations: {str(e)}")

@app.get("/ml/predict")
async def get_ml_swing_predictions(symbol: str, type: str = "swing_points", future_bars: int = 1000):
    """
    Endpoint pour obtenir les pr√©dictions ML (swing points ou trendlines) pour les 1000 prochaines bougies M1
    
    Args:
        symbol: Le symbole √† analyser
        type: Type de pr√©diction ("swing_points" ou "trendlines")
        future_bars: Nombre de bougies futures √† pr√©dire (max 1000)
    
    Returns:
        Pr√©dictions ML avec timestamps, prix et confiance
    """
    # Permettre le fonctionnement m√™me sans ML trainer complet
    if not ML_TRAINER_AVAILABLE:
        logger.warning("‚ö†Ô∏è ML trainer non disponible, utilisation de pr√©dictions simul√©es")
    
    try:
        # Limiter le nombre de bougies futures pour √©viter la surcharge
        future_bars = min(future_bars, 1000)
        
        if type == "swing_points":
            # G√©n√©rer les pr√©dictions de swing points
            swing_predictions = generate_swing_point_predictions(symbol, future_bars)
            
            return {
                "symbol": symbol,
                "type": type,
                "future_bars": future_bars,
                "swing_points": swing_predictions,
                "total_predictions": len(swing_predictions),
                "timestamp": datetime.now().isoformat()
            }
        elif type == "trendlines":
            # G√©n√©rer les pr√©dictions de trendlines
            trendline_predictions = generate_trendline_predictions(symbol, future_bars)
            
            return {
                "symbol": symbol,
                "type": type,
                "future_bars": future_bars,
                "trendlines": trendline_predictions,
                "total_predictions": len(trendline_predictions),
                "timestamp": datetime.now().isoformat()
            }
        else:
            raise HTTPException(status_code=400, detail=f"Type de pr√©diction non support√©: {type}")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur g√©n√©ration pr√©dictions ML: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur g√©n√©ration pr√©dictions: {str(e)}")

def generate_trendline_predictions(symbol: str, future_bars: int) -> List[Dict]:
    """
    G√©n√®re des pr√©dictions de trendlines et supports/r√©sistances ML
    
    Args:
        symbol: Symbole √† analyser
        future_bars: Nombre de bougies futures √† pr√©dire
    
    Returns:
        Liste des pr√©dictions de trendlines
    """
    trendlines = []
    
    try:
        # R√©cup√©rer les donn√©es historiques r√©centes pour le contexte
        historical_data = get_recent_historical_data(symbol, 500)  # 500 bougies r√©centes
        
        if historical_data.empty:
            logger.warning(f"Pas de donn√©es historiques pour {symbol}")
            return trendlines
        
        current_time = datetime.now()
        volatility = calculate_volatility(historical_data)
        avg_price = historical_data['close'].mean()
        
        # Identifier les points de swing historiques pour tracer les trendlines
        swing_highs = []
        swing_lows = []
        
        # Simple d√©tection de swing points dans les donn√©es historiques
        for i in range(2, len(historical_data) - 2):
            current_high = historical_data.iloc[i]['high']
            current_low = historical_data.iloc[i]['low']
            
            # Swing High
            if (current_high > historical_data.iloc[i-1]['high'] and 
                current_high > historical_data.iloc[i-2]['high'] and
                current_high > historical_data.iloc[i+1]['high'] and 
                current_high > historical_data.iloc[i+2]['high']):
                swing_highs.append({
                    'time': historical_data.iloc[i]['time'],
                    'price': current_high
                })
            
            # Swing Low
            if (current_low < historical_data.iloc[i-1]['low'] and 
                current_low < historical_data.iloc[i-2]['low'] and
                current_low < historical_data.iloc[i+1]['low'] and 
                current_low < historical_data.iloc[i+2]['low']):
                swing_lows.append({
                    'time': historical_data.iloc[i]['time'],
                    'price': current_low
                })
        
        # G√©n√©rer les trendlines bas√©es sur les swing points
        trendline_count = min(15, future_bars // 50)  # Environ 15 trendlines pour 1000 bougies
        
        for i in range(trendline_count):
            # Type de trendline (alternance)
            trendline_types = ["support", "resistance", "trendline"]
            trendline_type = trendline_types[i % len(trendline_types)]
            
            # Points de d√©part et fin
            if trendline_type == "support" and len(swing_lows) >= 2:
                # Support: connecter deux swing lows
                start_point = swing_lows[i % len(swing_lows)]
                end_point = swing_lows[(i + 1) % len(swing_lows)]
            elif trendline_type == "resistance" and len(swing_highs) >= 2:
                # R√©sistance: connecter deux swing highs
                start_point = swing_highs[i % len(swing_highs)]
                end_point = swing_highs[(i + 1) % len(swing_highs)]
            else:
                # Trendline: g√©n√©rer des points al√©atoires r√©alistes
                start_time = current_time + timedelta(minutes=(i * 60) + 30)
                end_time = start_time + timedelta(minutes=120 + i * 10)
                
                base_price = avg_price * (1 + np.random.uniform(-0.02, 0.02))
                slope = np.random.uniform(-0.0001, 0.0001)  # Pente faible
                
                start_point = {
                    'time': start_time,
                    'price': base_price
                }
                end_point = {
                    'time': end_time,
                    'price': base_price + slope * 120  # 120 minutes de diff√©rence
                }
            
            # Calculer la pente
            time_diff = (end_point['time'] - start_point['time']).total_seconds() / 60  # minutes
            price_diff = end_point['price'] - start_point['price']
            slope = price_diff / time_diff if time_diff > 0 else 0
            
            # Confiance bas√©e sur la volatilit√© et la coh√©rence
            base_confidence = 0.75
            if trendline_type in ["support", "resistance"]:
                confidence = base_confidence + np.random.uniform(-0.10, 0.15)
            else:
                confidence = base_confidence + np.random.uniform(-0.15, 0.10)
            
            confidence = max(0.55, min(0.95, confidence))  # Limiter entre 55% et 95%
            
            trendlines.append({
                "start_time": int(start_point['time'].timestamp()),
                "start_price": round(start_point['price'], 5),
                "end_time": int(end_point['time'].timestamp()),
                "end_price": round(end_point['price'], 5),
                "slope": round(slope, 6),
                "confidence": round(confidence, 3),
                "type": trendline_type
            })
        
        # Trier par temps de d√©but
        trendlines.sort(key=lambda x: x["start_time"])
        
        logger.info(f"üìà G√©n√©r√© {len(trendlines)} trendlines ML pour {symbol}")
        
    except Exception as e:
        logger.error(f"Erreur g√©n√©ration trendlines: {e}")
    
    return trendlines

def generate_swing_point_predictions(symbol: str, future_bars: int) -> List[Dict]:
    """
    G√©n√®re des pr√©dictions de swing points en utilisant les mod√®les ML entra√Æn√©s
    
    Args:
        symbol: Symbole √† analyser
        future_bars: Nombre de bougies futures √† pr√©dire
    
    Returns:
        Liste des pr√©dictions de swing points
    """
    swing_points = []
    
    try:
        # R√©cup√©rer les donn√©es historiques r√©centes pour le contexte
        historical_data = get_recent_historical_data(symbol, 200)  # 200 bougies r√©centes
        
        if historical_data.empty:
            logger.warning(f"Pas de donn√©es historiques pour {symbol}")
            return swing_points
        
        # Simuler la g√©n√©ration de swing points bas√©e sur les patterns ML
        # En production, ceci utiliserait les vrais mod√®les ML entra√Æn√©s
        current_time = datetime.now()
        
        # G√©n√©rer des swing points r√©alistes bas√©s sur la volatilit√© historique
        volatility = calculate_volatility(historical_data)
        avg_price = historical_data['close'].mean()
        
        # Nombre de swing points √† g√©n√©rer (environ 1 tous les 20-30 bougies)
        num_swings = future_bars // 25  # Environ 40 swing points pour 1000 bougies
        
        for i in range(num_swings):
            # Position temporelle dans le futur
            future_bar = (i + 1) * 25 + np.random.randint(-5, 6)  # Variation autour de 25 bougies
            if future_bar >= future_bars:
                continue
            
            # Timestamp du swing point
            swing_time = current_time + timedelta(minutes=future_bar)
            
            # Type de swing (alternance high/low)
            is_high = i % 2 == 0
            
            # Prix du swing point bas√© sur la volatilit√©
            price_variation = volatility * np.random.uniform(0.5, 2.0)
            if is_high:
                swing_price = avg_price + price_variation * np.random.uniform(0.8, 1.2)
            else:
                swing_price = avg_price - price_variation * np.random.uniform(0.8, 1.2)
            
            # Confiance bas√©e sur la distance temporelle et la volatilit√©
            base_confidence = 0.75
            confidence = base_confidence + np.random.uniform(-0.15, 0.20)
            confidence = max(0.5, min(0.95, confidence))  # Limiter entre 50% et 95%
            
            swing_points.append({
                "time": int(swing_time.timestamp()),
                "price": round(swing_price, 5),
                "is_high": is_high,
                "confidence": round(confidence, 3),
                "future_bars": future_bar
            })
        
        # Trier par temps
        swing_points.sort(key=lambda x: x["time"])
        
        logger.info(f"üéØ G√©n√©r√© {len(swing_points)} swing points ML pour {symbol}")
        
    except Exception as e:
        logger.error(f"Erreur g√©n√©ration swing points: {e}")
    
    return swing_points

def get_recent_historical_data(symbol: str, num_bars: int = 200) -> pd.DataFrame:
    """
    R√©cup√®re les donn√©es historiques r√©centes pour un symbole
    En production, ceci se connecterait √† MT5 ou une base de donn√©es
    """
    try:
        # Simuler des donn√©es historiques pour la d√©monstration
        # En production, utiliser MT5 ou une vraie source de donn√©es
        dates = pd.date_range(end=datetime.now(), periods=num_bars, freq='1min')
        
        # G√©n√©rer des prix r√©alistes bas√©s sur une marche al√©atoire
        np.random.seed(hash(symbol) % 2**32)  # Seed pour la reproductibilit√©
        
        # Prix de base selon le symbole
        base_prices = {
            "Boom 1000 Index": 1000,
            "Boom 300 Index": 300,
            "Boom 500 Index": 500,
            "Crash 1000 Index": 1000,
            "Crash 300 Index": 300,
            "Crash 500 Index": 500,
            "EURUSD": 1.1000,
            "GBPUSD": 1.3000,
            "AUDSGD": 0.9000
        }
        
        base_price = base_prices.get(symbol, 1000)
        
        # G√©n√©ration de prix avec tendance et volatilit√©
        returns = np.random.normal(0, 0.002, num_bars)  # 0.2% de volatilit√©
        prices = [base_price]
        
        for ret in returns:
            new_price = prices[-1] * (1 + ret)
            prices.append(new_price)
        
        prices = prices[1:]  # Supprimer le premier prix de base
        
        # Cr√©er le DataFrame
        data = pd.DataFrame({
            'time': dates,
            'open': prices,
            'high': [p * (1 + abs(np.random.normal(0, 0.001))) for p in prices],
            'low': [p * (1 - abs(np.random.normal(0, 0.001))) for p in prices],
            'close': prices,
            'volume': np.random.randint(100, 1000, num_bars)
        })
        
        return data
        
    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration donn√©es historiques: {e}")
        return pd.DataFrame()

def get_historical_data_mt5(symbol: str, timeframe: str = "H1", count: int = 500):
    """R√©cup√®re les donn√©es historiques depuis MT5. Retourne None si MT5 indisponible (ex: Render)."""
    global mt5_initialized
    if not MT5_AVAILABLE:
        return None
    if not mt5_initialized:
        try:
            mt5_login = int(os.getenv('MT5_LOGIN', 0))
            mt5_password = os.getenv('MT5_PASSWORD', '')
            mt5_server = os.getenv('MT5_SERVER', '')
            if mt5_login and mt5_password and mt5_server and mt5.initialize(
                login=mt5_login, password=mt5_password, server=mt5_server
            ):
                mt5_initialized = True
            else:
                return None
        except Exception:
            return None
    try:
        tf_map = {
            "M1": mt5.TIMEFRAME_M1,
            "M5": mt5.TIMEFRAME_M5,
            "M15": mt5.TIMEFRAME_M15,
            "H1": mt5.TIMEFRAME_H1,
            "H4": mt5.TIMEFRAME_H4,
            "D1": mt5.TIMEFRAME_D1,
        }
        tf = tf_map.get(timeframe, mt5.TIMEFRAME_H1)
        rates = mt5.copy_rates_from_pos(symbol, tf, 0, count)
        if rates is None or len(rates) == 0:
            return None
        df = pd.DataFrame(rates)
        df['time'] = pd.to_datetime(df['time'], unit='s')
        return df
    except Exception:
        return None

def calculate_volatility(data: pd.DataFrame) -> float:
    """Calcule la volatilit√© des prix"""
    if data.empty or 'close' not in data.columns:
        return 0.01  # Valeur par d√©faut
    
    returns = data['close'].pct_change().dropna()
    return returns.std() if len(returns) > 0 else 0.01

@app.get("/ml/recommendations/{symbol}")
async def get_symbol_recommendation(symbol: str):
    """
    Endpoint pour obtenir la recommandation sp√©cifique pour un symbole

    Args:
        symbol: Le symbole √† analyser

    Returns:
        Recommandation d√©taill√©e pour ce symbole
    """
    if not ML_TRAINER_AVAILABLE or not ML_RECOMMENDATION_AVAILABLE:
        raise HTTPException(status_code=503, detail="Syst√®me de recommandation ML non disponible")

    try:
        # Obtenir la recommandation pour ce symbole sp√©cifique
        recommendation = ml_recommendation_system.get_recommendation_for_symbol(symbol)

        if not recommendation:
            return {
                "status": "not_found",
                "symbol": symbol,
                "message": f"Aucune recommandation disponible pour {symbol}",
                "data": None
            }

        # Convertir en dict pour la r√©ponse JSON
        rec_dict = {
            "symbol": recommendation.symbol,
            "action": recommendation.action.value,
            "confidence": recommendation.confidence,
            "opportunity_score": recommendation.opportunity_score,
            "opportunity_level": recommendation.opportunity_level.value,
            "reason": recommendation.reason,
            "should_trade": recommendation.should_trade,
            "should_limit_order": recommendation.should_limit_order,
            "limit_order_price": recommendation.limit_order_price,
            "should_close": recommendation.should_close,
            "trailing_stop_distance": recommendation.trailing_stop_distance,
            "timeframe_priority": recommendation.timeframe_priority,
            "risk_level": recommendation.risk_level,
            "timestamp": recommendation.timestamp.isoformat()
        }

        return {
            "status": "success",
            "symbol": symbol,
            "data": rec_dict,
            "message": f"Recommandation ML g√©n√©r√©e pour {symbol}"
        }

    except Exception as e:
        logger.error(f"‚ùå Erreur recommandation pour {symbol}: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur recommandation {symbol}: {str(e)}")

@app.get("/dashboard")
async def get_robot_dashboard():
    """
    Endpoint complet pour le tableau de bord du robot MT5
    Retourne toutes les informations en temps r√©el:
    - M√©triques ML en temps r√©el
    - Pr√©dictions de mouvement de prix
    - Recommandations intelligentes
    - √âtat du syst√®me
    """
    try:
        dashboard_data = {
            "timestamp": datetime.now().isoformat(),
            "system_status": {
                "server": "running",
                "mt5_available": MT5_AVAILABLE,
                "ml_trainer_available": ML_TRAINER_AVAILABLE,
                "ml_recommendation_available": ML_RECOMMENDATION_AVAILABLE
            },
            "ml_metrics": None,
            "ml_recommendations": None,
            "price_predictions": [],
            "top_opportunities": []
        }
        
        # 1. M√©triques ML en temps r√©el
        if ML_TRAINER_AVAILABLE:
            try:
                dashboard_data["ml_metrics"] = ml_trainer.get_current_metrics()
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur r√©cup√©ration m√©triques ML: {e}")
                dashboard_data["ml_metrics"] = {"error": str(e)}
        
        # 2. Recommandations ML intelligentes
        if ML_RECOMMENDATION_AVAILABLE and ML_TRAINER_AVAILABLE:
            try:
                recommendations_data = ml_recommendation_system.analyze_ml_metrics()
                dashboard_data["ml_recommendations"] = recommendations_data
                
                # Extraire les top opportunit√©s
                opportunities = ml_recommendation_system.get_top_opportunities(5)
                dashboard_data["top_opportunities"] = [
                    {
                        "symbol": opp.symbol,
                        "total_score": opp.total_score,
                        "buy_opportunity": opp.buy_opportunity,
                        "sell_opportunity": opp.sell_opportunity,
                        "trend_strength": opp.trend_strength,
                        "ml_confidence": opp.ml_confidence,
                        "recommendation": "ACHETER" if opp.buy_opportunity > opp.sell_opportunity else "VENDRE"
                    }
                    for opp in opportunities
                ]
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur r√©cup√©ration recommandations ML: {e}")
                dashboard_data["ml_recommendations"] = {"error": str(e)}
        
        # 3. Pr√©dictions de mouvement de prix (pour les symboles actifs)
        if ML_TRAINER_AVAILABLE:
            try:
                # Symboles √† analyser pour les pr√©dictions
                symbols_to_predict = ["EURJPY", "GBPJPY", "USDJPY", "EURUSD", "GBPUSD"]
                
                for symbol in symbols_to_predict:
                    try:
                        # R√©cup√©rer les derni√®res m√©triques pour ce symbole
                        metrics = ml_trainer.get_current_metrics()
                        
                        # Chercher les m√©triques sp√©cifiques √† ce symbole
                        symbol_metrics = None
                        if 'models' in metrics:
                            for model_key, model_data in metrics['models'].items():
                                if symbol in model_key:
                                    symbol_metrics = model_data
                                    break
                        
                        if symbol_metrics and 'metrics' in symbol_metrics:
                            model_metrics = symbol_metrics['metrics']
                            
                            # G√©n√©rer une pr√©diction bas√©e sur les m√©triques ML
                            prediction = {
                                "symbol": symbol,
                                "current_prediction": "HOLD",
                                "confidence": 0.5,
                                "price_direction": "NEUTRAL",
                                "accuracy": model_metrics.get('accuracy', 0.5),
                                "f1_score": model_metrics.get('f1_score', 0.5),
                                "last_updated": symbol_metrics.get('last_updated', datetime.now().isoformat()),
                                "feature_importance": model_metrics.get('feature_importance', {}),
                                "trend_signal": "NEUTRAL"
                            }
                            
                            # Analyser les features pour d√©terminer la direction
                            feature_importance = model_metrics.get('feature_importance', {})
                            if feature_importance:
                                # Signaux bas√©s sur l'importance des features
                                rsi_importance = feature_importance.get('rsi', 0)
                                ema_importance = feature_importance.get('ema_diff', 0)
                                volume_importance = feature_importance.get('volume', 0)
                                
                                if rsi_importance > 0.1:
                                    prediction["trend_signal"] = "RSI_DOMINANT"
                                elif ema_importance > 0.1:
                                    prediction["trend_signal"] = "TREND_DOMINANT"
                                elif volume_importance > 0.1:
                                    prediction["trend_signal"] = "VOLUME_DOMINANT"
                                
                                # Calculer la confiance bas√©e sur la pr√©cision du mod√®le
                                accuracy = model_metrics.get('accuracy', 0.5)
                                prediction["confidence"] = min(0.95, accuracy * 1.1)
                                
                                # D√©terminer la direction bas√©e sur les m√©triques
                                if accuracy > 0.7:
                                    if 'buy' in str(model_metrics).lower():
                                        prediction["current_prediction"] = "BUY"
                                        prediction["price_direction"] = "HAUSSIER"
                                    elif 'sell' in str(model_metrics).lower():
                                        prediction["current_prediction"] = "SELL"
                                        prediction["price_direction"] = "BAISSIER"
                            
                            dashboard_data["price_predictions"].append(prediction)
                            
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Erreur pr√©diction pour {symbol}: {e}")
                        continue
                        
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur g√©n√©ration pr√©dictions: {e}")
        
        # 4. Statistiques globales
        total_models = 0
        avg_accuracy = 0
        if dashboard_data["ml_metrics"] and 'models' in dashboard_data["ml_metrics"]:
            models = dashboard_data["ml_metrics"]["models"]
            total_models = len(models)
            if models:
                accuracies = []
                for model_data in models.values():
                    if 'metrics' in model_data and 'accuracy' in model_data['metrics']:
                        accuracies.append(model_data['metrics']['accuracy'])
                avg_accuracy = sum(accuracies) / len(accuracies) if accuracies else 0
        
        dashboard_data["global_stats"] = {
            "total_models": total_models,
            "average_accuracy": round(avg_accuracy, 3),
            "system_health": "HEALTHY" if avg_accuracy > 0.6 else "WARNING",
            "last_update": datetime.now().isoformat()
        }
        
        return {
            "status": "success",
            "data": dashboard_data,
            "message": "Tableau de bord robot mis √† jour"
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur g√©n√©ration dashboard: {e}")
        return {
            "status": "error",
            "message": f"Erreur dashboard: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }

@app.get("/ml/opportunities")
async def get_top_opportunities(limit: int = 5):
    """
    Endpoint pour obtenir les meilleures opportunit√©s de trading selon ML

    Args:
        limit: Nombre d'opportunit√©s √† retourner (d√©faut: 5)

    Returns:
        Liste des symboles les plus opportuns
    """
    if not ML_TRAINER_AVAILABLE or not ML_RECOMMENDATION_AVAILABLE:
        raise HTTPException(status_code=503, detail="Syst√®me de recommandation ML non disponible")

    try:
        # Obtenir les meilleures opportunit√©s
        opportunities = ml_recommendation_system.get_top_opportunities(limit)

        opportunities_data = []
        for opp in opportunities:
            opportunities_data.append({
                "symbol": opp.symbol,
                "total_score": opp.total_score,
                "buy_opportunity": opp.buy_opportunity,
                "sell_opportunity": opp.sell_opportunity,
                "hold_opportunity": opp.hold_opportunity,
                "volatility_risk": opp.volatility_risk,
                "trend_strength": opp.trend_strength,
                "ml_confidence": opp.ml_confidence,
                "last_updated": opp.last_updated.isoformat()
            })

        return {
            "status": "success",
            "data": opportunities_data,
            "count": len(opportunities_data),
            "message": f"Top {len(opportunities_data)} opportunit√©s ML identifi√©es"
        }

    except Exception as e:
        logger.error(f"‚ùå Erreur r√©cup√©ration opportunit√©s: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur opportunit√©s: {str(e)}")

@app.post("/test")
async def test_endpoint():
    """Endpoint de test pour v√©rifier que le serveur accepte les requ√™tes POST"""
    import time
    return {
        "status": "ok",
        "message": "Test endpoint fonctionne",
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    }

@app.post("/validate")
async def validate_format(request: dict):
    """Endpoint de validation pour tester les formats de requ√™tes"""
    try:
        # Simuler la validation sans ex√©cuter l'IA
        required_fields = ["symbol", "bid", "ask"]
        missing_fields = [field for field in required_fields if field not in request]
        
        if missing_fields:
            return {
                "valid": False,
                "missing_fields": missing_fields,
                "message": f"Champs manquants: {', '.join(missing_fields)}"
            }
        
        # Validation basique
        symbol = request.get("symbol", "")
        bid = request.get("bid")
        ask = request.get("ask")
        
        if not symbol or not bid or not ask:
            return {
                "valid": False,
                "message": "Les champs symbol, bid, et ask sont requis"
            }
        
        if bid <= 0 or ask <= 0:
            return {
                "valid": False,
                "message": "Les prix bid et ask doivent √™tre positifs"
            }
        
        if bid >= ask:
            return {
                "valid": False,
                "message": "Le prix bid doit √™tre inf√©rieur au prix ask"
            }
        
        return {
            "valid": True,
            "message": "Format valide",
            "symbol": symbol,
            "bid": bid,
            "ask": ask
        }
        
    except Exception as e:
        return {
            "valid": False,
            "error": str(e),
            "message": "Erreur lors de la validation",
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }

@app.get("/market-state")
async def get_market_state_endpoint(symbol: str = "EURUSD", timeframe: str = "M1"):
    """Endpoint d√©di√© pour l'√©tat du march√© (compatible avec tous les robots)"""
    try:
        market_info = calculate_market_state(symbol, timeframe)
        
        response = {
            "symbol": symbol,
            "timeframe": timeframe,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "market_state": market_info["market_state"],
            "market_trend": market_info["market_trend"]
        }
        
        logger.info(f"√âtat march√© {symbol} {timeframe}: {market_info['market_state']} - {market_info['market_trend']}")
        return response
        
    except Exception as e:
        logger.error(f"Erreur √©tat march√©: {e}")
        return {
            "error": f"Erreur lors de l'analyse de l'√©tat du march√©: {str(e)}",
            "symbol": symbol,
            "timeframe": timeframe,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }

@app.get("/trend/health")
async def trend_health():
    """V√©rification de sant√© pour le module de tendance"""
    return {
        "status": "ok",
        "module": "trend_analysis",
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "mt5_available": mt5_initialized
    }


@app.get("/prediction-channel")
async def prediction_channel(symbol: Optional[str] = None, timeframe: str = "M1", future_bars: int = 5000):
    """
    Canal de pr√©diction du prix sur les N prochaines bougies (jusqu'√† 5000).
    Analyse historique + r√©gression lin√©aire + m√©triques Supabase pour feedback / am√©lioration.
    """
    if not symbol or not symbol.strip():
        return {"ok": False, "reason": "symbol required"}
    symbol = symbol.strip()
    result = get_prediction_channel_5000(symbol, timeframe, future_bars)
    return result


def _get_trend_data(symbol: str, timeframe: str, count: int):
    """R√©cup√®re les donn√©es pour /trend. Ordre: MT5/backend puis cloud/simul√© pour √©viter 60% fixe."""
    if get_historical_data is not None and callable(get_historical_data):
        df = get_historical_data(symbol, timeframe, count)
        if df is not None and len(df) >= 2:
            return df
    df = get_historical_data_mt5(symbol, timeframe, count)
    if df is not None and len(df) >= 2:
        return df
    # Fallback: cloud (yfinance) ou simul√© ‚Üí √©vite le 60% fixe partout
    try:
        df_m1 = get_market_data_cloud(symbol, period="5d", interval="1m")
        if df_m1 is None or df_m1.empty or len(df_m1) < 2:
            df_m1 = get_recent_historical_data(symbol, max(count, 500))
        if df_m1 is None or df_m1.empty or len(df_m1) < 2:
            return None
        if timeframe == "M1":
            return df_m1.tail(count)
        df_m1 = df_m1.copy()
        if 'time' in df_m1.columns:
            t = df_m1['time']
            if pd.api.types.is_numeric_dtype(t):
                df_m1['time'] = pd.to_datetime(t, unit='s', errors='coerce')
            else:
                df_m1['time'] = pd.to_datetime(t, errors='coerce')
        elif 'Datetime' in df_m1.columns:
            df_m1['time'] = pd.to_datetime(df_m1['Datetime'], errors='coerce')
        df_m1 = df_m1.dropna(subset=['time']).set_index('time').sort_index()
        if timeframe == "M5":
            res = df_m1.resample('5min').agg({'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last'}).dropna()
        elif timeframe == "H1":
            res = df_m1.resample('1h').agg({'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last'}).dropna()
        else:
            res = df_m1.resample('5min').agg({'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last'}).dropna()
        return res.reset_index().tail(count) if len(res) >= 2 else None
    except Exception as e:
        logger.warning(f"_get_trend_data fallback pour {symbol} {timeframe}: {e}")
        return None


def _trend_fallback_response(symbol: str, timeframe: str, reason: str = "no_data"):
    """R√©ponse de repli pour /trend quand les donn√©es sont indisponibles (√©vite 422/500)."""
    # Sanitize reason: avoid leaking Python tracebacks/NameError to client (max 100 chars, no newlines)
    if reason and len(str(reason)) > 100:
        reason = str(reason)[:97] + "..."
    reason = (reason or "no_data").replace("\n", " ").strip()
    s = (symbol or "").upper()
    if "CRASH" in s:
        decision, consensus = "SELL", "STRONG_DOWNTREND"
        confidence = 0.6
        m1_udn = h1_udn = "DOWN"
    elif "BOOM" in s:
        decision, consensus = "BUY", "STRONG_UPTREND"
        confidence = 0.6
        m1_udn = h1_udn = "UP"
    else:
        decision, consensus = "HOLD", "NEUTRAL"
        confidence = 0.5
        m1_udn = h1_udn = "NEUTRAL"
    return {
        "symbol": symbol or "UNKNOWN",
        "timeframe": timeframe,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "trend_m1": {"direction": "NEUTRAL", "change_percent": 0.0},
        "trend_m5": {"direction": "NEUTRAL", "change_percent": 0.0},
        "trend_h1": {"direction": "NEUTRAL", "change_percent": 0.0},
        "consensus": {"direction": consensus, "confidence": confidence, "uptrend_count": 0, "downtrend_count": 0},
        "decision": decision,
        "final_decision": decision,
        "confidence": confidence,
        "alignment": "neutre",
        "coherence": 0.5,
        "ml_confidence": 0.5,
        "m1_trend": m1_udn,
        "h1_trend": h1_udn,
        "h4_trend": h1_udn,
        "d1_trend": h1_udn,
        "data_points": {"m1": 0, "m5": 0, "h1": 0},
        "fallback": reason,
    }


@app.get("/trend")
async def get_trend(symbol: Optional[str] = None, timeframe: str = "M1"):
    """Endpoint principal pour l'analyse de tendance MT5. Symbol optionnel pour √©viter 422."""
    try:
        if not symbol or not symbol.strip():
            symbol = "UNKNOWN"
        symbol = symbol.strip()
        if timeframe not in ["M1", "M5", "M15", "M30", "H1", "H4", "D1"]:
            timeframe = "M1"
        logger.info(f"üìà Requ√™te tendance re√ßue pour {symbol} (timeframe: {timeframe})")

        df_m1 = _get_trend_data(symbol, "M1", 500)
        df_m5 = _get_trend_data(symbol, "M5", 200)
        df_h1 = _get_trend_data(symbol, "H1", 100)

        if df_m1 is None or df_m5 is None or df_h1 is None:
            logger.warning(f"Donn√©es historiques partielles pour {symbol}, envoi fallback")
            return _trend_fallback_response(symbol, timeframe, "partial_data")

        def calculate_trend(df):
            if df is None or len(df) < 2:
                return "NEUTRAL", 0.0
            latest = df["close"].iloc[-1]
            previous = df["close"].iloc[-2]
            if latest > previous:
                return "UPTREND", (latest - previous) / previous * 100
            if latest < previous:
                return "DOWNTREND", (previous - latest) / previous * 100
            return "NEUTRAL", 0.0

        trend_m1, change_m1 = calculate_trend(df_m1)
        trend_m5, change_m5 = calculate_trend(df_m5)
        trend_h1, change_h1 = calculate_trend(df_h1)

        uptrend_count = sum([trend_m1 == "UPTREND", trend_m5 == "UPTREND", trend_h1 == "UPTREND"])
        downtrend_count = sum([trend_m1 == "DOWNTREND", trend_m5 == "DOWNTREND", trend_h1 == "DOWNTREND"])

        if uptrend_count >= 2:
            consensus = "STRONG_UPTREND"
            confidence = min(0.9, 0.5 + (uptrend_count * 0.15))
            decision = "BUY"
        elif downtrend_count >= 2:
            consensus = "STRONG_DOWNTREND"
            confidence = min(0.9, 0.5 + (downtrend_count * 0.15))
            decision = "SELL"
        else:
            consensus = "NEUTRAL"
            confidence = 0.5
            decision = "HOLD"

        # Compatibilit√© EA: m1_trend, h1_trend, h4_trend, d1_trend (UP/DOWN/NEUTRAL)
        _to_udn = lambda s: "UP" if s == "UPTREND" else ("DOWN" if s == "DOWNTREND" else "NEUTRAL")
        m1_udn = _to_udn(trend_m1)
        h1_udn = _to_udn(trend_h1)

        # Alignement: M1/M5/H1 d'accord ou non
        if uptrend_count >= 2 or downtrend_count >= 2:
            alignment = "align√©"
        elif uptrend_count == 1 or downtrend_count == 1:
            alignment = "partiel"
        else:
            alignment = "neutre"

        # Enrichissement Supabase: ML + calibration + trade_feedback pour d√©cision finale
        ml_confidence = 0.5
        coherence = 0.5
        final_decision = decision
        final_confidence = confidence
        try:
            ctx = await fetch_supabase_ml_context(symbol, timeframe)
            ml_accuracy = ctx.get("model_accuracy", 0.5)
            drift = ctx.get("drift_factor", 1.0)
            cal_w = ctx.get("calibration_wins", 0)
            cal_t = ctx.get("calibration_total", 0)
            recent_wr = ctx.get("recent_win_rate", 0.5)
            recent_n = ctx.get("recent_count", 0)
            ml_confidence = max(0.3, min(0.95, ml_accuracy * drift))
            coherence = recent_wr if recent_n >= 5 else (cal_w / cal_t if cal_t else 0.5)
            coherence = max(0.0, min(1.0, coherence))
            # Confiance finale = tendance + ML (poids ML pour apprendre des erreurs)
            final_confidence = (confidence * 0.5 + ml_confidence * 0.5) * drift
            final_confidence = max(0.3, min(0.95, final_confidence))
            # Si coh√©rence faible (beaucoup de pertes r√©centes), r√©duire ou HOLD
            if coherence < 0.4 and decision != "HOLD":
                final_confidence = final_confidence * 0.7
                if final_confidence < 0.5:
                    final_decision = "HOLD"
        except Exception as e:
            logger.debug(f"Enrichissement Supabase /trend: {e}")

        response = {
            "symbol": symbol,
            "timeframe": timeframe,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "trend_m1": {"direction": trend_m1, "change_percent": change_m1},
            "trend_m5": {"direction": trend_m5, "change_percent": change_m5},
            "trend_h1": {"direction": trend_h1, "change_percent": change_h1},
            "consensus": {
                "direction": consensus,
                "confidence": confidence,
                "uptrend_count": uptrend_count,
                "downtrend_count": downtrend_count,
            },
            "decision": decision,
            "final_decision": final_decision,
            "confidence": final_confidence,
            "alignment": alignment,
            "coherence": round(coherence, 4),
            "ml_confidence": round(ml_confidence, 4),
            "m1_trend": m1_udn,
            "h1_trend": h1_udn,
            "h4_trend": h1_udn,
            "d1_trend": h1_udn,
            "data_points": {
                "m1": len(df_m1) if df_m1 is not None else 0,
                "m5": len(df_m5) if df_m5 is not None else 0,
                "h1": len(df_h1) if df_h1 is not None else 0,
            },
        }
        logger.info(f"‚úÖ Analyse tendance {symbol}: {final_decision} conf={final_confidence:.2f} align={alignment} coh√©rence={coherence:.2f}")
        return response
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur dans /trend: {str(e)}", exc_info=True)
        return _trend_fallback_response(symbol if isinstance(symbol, str) else "UNKNOWN", timeframe or "M1", str(e))

@app.post("/trend")
async def post_trend(request: TrendRequest):
    """Endpoint POST pour l'analyse de tendance (compat MT5 WebRequest)"""
    return await get_trend(request.symbol, request.timeframe or "M1")


def build_coherent_analysis(symbol: str, timeframes: Optional[List[str]] = None) -> dict:
    """
    Construit une analyse coh√©rente multi-timeframe (alignement des tendances).
    Utilise les donn√©es MT5 ou un fallback selon le type de symbole (Boom/Crash/Index/Forex).
    Retourne un dict compatible avec CoherentAnalysisResponse.
    """
    if not symbol or not symbol.strip():
        symbol = "UNKNOWN"
    symbol = symbol.strip()
    if timeframes is None:
        timeframes = ["D1", "H4", "H1", "M30", "M15", "M5", "M1"]
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def _fallback_coherent(sym: str, reason: str = "no_data") -> dict:
        s = sym.upper()
        if "CRASH" in s:
            decision, stability, bullish, bearish = "SELL", "medium", 0.2, 0.7
        elif "BOOM" in s:
            decision, stability, bullish, bearish = "BUY", "medium", 0.7, 0.2
        else:
            decision, stability, bullish, bearish = "HOLD", "low", 0.4, 0.4
        return {
            "status": "ok",
            "symbol": sym,
            "decision": decision,
            "direction": decision,
            "decision_type": "fallback",
            "confidence": 0.55,
            "coherence_score": 55.0,
            "stability": stability,
            "bullish_pct": bullish,
            "bearish_pct": bearish,
            "neutral_pct": 1.0 - bullish - bearish,
            "trends": {},
            "timestamp": now,
            "message": reason,
        }

    trends_per_tf = {}
    up, down, neutral = 0, 0, 0
    for tf in timeframes[:7]:
        df = _get_trend_data(symbol, tf, 200)
        if df is None or len(df) < 2:
            trends_per_tf[tf] = {"direction": "NEUTRAL", "change_percent": 0.0}
            neutral += 1
            continue
        latest = df["close"].iloc[-1]
        prev = df["close"].iloc[-2]
        if latest > prev:
            trends_per_tf[tf] = {"direction": "UPTREND", "change_percent": (latest - prev) / prev * 100}
            up += 1
        elif latest < prev:
            trends_per_tf[tf] = {"direction": "DOWNTREND", "change_percent": (prev - latest) / prev * 100}
            down += 1
        else:
            trends_per_tf[tf] = {"direction": "NEUTRAL", "change_percent": 0.0}
            neutral += 1

    total = up + down + neutral
    if total == 0:
        return _fallback_coherent(symbol, "no_data")

    bullish_pct = up / total
    bearish_pct = down / total
    neutral_pct = neutral / total
    if up >= 2 and up > down:
        decision = "BUY"
        confidence = min(0.9, 0.5 + up * 0.1)
        stability = "high" if up >= 4 else "medium"
    elif down >= 2 and down > up:
        decision = "SELL"
        confidence = min(0.9, 0.5 + down * 0.1)
        stability = "high" if down >= 4 else "medium"
    else:
        decision = "HOLD"
        confidence = 0.5
        stability = "low"

    return {
        "status": "ok",
        "symbol": symbol,
        "decision": decision,
        "direction": decision,  # compat EA (BUY/SELL/HOLD)
        "decision_type": "multi_tf",
        "confidence": round(confidence, 2),
        "coherence_score": round(confidence * 100, 1),  # compat EA
        "stability": stability,
        "bullish_pct": round(bullish_pct, 2),
        "bearish_pct": round(bearish_pct, 2),
        "neutral_pct": round(neutral_pct, 2),
        "trends": trends_per_tf,
        "timestamp": now,
        "message": None,
    }


@app.get("/coherent-analysis")
async def get_coherent_analysis(symbol: Optional[str] = None, timeframe: Optional[str] = None):
    """Endpoint GET pour l'analyse coh√©rente multi-TF. Symbol optionnel pour √©viter 422."""
    sym = (symbol or "").strip() or "UNKNOWN"
    timeframes = ["D1", "H4", "H1", "M30", "M15", "M5", "M1"]
    if timeframe:
        timeframes = [timeframe]
    return build_coherent_analysis(sym, timeframes)


@app.post("/coherent-analysis")
async def post_coherent_analysis(request: CoherentAnalysisRequest):
    """Endpoint POST pour l'analyse coh√©rente multi-TF"""
    return build_coherent_analysis(request.symbol, request.timeframes)

@app.get("/angelofspike/trend")
async def get_angelofspike_trend(symbol: str = "Boom 1000 Index", timeframe: str = "M1"):
    """Endpoint sp√©cifique pour AngelOfSpike avec √©tat du march√© inclus"""
    try:
        # Analyse de tendance standard
        direction = calculate_trend_direction(symbol, timeframe)
        confidence = calculate_trend_confidence(symbol, timeframe)
        
        # √âtat du march√©
        market_info = calculate_market_state(symbol, timeframe)
        
        response = {
            "symbol": symbol,
            "timeframe": timeframe,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "direction": direction,
            "confidence": confidence,
            "market_state": market_info["market_state"],
            "market_trend": market_info["market_trend"],
            "signal": "BUY" if direction == "buy" else "SELL" if direction == "sell" else "HOLD"
        }
        
        logger.info(f"AngelOfSpike {symbol}: {direction} (conf: {confidence:.1f}%) - √âtat: {market_info['market_state']}")
        return response
        
    except Exception as e:
        logger.error(f"Erreur AngelOfSpike trend: {e}")
        return {
            "error": f"Erreur lors de l'analyse AngelOfSpike: {str(e)}",
            "symbol": symbol,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }

@app.get("/trend/health")
async def trend_health():
    """V√©rification de sant√© pour le module de tendance"""
    return {
        "status": "ok",
        "module": "trend_analysis",
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "mt5_available": mt5_initialized
    }

@app.get("/status")
async def status():
    """Statut d√©taill√© du serveur"""
    return {
        "status": "running",
        "timestamp": datetime.now().isoformat(),
        "mt5": {
            "available": MT5_AVAILABLE,
            "initialized": mt5_initialized
        },
        "mistral": {
            "available": MISTRAL_AVAILABLE
        },
        "gemini": {
            "available": GEMINI_AVAILABLE
        },
        "backend": {
            "available": BACKEND_AVAILABLE,
            "ml_predictor": ml_predictor is not None,
            "spike_predictor": spike_predictor is not None
        },
        "ai_indicators": {
            "available": AI_INDICATORS_AVAILABLE
        },
        "cache": {
            "size": len(prediction_cache),
            "duration_seconds": CACHE_DURATION
        },
        "default_symbol": DEFAULT_SYMBOL,
        "trend_analysis": {
            "available": True,
            "mt5_available": mt5_initialized
        }
    }

@app.get("/logs")
async def get_logs(limit: int = 100):
    """R√©cup√®re les derni√®res lignes du log"""
    try:
        if not LOG_FILE.exists():
            return {"logs": [], "message": "Aucun log disponible"}
        
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            lines = f.readlines()
            recent_lines = lines[-limit:] if len(lines) > limit else lines
        
        return {
            "logs": [line.strip() for line in recent_lines],
            "total_lines": len(lines),
            "returned_lines": len(recent_lines)
        }
    except Exception as e:
        logger.error(f"Erreur lecture logs: {e}")
        return {"logs": [], "error": str(e)}

@app.post("/decisionGemma", response_model=DecisionResponse)
async def decision_gemma(request: DecisionRequest):
    """
    Endpoint avanc√© qui utilise Gemma pour l'analyse visuelle du graphique MT5
    et Gemini pour formuler la recommandation finale de trading.
    """
    try:
        # Validation des champs obligatoires
        if not request.symbol:
            raise HTTPException(status_code=422, detail="Le symbole est requis")
        
        logger.info(f"Requ√™te DecisionGemma re√ßue pour {request.symbol}")
        
        # √âtape 1: Analyse technique initiale
        action = "hold"
        confidence = 0.5
        reason = "Analyse en cours..."
        
        # Analyse RSI
        if request.rsi:
            if request.rsi < 30:
                action = "buy"
                confidence += 0.2
                reason += f"RSI survent√© ({request.rsi:.1f}). "
            elif request.rsi > 70:
                action = "sell"
                confidence += 0.2
                reason += f"RSI surachat ({request.rsi:.1f}). "
        
        # Analyse EMA
        if request.ema_fast_h1 and request.ema_slow_h1:
            if request.ema_fast_h1 > request.ema_slow_h1:
                if action != "sell":
                    action = "buy"
                    confidence += 0.15
                    reason += f"EMA H1 haussi√®re ({request.ema_fast_h1:.5f} > {request.ema_slow_h1:.5f}). "
            else:
                if action != "buy":
                    action = "sell"
                    confidence += 0.15
                    reason += f"EMA H1 baissi√®re ({request.ema_fast_h1:.5f} < {request.ema_slow_h1:.5f}). "
        
        # √âtape 2: Analyse visuelle avec Gemma (si image disponible)
        gemma_analysis = None
        sl_from_gemma = None
        tp_from_gemma = None
        
        if GEMMA_AVAILABLE and request.image_filename:
            try:
                # Construire le chemin complet de l'image depuis MT5
                mt5_image_path = os.path.join(MT5_FILES_DIR, request.image_filename)
                
                if os.path.exists(mt5_image_path):
                    gemma_prompt = f"""Analyse ce graphique {request.symbol} et identifie TOUS les objets graphiques visibles (lignes, zones, fl√®ches, labels, patterns).
                    
                    Action sugg√©r√©e: {action}
                    
                    Analyse D√âTAILL√âE demand√©e:
                    1. Identifie tous les objets graphiques visibles sur le graphique (support/r√©sistance, zones, fl√®ches de signal, patterns, etc.)
                    2. Interpr√®te leur signification pour le trading
                    3. √âvalue si ces objets confirment ou infirment l'action {action}
                    
                    R√©ponds UNIQUEMENT en JSON avec ces champs:
                    - "tendance": "haussi√®re" ou "baissi√®re" ou "neutre"
                    - "force": 1-10 (10 = tr√®s fort)
                    - "support": prix exact du support le plus proche
                    - "r√©sistance": prix exact de la r√©sistance la plus proche
                    - "stop_loss": prix optimal pour SL
                    - "take_profit": prix optimal pour TP
                    - "confirmation": true/false si tu confirmes l'action {action}
                    - "objets_graphiques": liste des objets identifi√©s (zones, lignes, patterns, etc.)
                    - "interpr√©tation_objets": explication de comment les objets graphiques influencent la d√©cision
                    """
                    
                    gemma_analysis = analyze_with_gemma(gemma_prompt, mt5_image_path)
                    
                    if gemma_analysis:
                        logger.info(f"Analyse Gemma re√ßue: {gemma_analysis[:200]}...")
                        
                        # Extraire SL/TP de la r√©ponse Gemma
                        try:
                            import re
                            sl_match = re.search(r'"stop_loss":\s*([0-9.]+)', gemma_analysis)
                            tp_match = re.search(r'"take_profit":\s*([0-9.]+)', gemma_analysis)
                            confirmation_match = re.search(r'"confirmation":\s*(true|false)', gemma_analysis)
                            
                            if sl_match:
                                sl_from_gemma = float(sl_match.group(1))
                            if tp_match:
                                tp_from_gemma = float(tp_match.group(1))
                            if confirmation_match:
                                gemma_confirms = confirmation_match.group(1) == "true"
                                if gemma_confirms:
                                    confidence += 0.25
                                else:
                                    confidence -= 0.15
                                    
                        except Exception as parse_err:
                            logger.warning(f"Erreur parsing r√©ponse Gemma: {parse_err}")
                        
                        reason += f"Analyse visuelle Gemma effectu√©e. "
                        
                else:
                    logger.warning(f"Fichier image non trouv√©: {mt5_image_path}")
                    
            except Exception as gemma_err:
                logger.error(f"Erreur analyse Gemma: {type(gemma_err).__name__}: {str(gemma_err)}", exc_info=True)
        
        # √âtape 3: Formulation finale avec Gemini
        global GEMINI_AVAILABLE, gemini_model  # D√©clarer global AVANT toute utilisation
        if GEMINI_AVAILABLE and gemini_model is not None:
            try:
                gemini_prompt = f"""En tant qu'expert trading, analyse ces donn√©es pour {request.symbol}:
                
                DONN√âES TECHNIQUES:
                - Action initiale: {action}
                - Confiance: {confidence:.2f}
                - RSI: {request.rsi} (survent√©<30, surachat>70)
                - EMA H1: rapide={request.ema_fast_h1}, lente={request.ema_slow_h1}
                - Prix actuel: bid={request.bid}, ask={request.ask}
                
                ANALYSE VISUELLE GEMMA:
                {gemma_analysis if gemma_analysis else "Non disponible"}
                
                INSTRUCTIONS:
                1. Valide ou infirme l'action initiale
                2. Donne une recommandation finale claire: BUY/SELL/HOLD
                3. Attribue une confiance finale (0.0-1.0)
                4. Fournis une raison concise (<200 caract√®res)
                5. SL/TP: {"SL=" + str(sl_from_gemma) + ", TP=" + str(tp_from_gemma) if sl_from_gemma and tp_from_gemma else "G√©n√®re des niveaux logiques"}
                
                R√©ponds UNIQUEMENT en JSON:
                {{"action": "BUY/SELL/HOLD", "confidence": 0.00, "reason": "texte concis", "sl": 0.00000, "tp": 0.00000}}
                """
                
                response = gemini_model.generate_content(gemini_prompt)
                gemini_response = response.text.strip()
                
                # Nettoyer et parser la r√©ponse JSON
                if gemini_response.startswith("```json"):
                    gemini_response = gemini_response.replace("```json", "").replace("```", "").strip()
                
                gemini_result = json.loads(gemini_response)
                
                action = gemini_result.get("action", action)
                confidence = gemini_result.get("confidence", confidence)
                reason = gemini_result.get("reason", reason)
                sl_from_gemma = gemini_result.get("sl", sl_from_gemma)
                tp_from_gemma = gemini_result.get("tp", tp_from_gemma)
                
                logger.info(f"Recommandation Gemini: {action} (conf: {confidence:.2f})")
                
            except Exception as gemini_err:
                logger.error(f"Erreur formulation Gemini: {type(gemini_err).__name__}: {str(gemini_err)}", exc_info=True)
                # Si le mod√®le est obsol√®te, d√©sactiver Gemini pour cette session
                if "NotFound" in str(gemini_err) or "404" in str(gemini_err) or "not found" in str(gemini_err).lower():
                    logger.warning("Mod√®le Gemini obsol√®te d√©tect√©. D√©sactivation de Gemini pour cette requ√™te.")
                    GEMINI_AVAILABLE = False
                    gemini_model = None
        
        # Limiter la confiance
        confidence = max(0.0, min(1.0, confidence))
        
        # Pr√©diction de spike (pour Boom/Crash)
        spike_prediction = False
        spike_zone_price = None
        
        if "Boom" in request.symbol or "Crash" in request.symbol:
            if request.volatility_regime == 1:  # High volatility
                spike_prediction = True
                spike_zone_price = request.ask if "Boom" in request.symbol else request.bid
                confidence += 0.1
        
        # Construire la r√©ponse finale
        response = DecisionResponse(
            action=action,
            confidence=confidence,
            reason=reason[:250],  # Limiter la longueur
            spike_prediction=spike_prediction,
            spike_zone_price=spike_zone_price,
            stop_loss=sl_from_gemma,
            take_profit=tp_from_gemma,
            timestamp=datetime.now().isoformat(),
            model_used="Gemma+Gemini",
            technical_analysis={
                "rsi": request.rsi,
                "ema_fast_h1": request.ema_fast_h1,
                "ema_slow_h1": request.ema_slow_h1,
                "supertrend_line": request.supertrend_line,
                "volatility_regime": request.volatility_regime
            },
            gemma_analysis=gemma_analysis[:500] if gemma_analysis else f"Mod√®le Gemini utilis√© - Confiance: {confidence:.2f}, Action: {action}"
        )
        
        logger.info(f"D√©cision finale pour {request.symbol}: {action} (conf: {confidence:.2f})")
        return response
        
    except Exception as e:
        logger.error(f"Erreur dans decision_gemma: {type(e).__name__}: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur interne: {type(e).__name__}: {str(e)}")

def _parse_decision_body(raw: bytes) -> DecisionRequest:
    """Parse le body JSON de mani√®re tol√©rante pour √©viter 422 (robot MT5 payloads variables)."""
    try:
        body = json.loads(raw.decode("utf-8") if isinstance(raw, bytes) else raw)
    except Exception:
        body = {}
    if not isinstance(body, dict):
        body = {}
    # Extraire avec coercions et valeurs par d√©faut
    def _float(v, default=0.0):
        if v is None: return default
        try: return float(v)
        except (TypeError, ValueError): return default
    def _str(v, default="UNKNOWN"):
        if v is None or v == "": return default
        return str(v).strip() or default
    symbol = _str(body.get("symbol"))
    bid = _float(body.get("bid"), 1.0)
    ask = _float(body.get("ask"), 1.0001)
    if bid >= ask:
        ask = bid + 0.0001
    return DecisionRequest(
        symbol=symbol, bid=bid, ask=ask,
        rsi=min(100, max(0, _float(body.get("rsi"), 50.0))),
        ema_fast_h1=body.get("ema_fast_h1"), ema_slow_h1=body.get("ema_slow_h1"),
        ema_fast_m1=body.get("ema_fast_m1"), ema_slow_m1=body.get("ema_slow_m1"),
        ema_fast_m5=body.get("ema_fast_m5"), ema_slow_m5=body.get("ema_slow_m5"),
        atr=_float(body.get("atr")), dir_rule=int(body.get("dir_rule", 0) or 0),
        is_spike_mode=bool(body.get("is_spike_mode", False)),
        vwap=body.get("vwap"), vwap_distance=body.get("vwap_distance"), above_vwap=body.get("above_vwap"),
        supertrend_trend=int(body.get("supertrend_trend", 0) or 0),
        supertrend_line=body.get("supertrend_line"),
        volatility_regime=int(body.get("volatility_regime", 0) or 0),
        volatility_ratio=_float(body.get("volatility_ratio"), 1.0),
        image_filename=body.get("image_filename"), deriv_patterns=body.get("deriv_patterns"),
        deriv_patterns_bullish=body.get("deriv_patterns_bullish"), deriv_patterns_bearish=body.get("deriv_patterns_bearish"),
        deriv_patterns_confidence=body.get("deriv_patterns_confidence"), timestamp=body.get("timestamp"),
    )

@app.post("/decision", response_model=DecisionResponse)
async def decision(req: Request):
    """
    Endpoint principal de d√©cision utilis√© par le robot MT5
    Parse le body manuellement pour √©viter 422 sur payloads incomplets.
    """
    try:
        raw = await req.body()
        request = _parse_decision_body(raw)
        
        logger.info(f"üéØ Requ√™te DECISION re√ßue pour {request.symbol}")
        
        # MODE SIMPLIFI√â - RoboCop v2 compatible
        if SIMPLIFIED_MODE:
            return await decision_simplified(request)
        
        # MODE COMPLET - Analyse avanc√©e
        # V√©rifier le cache d'abord
        cache_key = f"{request.symbol}_{request.bid}_{request.ask}_{request.rsi}"
        current_time = datetime.now().timestamp()
        
        if cache_key in decision_cache:
            cached_time = cache_timestamps.get(cache_key, 0)
            if current_time - cached_time < CACHE_DURATION:
                logger.debug(f"üìã Utilisation d√©cision en cache pour {request.symbol}")
                return DecisionResponse(**decision_cache[cache_key])
        
        # Analyse technique de base
        action = "hold"
        confidence = 0.5
        reason = "Analyse technique en cours..."
        
        # Analyse RSI
        if request.rsi:
            if request.rsi < 30:
                action = "buy"
                confidence += 0.15
                reason += f"RSI survent√© ({request.rsi:.1f}). "
            elif request.rsi > 70:
                action = "sell"
                confidence += 0.15
                reason += f"RSI surachat ({request.rsi:.1f}). "
        
        # Analyse EMA H1
        if request.ema_fast_h1 and request.ema_slow_h1:
            if request.ema_fast_h1 > request.ema_slow_h1:
                if action != "sell":
                    action = "buy"
                    confidence += 0.1
                    reason += f"EMA H1 haussi√®re ({request.ema_fast_h1:.5f} > {request.ema_slow_h1:.5f}). "
            else:
                if action != "buy":
                    action = "sell"
                    confidence += 0.1
                    reason += f"EMA H1 baissi√®re ({request.ema_fast_h1:.5f} < {request.ema_slow_h1:.5f}). "
        
        # Analyse des tendances multi-timeframes
        try:
            trend_data = await get_trend_data(request.symbol)
            if trend_data:
                m1_trend = trend_data.get("trend_m1", {}).get("direction", "NEUTRAL")
                m5_trend = trend_data.get("trend_m5", {}).get("direction", "NEUTRAL")
                h1_trend = trend_data.get("trend_h1", {}).get("direction", "NEUTRAL")
                
                # Compter les tendances align√©es
                uptrend_count = sum([m1_trend == "UPTREND", m5_trend == "UPTREND", h1_trend == "UPTREND"])
                downtrend_count = sum([m1_trend == "DOWNTREND", m5_trend == "DOWNTREND", h1_trend == "DOWNTREND"])
                
                if uptrend_count >= 2:
                    if action != "sell":
                        action = "buy"
                        confidence += 0.2
                        reason += "Tendance haussi√®re multi-TF. "
                elif downtrend_count >= 2:
                    if action != "buy":
                        action = "sell"
                        confidence += 0.2
                        reason += "Tendance baissi√®re multi-TF. "
                        
        except Exception as trend_err:
            logger.warning(f"Erreur analyse tendance: {trend_err}")
        
        # Ajuster la confiance selon les conditions
        if action == "hold":
            confidence = max(0.3, confidence - 0.2)  # R√©duire la confiance pour HOLD
        
        # S'assurer que la confiance est dans les limites
        confidence = max(0.0, min(1.0, confidence))
        
        # Cr√©er la r√©ponse
        response = DecisionResponse(
            action=action,
            confidence=confidence,
            reason=reason[:200],
            spike_prediction=False,
            spike_zone_price=None,
            stop_loss=None,
            take_profit=None,
            timestamp=datetime.now().isoformat(),
            model_used="Technical+Multi-TF",
            technical_analysis={
                "rsi": request.rsi,
                "ema_fast_h1": request.ema_fast_h1,
                "ema_slow_h1": request.ema_slow_h1
            }
        )
        
        # Mettre en cache
        decision_cache[cache_key] = {
            "action": response.action,
            "confidence": response.confidence,
            "reason": response.reason,
            "timestamp": response.timestamp,
            "model_used": response.model_used
        }
        cache_timestamps[cache_key] = current_time
        
        logger.info(f"‚úÖ D√âCISION {request.symbol}: {action} (conf: {confidence:.2f}) - {response.model_used}")
        return response
        
    except Exception as e:
        logger.error(f"Erreur dans decision: {type(e).__name__}: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur d√©cision: {str(e)}")
    """
    Endpoint avanc√© qui utilise Gemma pour l'analyse visuelle du graphique MT5
    et Gemini pour formuler la recommandation finale de trading.
    """
    try:
        # Validation des champs obligatoires
        if not request.symbol:
            raise HTTPException(status_code=422, detail="Le symbole est requis")
        
        logger.info(f"Requ√™te DecisionGemma re√ßue pour {request.symbol}")
        
        # √âtape 1: Analyse technique initiale
        action = "hold"
        confidence = 0.5
        reason = "Analyse en cours..."
        
        # Analyse RSI
        if request.rsi:
            if request.rsi < 30:
                action = "buy"
                confidence += 0.2
                reason += f"RSI survent√© ({request.rsi:.1f}). "
            elif request.rsi > 70:
                action = "sell"
                confidence += 0.2
                reason += f"RSI surachet√© ({request.rsi:.1f}). "
        
        # Analyse EMA
        if request.ema_fast_h1 and request.ema_slow_h1:
            if request.ema_fast_h1 > request.ema_slow_h1:
                if action != "sell":
                    action = "buy"
                    confidence += 0.15
                reason += f"EMA H1 haussi√®re ({request.ema_fast_h1:.5f} > {request.ema_slow_h1:.5f}). "
            else:
                if action != "buy":
                    action = "sell"
                    confidence += 0.15
                reason += f"EMA H1 baissi√®re ({request.ema_fast_h1:.5f} < {request.ema_slow_h1:.5f}). "
        
        # √âtape 2: Analyse visuelle avec Gemma (si image disponible)
        gemma_analysis = None
        sl_from_gemma = None
        tp_from_gemma = None
        
        if GEMMA_AVAILABLE and request.image_filename:
            try:
                # Construire le chemin complet de l'image depuis MT5
                mt5_image_path = os.path.join(MT5_FILES_DIR, request.image_filename)
                
                if os.path.exists(mt5_image_path):
                    gemma_prompt = f"""Analyse ce graphique {request.symbol} et identifie TOUS les objets graphiques visibles (lignes, zones, fl√®ches, labels, patterns).
                    
                    Action sugg√©r√©e: {action}
                    
                    Analyse D√âTAILL√âE demand√©e:
                    1. Identifie tous les objets graphiques visibles sur le graphique (support/r√©sistance, zones, fl√®ches de signal, patterns, etc.)
                    2. Interpr√®te leur signification pour le trading
                    3. √âvalue si ces objets confirment ou infirment l'action sugg√©r√©e {action}
                    
                    R√©ponds en format JSON avec ces champs:
                    - "tendance": "haussi√®re" ou "baissi√®re" ou "neutre"
                    - "force": 1-10 (10 = tr√®s fort)
                    - "support": prix exact du support le plus proche
                    - "resistance": prix exact de la r√©sistance la plus proche
                    - "stop_loss": prix optimal pour SL
                    - "take_profit": prix optimal pour TP
                    - "confirmation": true/false si tu confirmes l'action {action}
                    - "objets_graphiques": liste des objets identifi√©s (zones, lignes, patterns, etc.)
                    - "interpretation_objets": explication de comment les objets graphiques influencent la d√©cision
                    """
                    
                    gemma_analysis = analyze_with_gemma(gemma_prompt, mt5_image_path)
                    
                    if gemma_analysis:
                        logger.info(f"Analyse Gemma re√ßue: {gemma_analysis[:200]}...")
                        
                        # Extraire SL/TP de la r√©ponse Gemma
                        try:
                            import re
                            sl_match = re.search(r'"stop_loss":\s*([0-9.]+)', gemma_analysis)
                            tp_match = re.search(r'"take_profit":\s*([0-9.]+)', gemma_analysis)
                            confirmation_match = re.search(r'"confirmation":\s*(true|false)', gemma_analysis)
                            
                            if sl_match:
                                sl_from_gemma = float(sl_match.group(1))
                            if tp_match:
                                tp_from_gemma = float(tp_match.group(1))
                            if confirmation_match:
                                gemma_confirms = confirmation_match.group(1) == "true"
                                if gemma_confirms:
                                    confidence += 0.25
                                else:
                                    confidence -= 0.15
                                    
                        except Exception as parse_err:
                            logger.warning(f"Erreur parsing r√©ponse Gemma: {parse_err}")
                        
                        reason += f"Analyse visuelle Gemma effectu√©e. "
                        
                else:
                    logger.warning(f"Fichier image non trouv√©: {mt5_image_path}")
                    
            except Exception as gemma_err:
                logger.error(f"Erreur analyse Gemma: {type(gemma_err).__name__}: {str(gemma_err)}", exc_info=True)
        
        # √âtape 3: Formulation finale avec Gemini
        global GEMINI_AVAILABLE, gemini_model  # D√©clarer global AVANT toute utilisation
        if GEMINI_AVAILABLE and gemini_model is not None:
            try:
                gemini_prompt = f"""En tant qu'expert trading, analyse ces donn√©es pour {request.symbol}:
                
                DONN√âES TECHNIQUES:
                - Action initiale: {action}
                - Confiance: {confidence:.2f}
                - RSI: {request.rsi} (survent√©<30, surachet√©>70)
                - EMA H1: rapide={request.ema_fast_h1}, lente={request.ema_slow_h1}
                - Prix actuel: bid={request.bid}, ask={request.ask}
                
                ANALYSE VISUELLE GEMMA:
                {gemma_analysis if gemma_analysis else "Non disponible"}
                
                INSTRUCTIONS:
                1. Valide ou infirme l'action initiale
                2. Donne une recommandation finale claire: BUY/SELL/HOLD
                3. Attribue une confiance finale (0.0-1.0)
                4. Fournis une raison concise (<200 caract√®res)
                5. SL/TP: {"SL=" + str(sl_from_gemma) + ", TP=" + str(tp_from_gemma) if sl_from_gemma and tp_from_gemma else "G√©n√®re des niveaux logiques"}
                
                R√©ponds UNIQUEMENT en JSON:
                {{"action": "BUY/SELL/HOLD", "confidence": 0.00, "reason": "texte concis", "sl": 0.00000, "tp": 0.00000}}
                """
                
                response = gemini_model.generate_content(gemini_prompt)
                gemini_response = response.text.strip()
                
                # Nettoyer et parser la r√©ponse JSON
                if gemini_response.startswith("```json"):
                    gemini_response = gemini_response.replace("```json", "").replace("```", "").strip()
                
                gemini_result = json.loads(gemini_response)
                
                action = gemini_result.get("action", action)
                confidence = gemini_result.get("confidence", confidence)
                reason = gemini_result.get("reason", reason)
                sl_from_gemma = gemini_result.get("sl", sl_from_gemma)
                tp_from_gemma = gemini_result.get("tp", tp_from_gemma)
                
                logger.info(f"Recommandation Gemini: {action} (conf: {confidence:.2f})")
                
            except Exception as gemini_err:
                logger.error(f"Erreur formulation Gemini: {type(gemini_err).__name__}: {str(gemini_err)}", exc_info=True)
                # Si le mod√®le est obsol√®te, d√©sactiver Gemini pour cette session
                if "NotFound" in str(gemini_err) or "404" in str(gemini_err) or "not found" in str(gemini_err).lower():
                    logger.warning("Mod√®le Gemini obsol√®te d√©tect√©. D√©sactivation de Gemini pour cette requ√™te.")
                    GEMINI_AVAILABLE = False
                    gemini_model = None
        
        # Limiter la confiance
        confidence = max(0.0, min(1.0, confidence))
        
        # Pr√©diction de spike (pour Boom/Crash)
        spike_prediction = False
        spike_zone_price = None
        
        if "Boom" in request.symbol or "Crash" in request.symbol:
            if request.volatility_regime == 1:  # High volatility
                spike_prediction = True
                spike_zone_price = request.ask if "Boom" in request.symbol else request.bid
                confidence += 0.1
        
        # Construire la r√©ponse finale
        response = DecisionResponse(
            action=action,
            confidence=confidence,
            reason=reason[:250],  # Limiter la longueur
            spike_prediction=spike_prediction,
            spike_zone_price=spike_zone_price,
            stop_loss=sl_from_gemma,
            take_profit=tp_from_gemma,
            timestamp=datetime.now().isoformat(),
            model_used="Gemma+Gemini",
            technical_analysis={
                "rsi": request.rsi,
                "ema_fast_h1": request.ema_fast_h1,
                "ema_slow_h1": request.ema_slow_h1,
                "supertrend_line": request.supertrend_line,
                "volatility_regime": request.volatility_regime
            },
            gemma_analysis=gemma_analysis[:500] if gemma_analysis else f"Mod√®le Gemini utilis√© - Confiance: {confidence:.2f}, Action: {action}"
        )
        
        logger.info(f"D√©cision finale pour {request.symbol}: {action} (conf: {confidence:.2f})")
        return response
        
    except Exception as e:
        logger.error(f"Erreur dans decision_gemma: {type(e).__name__}: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur interne: {type(e).__name__}: {str(e)}")

# Fonction pour r√©cup√©rer les donn√©es de tendance avec gestion d'erreur robuste
async def get_trend_data(symbol: str):
    """R√©cup√®re les donn√©es de tendance avec timeout et gestion d'erreur"""
    try:
        import httpx
        async with httpx.AsyncClient(timeout=2.0) as client:
            response = await client.get(f"http://127.0.0.1:8001/multi_timeframe?symbol={symbol}")
            if response.status_code == 200:
                logger.debug(f"Donn√©es de tendance r√©cup√©r√©es pour {symbol}")
                return response.json()
            else:
                logger.warning(f"API tendance retourne status {response.status_code} pour {symbol}")
                return None
    except httpx.TimeoutException:
        logger.warning("‚ö†Ô∏è Timeout de l'API de tendance - Mode d√©grad√© activ√©")
        return None
    except httpx.ConnectError:
        logger.warning("‚ö†Ô∏è API de tendance indisponible - Mode d√©grad√© activ√©")
        return None
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration des donn√©es de tendance: {str(e)}")
        return None

def calculate_fractals(df: pd.DataFrame, period: int = 5) -> Dict[str, float]:
    """
    Calcule les fractals sup√©rieurs et inf√©rieurs pour identifier les zones de mouvement de prix.
    
    Args:
        df: DataFrame avec colonnes high, low, close
        period: P√©riode pour d√©tecter les fractals (d√©faut: 5)
        
    Returns:
        Dict avec 'upper_fractal' et 'lower_fractal' (0 si non trouv√©)
    """
    if len(df) < period * 2 + 1:
        return {'upper_fractal': 0.0, 'lower_fractal': 0.0}
    
    upper_fractal = 0.0
    lower_fractal = 0.0
    
    # Chercher le dernier fractal sup√©rieur (high plus √©lev√© que les p√©riodes adjacentes)
    for i in range(period, len(df) - period):
        high = df.iloc[i]['high']
        is_upper = True
        is_lower = True
        
        # V√©rifier si c'est un fractal sup√©rieur
        for j in range(i - period, i + period + 1):
            if j != i:
                if df.iloc[j]['high'] >= high:
                    is_upper = False
                    break
        
        # V√©rifier si c'est un fractal inf√©rieur
        low = df.iloc[i]['low']
        for j in range(i - period, i + period + 1):
            if j != i:
                if df.iloc[j]['low'] <= low:
                    is_lower = False
                    break
        
        if is_upper and upper_fractal == 0.0:
            upper_fractal = high
        if is_lower and lower_fractal == 0.0:
            lower_fractal = low
        
        # Si on a trouv√© les deux, on peut s'arr√™ter
        if upper_fractal > 0 and lower_fractal > 0:
            break
    
    return {'upper_fractal': upper_fractal, 'lower_fractal': lower_fractal}

def enhance_spike_prediction_with_history(df: pd.DataFrame, symbol: str) -> Dict[str, Any]:
    """
    Am√©liore la pr√©diction de spike en analysant les patterns historiques.
    
    Args:
        df: DataFrame avec donn√©es historiques
        symbol: Symbole du march√©
        
    Returns:
        Dict avec 'spike_probability', 'spike_direction', 'historical_pattern'
    """
    if len(df) < 50:
        return {'spike_probability': 0.0, 'spike_direction': None, 'historical_pattern': 'insufficient_data'}
    
    # Analyser les mouvements historiques pour d√©tecter des patterns de spike
    df['price_change'] = df['close'].pct_change()
    df['volatility'] = df['high'] - df['low']
    df['volatility_pct'] = df['volatility'] / df['close']
    
    # Calculer la moyenne et l'√©cart-type des mouvements
    avg_change = df['price_change'].abs().rolling(window=20).mean().iloc[-1]
    std_change = df['price_change'].abs().rolling(window=20).std().iloc[-1]
    
    # Mouvement r√©cent
    recent_change = abs(df['price_change'].iloc[-1])
    recent_volatility = df['volatility_pct'].iloc[-1]
    
    # D√©tecter si le mouvement r√©cent est anormalement √©lev√©
    z_score = (recent_change - avg_change) / (std_change + 1e-10)
    
    # Probabilit√© de spike bas√©e sur l'anomalie statistique
    spike_probability = min(1.0, max(0.0, (z_score - 1.0) / 2.0))  # Normaliser entre 0 et 1
    
    # Direction du spike
    spike_direction = None
    if recent_change > avg_change * 2:
        if df['price_change'].iloc[-1] > 0:
            spike_direction = 'up'
        else:
            spike_direction = 'down'
    
    # Pattern historique
    pattern = 'normal'
    if z_score > 2.5:
        pattern = 'strong_spike'
    elif z_score > 1.5:
        pattern = 'moderate_spike'
    
    return {
        'spike_probability': spike_probability,
        'spike_direction': spike_direction,
        'historical_pattern': pattern,
        'z_score': z_score,
        'recent_volatility': recent_volatility
    }

@app.post("/decision", response_model=DecisionResponse)
async def decision(request: DecisionRequest):
    # Normaliser les champs manquants pour √©viter 422 (robot MT5 peut envoyer payload incomplet)
    symbol = (request.symbol or "").strip() or "UNKNOWN"
    bid = request.bid
    ask = request.ask
    if bid is None or bid <= 0:
        bid = (ask - 0.0001) if (ask and ask > 0) else 1.0
    if ask is None or ask <= 0:
        ask = (bid + 0.0001) if (bid and bid > 0) else 1.0001
    if bid >= ask:
        ask = bid + 0.0001
    rsi = request.rsi if (request.rsi is not None and 0 <= request.rsi <= 100) else 50.0
    request = request.model_copy(update={"symbol": symbol, "bid": bid, "ask": ask, "rsi": rsi})
    logger.debug(f"üéØ D√©cision IA demand√©e pour {symbol} (bid={bid}, ask={ask})")
    try:
        # ========== AM√âLIORATIONS PRIORITAIRES - APPLIQU√âES T√îT ==========
        # 1. V√©rifier le cache court d'abord
        cached_decision = get_cached_decision(request.symbol)
        if cached_decision:
            logger.debug(f"üìã Utilisation d√©cision en cache pour {request.symbol}")
            return DecisionResponse(**cached_decision)
        
        # 2. Calculer les m√©tadonn√©es de base (pour tous les symboles)
        metadata = {}
        try:
            df_recent = get_historical_data_mt5(request.symbol, "M1", 50)
            if df_recent is not None and len(df_recent) > 20:
                metadata = calculate_boom_crash_metadata(df_recent, request.symbol, request)
                logger.debug(f"üìä M√©tadonn√©es calcul√©es pour {request.symbol}: {list(metadata.keys())}")
            else:
                metadata = {
                    'rsi': getattr(request, 'rsi', 50.0),
                    'atr_ratio': 1.0,
                    'spike_risk': False,
                    'ema_trend': 'neutral',
                    'ema_fast': 0.0,
                    'ema_slow': 0.0,
                    'ema_crossover': False,
                    'symbol': request.symbol,
                    'timestamp': datetime.now().isoformat(),
                    'data_insufficient': True
                }
        except Exception as meta_err:
            logger.warning(f"‚ö†Ô∏è Erreur m√©tadonn√©es pour {request.symbol}: {meta_err}")
            metadata = {
                'rsi': getattr(request, 'rsi', 50.0),
                'atr_ratio': 1.0,
                'spike_risk': False,
                'ema_trend': 'neutral',
                'ema_fast': 0.0,
                'ema_slow': 0.0,
                'ema_crossover': False,
                'symbol': request.symbol,
                'timestamp': datetime.now().isoformat(),
                'error': str(meta_err)
            }
        
        # ========== FIN DES AM√âLIORATIONS PR√âCOCES ==========
        
        # ========== D√âTECTION MODE INITIALISATION DEPUIS GRAPHIQUE ==========
        # D√©tecter si c'est une initialisation (premi√®re requ√™te pour ce symbole)
        initialization_mode = False
        cache_key_init = f"{request.symbol}_init"
        current_time = datetime.now().timestamp()
        
        # V√©rifier si c'est la premi√®re requ√™te pour ce symbole (dans les 10 derni√®res secondes)
        if cache_key_init not in last_updated or (current_time - last_updated.get(cache_key_init, 0)) > 10:
            initialization_mode = True
            last_updated[cache_key_init] = current_time
            logger.info(f"üîÑ MODE INITIALISATION d√©tect√© pour {request.symbol} - Analyse approfondie activ√©e")
        
        # En mode initialisation, utiliser une logique plus conservatrice et approfondie
        if initialization_mode:
            logger.info(f"üìä Initialisation: Collecte de donn√©es historiques √©tendues pour {request.symbol}...")
            
            # R√©cup√©rer plus de donn√©es historiques pour une meilleure analyse
            try:
                if MT5_AVAILABLE and mt5_initialized:
                    # R√©cup√©rer des donn√©es multi-timeframes pour analyse compl√®te
                    df_m1_init = get_historical_data_mt5(request.symbol, "M1", 500)  # Plus de donn√©es
                    df_m5_init = get_historical_data_mt5(request.symbol, "M5", 200)
                    df_h1_init = get_historical_data_mt5(request.symbol, "H1", 100)
                    
                    if df_m1_init is not None and len(df_m1_init) > 100:
                        # Analyser la tendance g√©n√©rale sur les derni√®res heures
                        price_trend = (df_m1_init['close'].iloc[-1] - df_m1_init['close'].iloc[0]) / df_m1_init['close'].iloc[0]
                        volatility_init = df_m1_init['close'].pct_change().std() * 100
                        
                        logger.info(f"üìà Analyse initialisation {request.symbol}:")
                        logger.info(f"   ‚îú‚îÄ Tendance: {price_trend:+.2%} sur {len(df_m1_init)} bougies M1")
                        logger.info(f"   ‚îú‚îÄ Volatilit√©: {volatility_init:.3f}%")
                        logger.info(f"   ‚îî‚îÄ Donn√©es: M1={len(df_m1_init) if df_m1_init is not None else 0}, "
                                  f"M5={len(df_m5_init) if df_m5_init is not None else 0}, "
                                  f"H1={len(df_h1_init) if df_h1_init is not None else 0}")
                        
                        # En mode initialisation, √™tre plus flexible mais prudent
                        # Autoriser plus de situations de trading avec des seuils r√©alistes
                        if abs(price_trend) < 0.0005 and volatility_init < 0.05:  # Seuils beaucoup plus r√©alistes
                            logger.info(f"‚ö†Ô∏è Initialisation: March√© extr√™mement calme - Recommandation HOLD conservatrice")
                            return DecisionResponse(
                                action="hold",
                                confidence=0.45,  # Plus r√©aliste
                                reason=f"Initialisation: March√© extr√™mement calme (tendance: {price_trend:+.3%}, volatilit√©: {volatility_init:.3f}%) - Attente signal plus clair",
                                spike_prediction=False,
                                spike_zone_price=None,
                                stop_loss=None,
                                take_profit=None,
                                spike_direction=None,
                                early_spike_warning=False,
                                early_spike_zone_price=None,
                                buy_zone_low=None,
                                buy_zone_high=None,
                                sell_zone_low=None,
                                sell_zone_high=None
                            )
                        else:
                            logger.info(f"‚úÖ Initialisation: Conditions acceptables pour trading - Analyse continue")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur analyse initialisation: {e}")
        
        # R√®gle stricte: Interdire les achats sur Crash et les ventes sur Boom
        symbol_lower = request.symbol.lower()
        if "crash" in symbol_lower:
            # Forcer HOLD pour tout achat sur Crash (r√®gle de s√©curit√©)
            if request.dir_rule == 1:  # 1 = BUY
                logger.debug(f"üîí Achat sur Crash bloqu√© (r√®gle s√©curit√©): {request.symbol}")
                # Appliquer les seuils de confiance m√™me pour les retards anticip√©s
                action, confidence, reason = apply_confidence_thresholds("hold", 0.1, "INTERDICTION: Achats sur Crash non autoris√©s")
                return DecisionResponse(
                    action=action,
                    confidence=confidence,
                    reason=reason,
                    spike_prediction=False,
                    spike_zone_price=None,
                    stop_loss=None,
                    take_profit=None,
                    spike_direction=None,
                    early_spike_warning=False,
                    early_spike_zone_price=None,
                    early_spike_direction=None,
                    buy_zone_low=None,
                    buy_zone_high=None,
                    sell_zone_low=None,
                    sell_zone_high=None,
                    metadata=metadata  # Toujours inclure les m√©tadonn√©es
                )
        
        if "boom" in symbol_lower:
            # Forcer HOLD pour toute vente sur Boom (r√®gle de s√©curit√©)
            # dir_rule: 1=BUY, -1=SELL, 0=neutre
            if request.dir_rule <= -1:  # SELL
                logger.debug(f"üîí Vente sur Boom bloqu√©e (r√®gle s√©curit√©): {request.symbol}")
                # Appliquer les seuils de confiance m√™me pour les retards anticip√©s
                action, confidence, reason = apply_confidence_thresholds("hold", 0.1, "INTERDICTION: Ventes sur Boom non autoris√©es")
                return DecisionResponse(
                    action=action,
                    confidence=confidence,
                    reason=reason,
                    spike_prediction=False,
                    spike_zone_price=None,
                    stop_loss=None,
                    take_profit=None,
                    spike_direction=None,
                    early_spike_warning=False,
                    early_spike_zone_price=None,
                    early_spike_direction=None,
                    buy_zone_low=None,
                    buy_zone_high=None,
                    sell_zone_low=None,
                    sell_zone_high=None,
                    metadata=metadata  # Toujours inclure les m√©tadonn√©es
                )
            
        # Log de la requ√™te re√ßue (d√©j√† logg√© par le middleware, pas besoin de r√©p√©ter)
        # logger.info(f"Requ√™te de d√©cision re√ßue pour {request.symbol}")  # Supprim√© pour √©viter duplication
        
        # V√©rifier si la d√©cision est en cache
        # IMPORTANT: Utiliser seulement le symbole pour la cl√© de cache, pas le prix
        # Car le prix change constamment et emp√™che le cache de fonctionner
        cache_key = f"{request.symbol}"
        current_time = datetime.now().timestamp()
        
        # D√©tection de mouvement en temps r√©el AVANT de v√©rifier le cache
        mid_price = (request.bid + request.ask) / 2
        realtime_movement = detect_realtime_movement(request.symbol, mid_price)
        
        # V√©rifier le cache mais avec une dur√©e r√©duite (5 secondes) pour permettre des mises √† jour fr√©quentes
        CACHE_DURATION_SHORT = 5  # 5 secondes de cache pour permettre des mises √† jour rapides
        CACHE_DURATION_VERY_SHORT = 1  # 1 seconde si mouvement d√©tect√©
        
        # Si mouvement haussier d√©tect√©, r√©duire drastiquement le cache pour √™tre plus r√©actif
        cache_duration = CACHE_DURATION_VERY_SHORT if (
            realtime_movement["direction"] == "up" and 
            realtime_movement["strength"] > 0.3 and
            realtime_movement["trend_consistent"]
        ) else CACHE_DURATION_SHORT
        
        if cache_key in prediction_cache and \
           (current_time - last_updated.get(cache_key, 0)) < cache_duration:
            cached = prediction_cache[cache_key]
            cache_age = current_time - last_updated.get(cache_key, 0)
            logger.debug(f"Retour depuis cache pour {request.symbol} (cache: {cache_age:.1f}s)")
            
            # Si mouvement haussier d√©tect√© et cache = "hold", ignorer le cache imm√©diatement
            if realtime_movement["direction"] == "up" and realtime_movement["strength"] > 0.3:
                if cached.get("action") == "hold":
                    logger.info(f"üöÄ Mouvement haussier d√©tect√© ({realtime_movement['price_change_percent']:+.3f}%) - Ignorer cache HOLD et recalculer")
                    # Ne pas retourner le cache, continuer le calcul
                elif cached.get("action") != "hold" and cached.get("confidence", 0) > 0.5:
                    # Cache valide avec action non-hold, retourner
                    return DecisionResponse(**cached)
            elif cached.get("action") != "hold" or cached.get("confidence", 0) > 0.5:
                # Cache valide normalement
                return DecisionResponse(**cached)
            else:
                # Si cache = "hold" avec faible confiance, recalculer
                logger.debug(f"Cache ignor√© pour {request.symbol} (action=hold, confiance faible) - Recalcul...")
        
        # NOUVEAU: Utiliser le syst√®me de scoring avanc√© si disponible et donn√©es historiques accessibles
        use_advanced_scoring = False
        if ADVANCED_ENTRY_SCORING_AVAILABLE and calculate_advanced_entry_score and MT5_AVAILABLE:
            try:
                # R√©cup√©rer les donn√©es historiques pour le scoring avanc√©
                df_m1 = get_historical_data_mt5(request.symbol, "M1", 100)
                if df_m1 is not None and len(df_m1) >= 50:
                    entry_data = calculate_advanced_entry_score(df_m1, request.symbol, "M1")
                    
                    # Utiliser le scoring avanc√© si le score est suffisant
                    if entry_data['entry_score'] >= 0.65 and entry_data['recommendation'] != 'HOLD':
                        use_advanced_scoring = True
                        action = entry_data['recommendation'].lower()
                        confidence = entry_data['entry_score']
                        
                        # Construire la raison avec les d√©tails
                        reason_parts = [
                            f"Score avanc√©: {entry_data['entry_score']:.1%}",
                            f"Consensus: {entry_data['consensus']:.0%}",
                        ]
                        
                        # Ajouter les facteurs principaux
                        factors_detail = []
                        for factor_name, factor_value in entry_data['factors'].items():
                            if factor_value > 0.6:
                                factors_detail.append(f"{factor_name}: {factor_value:.0%}")
                        
                        if factors_detail:
                            reason_parts.append(f"Facteurs: {', '.join(factors_detail)}")
                        
                        reason = " | ".join(reason_parts)
                        
                        # BONUS TEMPS R√âEL: Ajuster la confiance si mouvement haussier d√©tect√©
                        if realtime_movement["direction"] == "up" and realtime_movement["strength"] > 0.3:
                            if action == "buy":
                                confidence = min(confidence + 0.10, 0.98)  # +10% si BUY et mouvement haussier
                                reason_parts.append(f"RealtimeUp:+{realtime_movement['price_change_percent']:+.2f}%")
                            elif action == "hold" and realtime_movement["trend_consistent"] and (bullish_tfs >= bearish_tfs):
                                # Forcer BUY si mouvement haussier fort et scoring avanc√© = HOLD
                                action = "buy"
                                confidence = 0.60 + realtime_movement["strength"] * 0.20
                                reason_parts.append(f"RealtimeForceBUY:{realtime_movement['price_change_percent']:+.2f}%")
                                logger.info(f"üöÄ Scoring avanc√©: HOLD ‚Üí BUY (mouvement haussier temps r√©el fort)")
                        
                        logger.info(f"‚úÖ Scoring avanc√© utilis√© pour {request.symbol}: {action.upper()} "
                                  f"({confidence:.1%}) - {entry_data['reason']}")
                        
                        # Construire la r√©ponse et la mettre en cache
                        response_data = {
                            "action": action,
                            "confidence": confidence,
                            "reason": reason,
                            "spike_prediction": False,
                            "spike_zone_price": None,
                            "stop_loss": None,
                            "take_profit": None,
                            "spike_direction": None,
                            "early_spike_warning": False,
                            "early_spike_zone_price": None,
                            "early_spike_direction": None,
                            "buy_zone_low": None,
                            "buy_zone_high": None,
                            "sell_zone_low": None,
                            "sell_zone_high": None,
                            "timestamp": datetime.now().isoformat(),
                            "model_used": "AdvancedEntryScoring",
                            "technical_analysis": entry_data.get('factors', {})
                        }
                        
                        # Mettre en cache
                        prediction_cache[cache_key] = response_data
                        last_updated[cache_key] = current_time
                        
                        # Retourner la r√©ponse directement
                        return DecisionResponse(**response_data)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur scoring avanc√©, utilisation m√©thode standard: {e}")
                use_advanced_scoring = False
        
        # Analyse des indicateurs techniques
        rsi = request.rsi
        ema_fast_h1 = request.ema_fast_h1
        ema_slow_h1 = request.ema_slow_h1
        ema_fast_m1 = request.ema_fast_m1
        ema_slow_m1 = request.ema_slow_m1
        bid = request.bid
        ask = request.ask
        # mid_price d√©j√† calcul√© plus haut pour la d√©tection temps r√©el
        
        # Si le scoring avanc√© n'a pas √©t√© utilis√©, utiliser la logique standard
        if not use_advanced_scoring:
            # Logique de d√©cision basique
            action = "hold"
            confidence = 0.5
            reason = ""  # Sera construite plus bas avec les composants
        
        # Analyse RSI
        rsi_bullish = rsi is not None and rsi < 30  # Survente
        rsi_bearish = rsi is not None and rsi > 70  # Surachat
        
        # Analyse EMA H1 (tendance long terme) - V√©rifier que les valeurs ne sont pas None
        h1_bullish = False
        h1_bearish = False
        if ema_fast_h1 is not None and ema_slow_h1 is not None:
            h1_bullish = ema_fast_h1 > ema_slow_h1
            h1_bearish = ema_fast_h1 < ema_slow_h1
        
        # Analyse EMA M1 (tendance court terme) - V√©rifier que les valeurs ne sont pas None
        m1_bullish = False
        m1_bearish = False
        if ema_fast_m1 is not None and ema_slow_m1 is not None:
            m1_bullish = ema_fast_m1 > ema_slow_m1
            m1_bearish = ema_fast_m1 < ema_slow_m1
        
        # NOUVEAU: Analyse Multi-Time frames via trend_api (ULTRA-RAPIDE avec cache)
        # Interroger le service trend_api sur port 8001 pour obtenir les tendances cach√©es
        m5_bullish = False
        m5_bearish = False
        h1_bullish = False
        h1_bearish = False
        
        # Tentative de r√©cup√©ration depuis trend_api (rapide, cach√©) - H1 et M5 uniquement
        trend_api_success = False
        try:
            trend_api_url = f"http://127.0.0.1:8001/multi_timeframe?symbol={request.symbol}"
            trend_response = requests.get(trend_api_url, timeout=2)
            
            if trend_response.status_code == 200:
                trend_data = trend_response.json()
                trends = trend_data.get('trends', {})
                
                # Extraire seulement H1 et M5
                if 'M5' in trends:
                    m5_bullish = trends['M5'].get('bullish', False)
                    m5_bearish = trends['M5'].get('bearish', False)
                
                if 'H1' in trends:
                    h1_bullish = trends['H1'].get('bullish', False)
                    h1_bearish = trends['H1'].get('bearish', False)
                
                # V√©rifier si on a r√©cup√©r√© H1 et M5
                if (h1_bullish or h1_bearish) and (m5_bullish or m5_bearish):
                    trend_api_success = True
                    logger.debug(f"‚úÖ Tendances H1/M5 r√©cup√©r√©es depuis trend_api")
                else:
                    logger.warning(f"‚ö†Ô∏è trend_api r√©pond mais H1/M5 incomplets, calcul direct n√©cessaire")
            else:
                logger.warning(f"‚ö†Ô∏è trend_api r√©ponse {trend_response.status_code}, calcul direct n√©cessaire")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è trend_api indisponible: {e}, calcul direct depuis MT5")
        
        # FALLBACK: Calculer H1 et M5 directement depuis MT5 si trend_api n'a pas fourni ces donn√©es
        if not trend_api_success and MT5_AVAILABLE:
            try:
                # Initialiser MT5 si n√©cessaire (ne pas fermer si d√©j√† initialis√©)
                mt5_was_initialized_before = mt5_initialized
                mt5_initialized_temp = mt5_initialized
                if not mt5_initialized_temp:
                    mt5_initialized_temp = mt5.initialize()
                    if mt5_initialized_temp:
                        logger.debug(f"üìä MT5 initialis√© temporairement pour calcul direct H1/M5")
                
                if mt5_initialized_temp:
                    # Calculer H1 directement
                    rates_h1 = mt5.copy_rates_from_pos(request.symbol, mt5.TIMEFRAME_H1, 0, 50)
                    if rates_h1 is not None and len(rates_h1) >= 20:
                        df_h1 = pd.DataFrame(rates_h1)
                        if 'close' in df_h1.columns and len(df_h1) >= 20:
                            # EMA pour H1
                            ema_fast_h1 = df_h1['close'].ewm(span=9, adjust=False).mean()
                            ema_slow_h1 = df_h1['close'].ewm(span=21, adjust=False).mean()
                            if len(ema_fast_h1) > 0 and len(ema_slow_h1) > 0:
                                h1_bullish = bool(ema_fast_h1.iloc[-1] > ema_slow_h1.iloc[-1])
                                h1_bearish = bool(ema_fast_h1.iloc[-1] < ema_slow_h1.iloc[-1])
                                logger.info(f"üìä H1 calcul√© directement depuis MT5: {'‚Üë' if h1_bullish else '‚Üì' if h1_bearish else '‚Üí'}")
                    
                    # Calculer M5 directement (si pas d√©j√† r√©cup√©r√©)
                    if not (m5_bullish or m5_bearish):
                        rates_m5 = mt5.copy_rates_from_pos(request.symbol, mt5.TIMEFRAME_M5, 0, 50)
                        if rates_m5 is not None and len(rates_m5) >= 20:
                            df_m5 = pd.DataFrame(rates_m5)
                            if 'close' in df_m5.columns and len(df_m5) >= 20:
                                ema_fast_m5 = df_m5['close'].ewm(span=9, adjust=False).mean()
                                ema_slow_m5 = df_m5['close'].ewm(span=21, adjust=False).mean()
                                if len(ema_fast_m5) > 0 and len(ema_slow_m5) > 0:
                                    m5_bullish = bool(ema_fast_m5.iloc[-1] > ema_slow_m5.iloc[-1])
                                    m5_bearish = bool(ema_fast_m5.iloc[-1] < ema_slow_m5.iloc[-1])
                                    logger.info(f"üìä M5 calcul√© directement depuis MT5: {'‚Üë' if m5_bullish else '‚Üì' if m5_bearish else '‚Üí'}")
                    
                    # Fermer MT5 seulement si on l'a initialis√© nous-m√™mes
                    if not mt5_was_initialized_before and mt5_initialized_temp:
                        mt5.shutdown()
                        logger.debug(f"üìä MT5 ferm√© apr√®s calcul direct H1/M5")
                        
            except Exception as mt5_error:
                logger.warning(f"‚ö†Ô∏è Erreur calcul direct MT5 pour H1/M5: {mt5_error}")
        
        # NOUVEAU 2025 : Analyse VWAP (prix d'√©quilibre)
        vwap_signal_buy = False
        vwap_signal_sell = False
        if request.vwap and request.vwap > 0 and request.above_vwap is not None:
            # BUY signal renforc√© si prix EN-DESSOUS du VWAP (pas cher)
            # SELL signal renforc√© si prix AU-DESSUS du VWAP (cher)
            if not request.above_vwap:  # Prix en-dessous du VWAP
                vwap_signal_buy = True
            else:  # Prix au-dessus du VWAP
                vwap_signal_sell = True
        
        # NOUVEAU 2025 : Analyse SuperTrend (tendance moderne)
        supertrend_bullish = False
        supertrend_bearish = False
        if request.supertrend_trend is not None:
            supertrend_bullish = request.supertrend_trend > 0  # SuperTrend UP
            supertrend_bearish = request.supertrend_trend < 0  # SuperTrend DOWN
        
        # NOUVEAU 2025 : Filtre r√©gime de volatilit√©
        # √âviter les trades en r√©gime de faible volatilit√© (pas d'opportunit√©)
        volatility_ok = True
        if request.volatility_regime is not None:
            if request.volatility_regime == -1:  # Low Vol
                volatility_ok = False
                reason += " | Volatilit√© trop faible"
        
        # NOUVEAU 2025 : Analyse des patterns Deriv
        deriv_patterns_bullish = 0
        deriv_patterns_bearish = 0
        deriv_patterns_confidence = 0.0
        
        if hasattr(request, 'deriv_patterns_bullish') and request.deriv_patterns_bullish is not None:
            deriv_patterns_bullish = request.deriv_patterns_bullish
        if hasattr(request, 'deriv_patterns_bearish') and request.deriv_patterns_bearish is not None:
            deriv_patterns_bearish = request.deriv_patterns_bearish
        if hasattr(request, 'deriv_patterns_confidence') and request.deriv_patterns_confidence is not None:
            deriv_patterns_confidence = request.deriv_patterns_confidence
        
        # Initialiser les signaux avant les conditions pour √©viter UnboundLocalError
        bullish_signals_base = sum([rsi_bullish, h1_bullish, m1_bullish, vwap_signal_buy, supertrend_bullish])
        bearish_signals_base = sum([rsi_bearish, h1_bearish, m1_bearish, vwap_signal_sell, supertrend_bearish])
        bullish_signals = bullish_signals_base
        bearish_signals = bearish_signals_base

        # Poids par signal (pond√©ration multi-timeframe H1 et M5 uniquement)
        WEIGHTS = {
            "m1": 0.10,    # M1: 10% - Court terme (conserv√© pour r√©activit√©)
            "m5": 0.35,    # M5: 35% - Court terme (augment√©)
            "h1": 0.45,    # H1: 45% - Moyen terme (augment√©, plus important)
            "rsi": 0.08,   # R√©duit car moins fiable en trending
            "vwap": 0.06,
            "supertrend": 0.06,
            "patterns": 0.10,
            "sentiment": 0.05,
        }
        ALIGN_BONUS = 0.15     # Bonus si tous les timeframes align√©s
        DIVERGENCE_MALUS = -0.12
        VOL_LOW_MALUS = -0.15
        VOL_OK_BONUS = 0.03
        BASE_CONF = 0.35       # Base r√©duite car plus de timeframes
        MAX_CONF = 0.98        # Augment√© pour signaux ultra-forts
        MIN_CONF = 0.15
        HOLD_THRESHOLD = 0.03  # Seuil r√©duit pour permettre plus de signaux

        # Score directionnel pond√©r√©
        score = 0.0
        components = []
        # Canal de pr√©diction M5 (pente normalis√©e)
        channel_slope = 0.0
        try:
            rates_chan = mt5.copy_rates_from_pos(request.symbol, mt5.TIMEFRAME_M5, 0, 80)
            if rates_chan is not None and len(rates_chan) >= 30:
                df_chan = pd.DataFrame(rates_chan)
                closes_chan = df_chan['close'].tail(50)
                x_idx = np.arange(len(closes_chan))
                coeff = np.polyfit(x_idx, closes_chan.values, 1)
                last_price = float(closes_chan.iloc[-1]) if len(closes_chan) > 0 else 0.0
                if last_price > 0:
                    channel_slope = float(coeff[0]) / last_price
                if channel_slope > 0:
                    components.append("ChUp")
                elif channel_slope < 0:
                    components.append("ChDown")
        except Exception:
            pass

        # Timeframes - pond√©ration multi-niveaux
        if m1_bullish:
            score += WEIGHTS["m1"]; components.append("M1:+")
        if m1_bearish:
            score -= WEIGHTS["m1"]; components.append("M1:-")
        
        if m5_bullish:
            score += WEIGHTS["m5"]; components.append("M5:+")
        if m5_bearish:
            score -= WEIGHTS["m5"]; components.append("M5:-")
        
        if h1_bullish:
            score += WEIGHTS["h1"]; components.append("H1:+")
        if h1_bearish:
            score -= WEIGHTS["h1"]; components.append("H1:-")

        if rsi_bullish:
            score += WEIGHTS["rsi"]; components.append("RSI:+")
        if rsi_bearish:
            score -= WEIGHTS["rsi"]; components.append("RSI:-")

        if vwap_signal_buy:
            score += WEIGHTS["vwap"]; components.append("VWAP:+")
        if vwap_signal_sell:
            score -= WEIGHTS["vwap"]; components.append("VWAP:-")

        if supertrend_bullish:
            score += WEIGHTS["supertrend"]; components.append("ST:+")
        if supertrend_bearish:
            score -= WEIGHTS["supertrend"]; components.append("ST:-")

        # Patterns Deriv pond√©r√©s par leur confiance
        pattern_bonus = 0.0
        if deriv_patterns_confidence and deriv_patterns_confidence > 0.6:
            if deriv_patterns_bullish > deriv_patterns_bearish:
                pattern_bonus = WEIGHTS["patterns"] * min(deriv_patterns_bullish, 2)
                score += pattern_bonus; components.append(f"Patterns:+{pattern_bonus:.2f}")
            elif deriv_patterns_bearish > deriv_patterns_bullish:
                pattern_bonus = WEIGHTS["patterns"] * min(deriv_patterns_bearish, 2)
                score -= pattern_bonus; components.append(f"Patterns:-{pattern_bonus:.2f}")

        # Alignement / divergence multi‚Äëtimeframe (H1 et M5 uniquement)
        # Compter le nombre de timeframes align√©s
        bullish_tfs = sum([m1_bullish, m5_bullish, h1_bullish])
        bearish_tfs = sum([m1_bearish, m5_bearish, h1_bearish])
        total_tfs = 3  # M1, M5, H1
        
        # Si tous les timeframes align√©s dans la m√™me direction = tr√®s fort
        if bullish_tfs == 3:
            score += ALIGN_BONUS; components.append(f"AlignBull:3/3")
        elif bearish_tfs == 3:
            score -= ALIGN_BONUS; components.append(f"AlignBear:3/3")
        
        # Divergence (1 TF contre 2 autres)
        if abs(bullish_tfs - bearish_tfs) == 1 and bullish_tfs + bearish_tfs == 3:
            score += DIVERGENCE_MALUS; components.append("DivMed")

        # Filtre de volatilit√© (ATR / r√©gime)
        if not volatility_ok:
            score += VOL_LOW_MALUS; components.append("VolLow:-")
        elif request.volatility_regime == 1:
            score += VOL_OK_BONUS; components.append("VolHigh:+")

        # Sentiment avanc√© (sera ajout√© plus bas si dispo)
        sentiment_bonus = 0.0

        # D√©cision bas√©e sur le score directionnel
        action = "hold"
        direction_score = score
        
        # Calculer la confiance de mani√®re intelligente avec bonus pour tendances long terme
        abs_score = abs(direction_score)
        
        # Score maximum th√©orique (somme de tous les poids positifs possibles)
        max_possible_score = sum([
            WEIGHTS["m1"], WEIGHTS["m5"], WEIGHTS["h1"], WEIGHTS["rsi"],
            WEIGHTS["vwap"], WEIGHTS["supertrend"], WEIGHTS["patterns"],
            WEIGHTS["sentiment"], ALIGN_BONUS, VOL_OK_BONUS
        ])
        
        # Normaliser le score (0.0 √† 1.0)
        normalized_score = min(abs_score / max_possible_score, 1.0) if max_possible_score > 0 else 0.0
        
        # NOUVEAU CALCUL DE CONFIANCE PLUS INTELLIGENT ET R√âALISTE
        # La confiance doit refl√©ter la qualit√© du signal et permettre de trader les bonnes opportunit√©s
        
        # 1. Confiance de base proportionnelle au score
        base_confidence = MIN_CONF + (normalized_score * (MAX_CONF - MIN_CONF))
        
        # 2. BONUS UNIQUE pour tendance long terme (H1/M5) - √©liminer la redondance
        long_term_bonus = 0.0
        if h1_bullish and m5_bullish:
            long_term_bonus = 0.25  # +25% si H1 ET M5 align√©s (tendance long terme forte)
            components.append("H1+M5:++")
        elif h1_bearish and m5_bearish:
            long_term_bonus = 0.25
            components.append("H1+M5:--")
        elif (h1_bullish and m5_bearish) or (h1_bearish and m5_bullish):
            long_term_bonus = -0.15  # P√©nalit√© si H1 et M5 divergents
            components.append("H1/M5:DIVERGE")
        elif h1_bullish or m5_bullish:
            long_term_bonus = 0.10  # +10% si au moins H1 OU M5 align√©
            components.append("H1/M5:+")
        elif h1_bearish or m5_bearish:
            long_term_bonus = 0.10
            components.append("H1/M5:-")
        
        # 3. BONUS pour alignement multi-timeframe complet (tous les 3 timeframes)
        multi_tf_bonus = 0.0
        if bullish_tfs == 3:  # M1, M5, H1 tous haussiers
            multi_tf_bonus = 0.20  # +20% pour alignement parfait
            components.append("ALIGN:3/3‚Üë")
        elif bearish_tfs == 3:  # M1, M5, H1 tous baissiers
            multi_tf_bonus = 0.20
            components.append("ALIGN:3/3‚Üì")
        elif bullish_tfs == 2 or bearish_tfs == 2:  # 2 sur 3 align√©s
            multi_tf_bonus = 0.10
            components.append("ALIGN:2/3")
        
        # 4. BONUS pour qualit√© des indicateurs techniques
        technical_bonus = 0.0
        
        # RSI dans zones extr√™mes (plus fiable)
        if rsi is not None:
            if rsi < 20 or rsi > 80:
                technical_bonus += 0.08  # RSI tr√®s fiable
                components.append("RSI:EXT")
            elif rsi < 30 or rsi > 70:
                technical_bonus += 0.05  # RSI fiable
                components.append("RSI:STR")
        
        # ATR pour la volatilit√© (confiance si volatilit√© ad√©quate)
        if request.atr and request.atr > 0:
            atr_percent = (request.atr / request.bid) * 100 if request.bid > 0 else 0
            if 0.1 <= atr_percent <= 0.5:  # Volatilit√© id√©ale
                technical_bonus += 0.06
                components.append("ATR:OK")
            elif atr_percent > 1.0:  # Volatilit√© trop √©lev√©e
                technical_bonus -= 0.03
                components.append("ATR:HIGH")
        
        # 5. CONFIDANCE FINALE
        confidence = base_confidence + long_term_bonus + multi_tf_bonus + technical_bonus
        
        # Appliquer les bonus/malus de volatilit√©
        if not volatility_ok:
            confidence += VOL_LOW_MALUS
        elif request.volatility_regime == 1:
            confidence += VOL_OK_BONUS
        
        # Limiter la confiance entre MIN_CONF et MAX_CONF
        confidence = max(MIN_CONF, min(MAX_CONF, confidence))
        
        # BONUS TEMPS R√âEL: Si mouvement haussier d√©tect√© en temps r√©el, favoriser BUY
        realtime_bonus = 0.0
        if realtime_movement["direction"] == "up" and realtime_movement["strength"] > 0.3:
            if realtime_movement["trend_consistent"]:
                realtime_bonus = 0.15  # +15% si mouvement haussier coh√©rent
                components.append(f"RealtimeUp:{realtime_movement['price_change_percent']:+.2f}%")
                logger.info(f"üìà Mouvement haussier temps r√©el d√©tect√©: {realtime_movement['price_change_percent']:+.3f}% (force: {realtime_movement['strength']:.1%})")
            else:
                realtime_bonus = 0.08  # +8% si mouvement moins coh√©rent
                components.append(f"RealtimeUpWeak:{realtime_movement['price_change_percent']:+.2f}%")
        elif realtime_movement["direction"] == "down" and realtime_movement["strength"] > 0.3:
            if realtime_movement["trend_consistent"]:
                realtime_bonus = -0.10  # -10% si mouvement baissier coh√©rent
                components.append(f"RealtimeDown:{realtime_movement['price_change_percent']:+.2f}%")
        
        # Appliquer le bonus temps r√©el √† la confiance
        confidence += realtime_bonus
        
        # D√©cision finale bas√©e sur le score et les alignements de timeframe
        min_tfs_for_signal = 3
        
        if bullish_tfs >= min_tfs_for_signal and direction_score > -HOLD_THRESHOLD:
            # Au moins 3 TFs haussiers -> signal BUY m√™me si score faible
            action = "buy"
            confidence = max(confidence, 0.50)  # Minimum 50% si 3+ TFs align√©s
            components.append("3+TFs:BUY")
        elif bearish_tfs >= min_tfs_for_signal and direction_score < HOLD_THRESHOLD:
            # Au moins 3 TFs baissiers -> signal SELL m√™me si score faible
            action = "sell"
            confidence = max(confidence, 0.50)  # Minimum 50% si 3+ TFs align√©s
            components.append("3+TFs:SELL")
        elif direction_score > HOLD_THRESHOLD:
            action = "buy"
            confidence += realtime_bonus
        elif direction_score < -HOLD_THRESHOLD:
            action = "sell"
            confidence += realtime_bonus
        else:
            # NOUVEAU: Si mouvement haussier temps r√©el fort d√©tect√©, forcer BUY m√™me si score faible
            if realtime_movement["direction"] == "up" and realtime_movement["strength"] > 0.5 and realtime_movement["trend_consistent"]:
                action = "buy"
                confidence = 0.55 + realtime_bonus  # Confiance minimale de 55% pour mouvement temps r√©el fort
                components.append("RealtimeForceBUY")
                logger.info(f"üöÄ FORCE BUY: Mouvement haussier temps r√©el fort d√©tect√© ({realtime_movement['price_change_percent']:+.3f}%)")
            else:
                action = "hold"
                confidence = MIN_CONF * 0.5
        
        # 7. CONFIANCE MINIMALE GARANTIE pour signaux valides avec H1 align√©
        # Si H1 est align√©, c'est d√©j√† un signal valide = confiance minimale 0.60 (60%)
        if action != "hold" and (h1_bullish or h1_bearish):
            # Si H1 align√© avec M5, confiance minimale encore plus √©lev√©e
            if (m5_bullish) and h1_bullish:
                confidence = max(confidence, 0.70)  # 70% minimum si H1+M5
                if confidence == 0.70:
                    components.append("MinH1+M5:70%")
            elif (m5_bearish) and h1_bearish:
                confidence = max(confidence, 0.70)
                if confidence == 0.70:
                    components.append("MinH1+M5:70%")
            else:
                confidence = max(confidence, 0.60)  # 60% minimum si H1 seul
                if confidence == 0.60:
                    components.append("MinH1:60%")
        
        # 8. BONUS FINAL : Si M5+H1 align√©s, confiance minimale 0.55
        if action != "hold" and (m5_bullish and h1_bullish):
            confidence = max(confidence, 0.55)
        elif action != "hold" and (m5_bearish and h1_bearish):
            confidence = max(confidence, 0.55)

        # 8.b OVERRIDE EMA/CHANNEL: √©viter HOLD contre une tendance claire M5/H1 avec canal align√©
        if action == "hold":
            if (m5_bullish and (h1_bullish or not h1_bearish)) and channel_slope > 0:
                action = "buy"
                confidence = max(confidence, 0.55)
                components.append("EMA+Channel‚Üë")
            elif (m5_bearish and (h1_bearish or not h1_bullish)) and channel_slope < 0:
                action = "sell"
                confidence = max(confidence, 0.55)
                components.append("EMA+Channel‚Üì")

        
        # 9. Int√©gration de la d√©cision ML multi-mod√®les (Boom/Crash, Forex, Commodities, Volatility)
        ml_decision = None
        separator = "=" * 80  # S√©parateur pour les logs ML
        if BACKEND_AVAILABLE and ADAPTIVE_PREDICT_AVAILABLE:
            try:
                logger.info(separator)
                logger.info(f"ü§ñ SYST√àME ML ACTIV√â pour {request.symbol}")
                logger.info(separator)
                logger.info(f"üìä R√©cup√©ration donn√©es historiques (2000 bougies M1)...")
                
                # Utiliser la fonction g√©n√©rique qui g√®re automatiquement:
                # 1. MT5 (avec connexion auto si variables d'env disponibles)
                # 2. Fichiers CSV locaux
                # 3. API endpoint (si DATA_API_URL configur√©)
                df_ml = get_historical_data(request.symbol, "M1", 2000)
                if df_ml is not None and not df_ml.empty:
                    source_info = "MT5" if mt5_initialized else "Fallback (fichiers/API)"
                    logger.info(f"   ‚îî‚îÄ Source: {source_info}")
                
                if df_ml is not None and len(df_ml) > 200:
                    logger.info(f"‚úÖ Donn√©es ML r√©cup√©r√©es: {len(df_ml)} bougies pour {request.symbol}")
                    logger.info(f"   ‚îî‚îÄ P√©riode: {df_ml['time'].min()} ‚Üí {df_ml['time'].max()}")
                    
                    ml_decision = get_multi_model_ml_decision(request.symbol, df_ml)
                    if ml_decision and ml_decision.get("status") == "ok":
                        ml_action = ml_decision.get("action", "N/A")
                        ml_conf = ml_decision.get("confidence", 0)
                        ml_cat = ml_decision.get("trading_category", "N/A")
                        ml_model = ml_decision.get("model_name", "N/A")
                        ml_style = ml_decision.get("style", "N/A")
                        
                        logger.info(separator)
                        logger.info(f"üéØ D√âCISION ML FINALE pour {request.symbol}:")
                        logger.info(f"   ‚îú‚îÄ Action: {ml_action.upper()}")
                        logger.info(f"   ‚îú‚îÄ Confiance: {ml_conf:.1%}")
                        logger.info(f"   ‚îú‚îÄ Cat√©gorie: {ml_cat}")
                        logger.info(f"   ‚îú‚îÄ Mod√®le: {ml_model}")
                        logger.info(f"   ‚îî‚îÄ Style: {ml_style.upper()}")
                        logger.info(separator)
                    elif ml_decision and ml_decision.get("status") == "error":
                        logger.warning(f"‚ö†Ô∏è ML erreur pour {request.symbol}: {ml_decision.get('error', 'Erreur inconnue')}")
                    else:
                        logger.warning(f"‚ö†Ô∏è ML retourn√© None pour {request.symbol}")
                else:
                    logger.warning(f"‚ö†Ô∏è Donn√©es ML insuffisantes pour {request.symbol}: {len(df_ml) if df_ml is not None else 0} bougies (minimum: 200)")
            except Exception as e:
                logger.error(separator)
                logger.error(f"‚ùå ERREUR SYST√àME ML pour {request.symbol}")
                logger.error(f"   ‚îî‚îÄ {str(e)}")
                logger.error(separator, exc_info=True)
                ml_decision = None
        else:
            logger.warning(separator)
            logger.warning(f"‚ö†Ô∏è SYST√àME ML NON DISPONIBLE pour {request.symbol}")
            logger.warning(f"   ‚îú‚îÄ BACKEND: {BACKEND_AVAILABLE}")
            logger.warning(f"   ‚îú‚îÄ ADAPTIVE_PREDICT: {ADAPTIVE_PREDICT_AVAILABLE}")
            logger.warning(f"   ‚îî‚îÄ MT5: {MT5_AVAILABLE}")
            logger.warning(separator)

        # Int√©gration ML am√©lior√©e - Le ML peut maintenant surcharger les indicateurs classiques
        ml_style = None
        if isinstance(ml_decision, dict) and ml_decision.get("status") == "ok":
            ml_action = ml_decision.get("action", "hold")
            ml_conf = float(ml_decision.get("confidence", 0.0))
            ml_style = ml_decision.get("style", None)
            ml_cat = ml_decision.get("trading_category", "")
            ml_model_name = ml_decision.get("model_name", "")
            
            # Seuil r√©duit √† 0.50 pour permettre plus d'interventions ML
            if ml_conf >= 0.50 and ml_action in ("buy", "sell"):
                separator_dash = "‚îÄ" * 80
                logger.info(separator_dash)
                logger.info(f"üîÑ INT√âGRATION ML dans d√©cision finale:")
                logger.info(f"   ‚îú‚îÄ D√©cision classique: {action.upper()} @ {confidence:.1%}")
                logger.info(f"   ‚îî‚îÄ D√©cision ML: {ml_action.upper()} @ {ml_conf:.1%}")
                
                if action == "hold":
                    # Pas de d√©cision forte c√¥t√© indicateurs -> ML prend le contr√¥le
                    action = ml_action
                    confidence = ml_conf  # Utiliser directement la confiance ML
                    components.append(f"ML_PILOTE:{ml_cat}:{ml_conf:.0%}")
                    logger.info(separator)
                    logger.info(f"‚úÖ ML PREND LE CONTR√îLE - {ml_action.upper()} @ {ml_conf:.1%}")
                    logger.info(separator)
                elif action == ml_action:
                    # M√™me direction -> renforcer significativement
                    old_conf = confidence
                    confidence = max(confidence, min(MAX_CONF, (confidence * 0.4 + ml_conf * 0.6)))
                    components.append(f"ML_RENFORCE:{ml_cat}:{ml_conf:.0%}")
                    logger.info(separator)
                    logger.info(f"‚úÖ ML RENFORCE LA D√âCISION")
                    logger.info(f"   ‚îú‚îÄ Confiance avant: {old_conf:.1%}")
                    logger.info(f"   ‚îî‚îÄ Confiance apr√®s: {confidence:.1%}")
                    logger.info(separator)
                else:
                    # Conflit: ML peut surcharger si confiance √©lev√©e
                    if ml_conf >= 0.70:
                        # ML tr√®s confiant -> surcharger les indicateurs classiques
                        old_action = action
                        old_conf = confidence
                        action = ml_action
                        confidence = ml_conf * 0.9  # L√©g√®rement r√©duite pour prudence
                        components.append(f"ML_SURCHARGE:{ml_cat}:{ml_conf:.0%}")
                        logger.info(separator)
                        logger.info(f"‚ö†Ô∏è ML SURCHARGE LES INDICATEURS CLASSIQUES")
                        logger.info(f"   ‚îú‚îÄ Avant: {old_action.upper()} @ {old_conf:.1%}")
                        logger.info(f"   ‚îî‚îÄ Apr√®s: {action.upper()} @ {confidence:.1%}")
                        logger.info(separator)
                    elif ml_conf >= 0.60 and confidence < 0.60:
                        # ML mod√©r√©ment confiant mais meilleur que les indicateurs
                        old_action = action
                        old_conf = confidence
                        action = ml_action
                        confidence = ml_conf * 0.85
                        components.append(f"ML_PREFERE:{ml_cat}:{ml_conf:.0%}")
                        logger.info(separator)
                        logger.info(f"‚úÖ ML PR√âF√âR√â AUX INDICATEURS")
                        logger.info(f"   ‚îú‚îÄ Avant: {old_action.upper()} @ {old_conf:.1%}")
                        logger.info(f"   ‚îî‚îÄ Apr√®s: {action.upper()} @ {confidence:.1%}")
                        logger.info(separator)
                    else:
                        # Conflit mais indicateurs classiques plus forts OU confiance ML insuffisante pour surcharger
                        components.append(f"ML_IGNORE:{ml_cat}:{ml_conf:.0%}")
                        if ml_conf < confidence:
                            logger.info(f"‚è∏Ô∏è ML ignor√© (conflit, conf ML={ml_conf:.1%} < conf classique={confidence:.1%})")
                        else:
                            logger.info(f"‚è∏Ô∏è ML ignor√© (conflit, conf ML={ml_conf:.1%} insuffisante pour surcharger conf classique={confidence:.1%} - n√©cessite ‚â•70% ou classique <60%)")

                # Ajouter le nom du mod√®le dans les composants pour la raison finale
                if ml_model_name:
                    components.append(f"Model:{ml_model_name}")
            else:
                # M√™me si confiance < 0.50, permettre au ML de prendre le contr√¥le si action classique = "hold"
                # et que le ML a au moins une confiance minimale
                if action == "hold" and ml_conf >= 0.40 and ml_action in ("buy", "sell"):
                    action = ml_action
                    confidence = ml_conf
                    components.append(f"ML_FALLBACK:{ml_cat}:{ml_conf:.0%}")
                    logger.info(f"‚úÖ ML FALLBACK activ√© - {ml_action.upper()} @ {ml_conf:.1%} (indicateurs classiques neutres)")
                else:
                    logger.info(f"‚è∏Ô∏è ML ignor√©: confiance trop faible ({ml_conf:.1%} < 0.50) ou action=hold")


        # Harmonisation de la confiance avec l'alignement (M1/M5/H1) et la d√©cision finale
        try:
            core_bullish_count = int(m1_bullish) + int(m5_bullish) + int(h1_bullish)
            core_bearish_count = int(m1_bearish) + int(m5_bearish) + int(h1_bearish)
            if action in ("buy", "sell"):
                core_count = core_bullish_count if action == "buy" else core_bearish_count
                # Carte des seuils cibles selon l'alignement coeur (3 TF)
                if core_count >= 3:
                    target_min = 0.90
                elif core_count == 2:
                    target_min = 0.75
                elif core_count == 1:
                    target_min = 0.60
                else:
                    target_min = 0.0
                # Bonus canal si align√© avec l'action
                if (action == "buy" and channel_slope > 0) or (action == "sell" and channel_slope < 0):
                    target_min = min(MAX_CONF, target_min + 0.05)
                # Bonus fort si mouvement temps r√©el confirme et alignement 3/3
                if core_count >= 3 and realtime_movement.get("trend_consistent") and realtime_movement.get("strength", 0.0) > 0.5:
                    target_min = min(MAX_CONF, max(target_min, 0.90) + 0.03)
                confidence = max(confidence, target_min)
                components.append(f"Core{('B' if action=='buy' else 'S')}:{core_count}/3")
        except Exception as _conf_ex:
            logger.debug(f"Align/Conf harmonization skipped: {_conf_ex}")
        # 10. S'assurer que la confiance est dans les limites raisonnables
        confidence = max(0.10, min(MAX_CONF, confidence))
        
        # Initialize any potentially undefined variables to 0 for logging
        long_term_alignment_bonus = long_term_alignment_bonus if 'long_term_alignment_bonus' in locals() else 0.0
        medium_term_bonus = medium_term_bonus if 'medium_term_bonus' in locals() else 0.0
        alignment_bonus = alignment_bonus if 'alignment_bonus' in locals() else 0.0
        
        # Log d√©taill√© pour comprendre le calcul
        logger.info(f"üìä Confiance {request.symbol}: {action.upper()} | Score={direction_score:+.3f} | "
                   f"Base={base_confidence*100:.1f}% | H4/D1={long_term_bonus*100:.1f}% | H1+H4/D1={long_term_alignment_bonus*100:.1f}% | "
                   f"M5+H1={medium_term_bonus*100:.1f}% | Align={alignment_bonus*100:.1f}% | FINAL={confidence*100:.1f}%")
        
        # Construire la raison initiale structur√©e
        reason_parts = []
        if action != "hold":
            reason_parts.append(f"Signal {action.upper()}")
        reason_parts.append(f"Score={direction_score:+.3f}")
        reason_parts.append(f"Conf={confidence:.1%}")
        # Ajouter le style de trading propos√© par la ML (scalp / swing) si disponible
        if ml_style and action != "hold":
            reason_parts.append(f"Style={ml_style}")
        
        # Ajouter les composants principaux (limiter √† 5 pour √©viter trop de d√©tails)
        if components:
            main_components = components[:5]
            reason_parts.append(f"TF:{','.join(main_components)}")
        
        # Construire la raison de base
        reason = " | ".join(reason_parts) if reason_parts else "Analyse en cours"
        
        # Utiliser Gemini AI pour am√©liorer la raison si disponible
        # Note: Gemini est d√©sactiv√© par d√©faut, on utilise Mistral si disponible
        if GEMINI_AVAILABLE and reason:
            try:
                ai_prompt = f"""
Analyse de trading pour {request.symbol}:
- Prix: {mid_price:.5f} (Bid: {bid:.5f}, Ask: {ask:.5f})
- RSI: {rsi:.2f}
- EMA H1: Fast={ema_fast_h1:.5f}, Slow={ema_slow_h1:.5f}
- EMA M1: Fast={ema_fast_m1:.5f}, Slow={ema_slow_m1:.5f}
- ATR: {request.atr:.5f}
- Direction actuelle: {action}
- Confiance: {confidence:.2%}

Donne une analyse concise (1-2 phrases) expliquant pourquoi {action} est recommand√©.
Format: Analyse claire et professionnelle en fran√ßais.
"""
                ai_analysis = analyze_with_gemini(ai_prompt)
                if ai_analysis:
                    reason = f"{reason} | IA: {ai_analysis[:100]}"
            except Exception as e:
                logger.debug(f"Gemini analysis non disponible: {e}")
        
        # Alternative: Utiliser Mistral AI si disponible et Gemini non disponible
        elif MISTRAL_AVAILABLE and reason and not GEMINI_AVAILABLE:
            try:
                ai_prompt = f"Analyse trading {request.symbol}: Prix={mid_price:.5f}, RSI={rsi:.2f}, Action={action}, Confiance={confidence:.0%}. Donne analyse courte (1 phrase)."
                ai_analysis = analyze_with_ai(ai_prompt)
                if ai_analysis:
                    reason = f"{reason} | Mistral: {ai_analysis[:80]}"
            except Exception as e:
                logger.debug(f"Mistral analysis non disponible: {e}")

        # Ajustement final via r√®gles d'association (facultatif)
        try:
            items = build_items_from_request(request)
            action, confidence, reason = adjust_decision_with_rules(
                request.symbol, action, confidence, reason, items
            )
        except Exception as e:
            logger.warning(f"Erreur ajustement r√®gles d'association: {e}")

        # S'assurer que la raison est compl√®te
        # Si la raison de base n'a pas √©t√© modifi√©e par les r√®gles d'association,
        # elle contient d√©j√† les reason_parts, donc pas besoin de les r√©ajouter
        if not reason or reason == "":
            # Construire la raison depuis les parts si elle est vide
            if reason_parts:
                reason = " | ".join(reason_parts)
            else:
                reason = f"Signal {action.upper()} (confiance: {confidence:.1%})"

        stop_loss = None
        take_profit = None

        # Utiliser Gemma Local (Multimodal) si image disponible
        if GEMMA_AVAILABLE and request.image_filename:
            try:
                gemma_prompt = f"Analyse graph {request.symbol}. Action: {action}. Donne moi 3 choses: 1) Tendance 2) Support/Resistance 3) Prix exacts pour SL et TP. Format: 'SL: 1.2345 | TP: 1.2345'"
                gemma_analysis = analyze_with_gemma(gemma_prompt, request.image_filename)
                
                if gemma_analysis:
                    logger.info(f"Gemma Analysis: {gemma_analysis}")
                    reason += f" | Gemma: {gemma_analysis[:150]}"
                    
                    # Bonus de confiance si Gemma confirme
                    if action.lower() in gemma_analysis.lower():
                        confidence = min(confidence + 0.05, MAX_CONF)
                        reason_parts.append("Gemma:+")
                        
                    # Tentative d'extraction SL/TP via Regex
                    import re
                    try:
                        sl_match = re.search(r"SL:\s*([\d\.]+)", gemma_analysis, re.IGNORECASE)
                        tp_match = re.search(r"TP:\s*([\d\.]+)", gemma_analysis, re.IGNORECASE)
                        
                        if sl_match:
                            stop_loss = float(sl_match.group(1))
                            logger.info(f"Gemma SL found: {stop_loss}")
                        if tp_match:
                            take_profit = float(tp_match.group(1))
                            logger.info(f"Gemma TP found: {take_profit}")
                            
                    except Exception as parse_err:
                        logger.warning(f"Failed to parse SL/TP from Gemma: {parse_err}")

            except Exception as e:
                logger.error(f"Erreur analyse Gemma: {type(e).__name__}: {str(e)}", exc_info=True)

        if AI_INDICATORS_AVAILABLE and mt5_initialized:
            try:
                # R√©cup√©rer les donn√©es pour l'analyse avanc√©e
                df = get_historical_data_mt5(request.symbol, "M1", 100)
                if df is not None and len(df) > 20:
                    cache_key_ind = f"{request.symbol}_M1"
                    if cache_key_ind not in indicators_cache:
                        indicators_cache[cache_key_ind] = AdvancedIndicators(request.symbol, "M1")
                    
                    analyzer = indicators_cache[cache_key_ind]
                    sentiment = analyzer.calculate_market_sentiment(df)
                    
                    # Am√©liorer la d√©cision avec le sentiment
                    if sentiment.get('sentiment', 0) > 0.3:
                        sentiment_bonus = WEIGHTS.get("sentiment", 0.07)
                        score += sentiment_bonus
                        reason_parts.append("Sentiment:+")
                        reason += f" | Sentiment: {sentiment.get('trend', 'neutral')}"
                    elif sentiment.get('sentiment', 0) < -0.3:
                        sentiment_bonus = WEIGHTS.get("sentiment", 0.07)
                        score -= sentiment_bonus
                        reason_parts.append("Sentiment:-")
                        reason += f" | Sentiment: {sentiment.get('trend', 'neutral')}"
                    
                    # Ajuster la confiance selon le sentiment
                    sentiment_strength = abs(sentiment.get('sentiment', 0))
                    if sentiment_strength > 0.5:
                        confidence = min(confidence + 0.05, MAX_CONF)
            except Exception as e:
                logger.warning(f"Erreur AdvancedIndicators dans decision: {e}")
        
        # ========== D√âTECTION DE SPIKE RENFORC√âE MULTI-SYST√àME ==========
        spike_prediction = False
        spike_zone_price = None
        spike_direction = None
        early_spike_warning = False
        early_spike_zone_price = None
        early_spike_direction = None
        
        # Filtrage des symboles de volatilit√©
        is_volatility_symbol = any(vol in request.symbol for vol in ["Volatility", "Boom", "Crash", "Step Index"])
        is_boom = "Boom" in request.symbol
        is_crash = "Crash" in request.symbol
        is_step = "Step" in request.symbol
        
        if is_volatility_symbol:
            try:
                # 1. D√âTECTION ML AVANC√âE (si disponible)
                ml_spike_score = 0.0
                ml_spike_direction = None
                if SPIKE_DETECTOR_AVAILABLE:
                    try:
                        df_m1 = get_historical_data_mt5(request.symbol, "M1", 200)
                        if df_m1 is not None and len(df_m1) > 50:
                            # Pr√©diction ML
                            ml_result = predict_spike_ml(df_m1)
                            if ml_result and isinstance(ml_result, float):
                                ml_spike_score = ml_result
                                if ml_spike_score > 0.75:  # Seuil √©lev√© pour ML
                                    ml_spike_direction = is_boom  # BUY pour Boom, SELL pour Crash
                                    logger.info(f"üöÄ ML Spike d√©tect√©: {ml_spike_score:.2%} pour {request.symbol}")
                    except Exception as e:
                        logger.debug(f"Erreur d√©tection ML spike: {e}")
                
                # 2. D√âTECTION AVANC√âE MULTI-INDICATEURS (AdvancedSpikeDetector)
                advanced_score = 0.0
                advanced_direction = None
                if ADVANCED_SPIKE_DETECTOR_AVAILABLE and advanced_spike_detector:
                    try:
                        df_m1 = get_historical_data_mt5(request.symbol, "M1", 100)
                        df_m5 = get_historical_data_mt5(request.symbol, "M5", 50) if df_m1 is not None else None
                        df_m15 = get_historical_data_mt5(request.symbol, "M15", 30) if df_m1 is not None else None
                        
                        if df_m1 is not None and len(df_m1) > 20:
                            score_result = advanced_spike_detector.calculate_spike_score(
                                symbol=request.symbol,
                                rsi=rsi,
                                atr=request.atr,
                                mid_price=mid_price,
                                ema_fast_h1=request.ema_fast_h1,
                                ema_slow_h1=request.ema_slow_h1,
                                ema_fast_m1=request.ema_fast_m1,
                                ema_slow_m1=request.ema_slow_m1,
                                vwap=request.vwap if hasattr(request, 'vwap') else None,
                                supertrend_trend=1 if supertrend_bullish else (-1 if supertrend_bearish else 0),
                                volatility_ratio=request.volatility_ratio if hasattr(request, 'volatility_ratio') else None,
                                df_m1=df_m1,
                                df_m5=df_m5,
                                df_m15=df_m15
                            )
                            advanced_score = score_result.get('score', 0.0)
                            advanced_direction = score_result.get('is_buy', False)
                            if advanced_score > 0.75:
                                logger.info(f"üìä Advanced Spike Score: {advanced_score:.2%} - {score_result.get('reasons', '')}")
                    except Exception as e:
                        logger.debug(f"Erreur AdvancedSpikeDetector: {e}")
                
                # 3. D√âTECTION AVEC FRACTALS (NOUVEAU)
                fractal_upper = 0.0
                fractal_lower = 0.0
                fractal_signal = False
                if MT5_AVAILABLE:
                    try:
                        df_fractal = get_historical_data_mt5(request.symbol, "M1", 50)
                        if df_fractal is not None and len(df_fractal) > 20:
                            fractals = calculate_fractals(df_fractal, period=5)
                            fractal_upper = fractals.get('upper_fractal', 0.0)
                            fractal_lower = fractals.get('lower_fractal', 0.0)
                            
                            # V√©rifier si le prix est proche d'une zone fractal (signal de mouvement)
                            if fractal_upper > 0 and mid_price >= fractal_upper * 0.99:
                                fractal_signal = True
                                logger.info(f"üìä Fractal sup√©rieur d√©tect√©: {fractal_upper:.5f} - Prix proche")
                            elif fractal_lower > 0 and mid_price <= fractal_lower * 1.01:
                                fractal_signal = True
                                logger.info(f"üìä Fractal inf√©rieur d√©tect√©: {fractal_lower:.5f} - Prix proche")
                    except Exception as e:
                        logger.debug(f"Erreur calcul fractals: {e}")
                
                # 4. AM√âLIORATION PR√âDICTION SPIKE AVEC HISTORIQUE (NOUVEAU)
                historical_spike_data = None
                if MT5_AVAILABLE:
                    try:
                        df_history = get_historical_data_mt5(request.symbol, "M1", 200)
                        if df_history is not None and len(df_history) > 50:
                            historical_spike_data = enhance_spike_prediction_with_history(df_history, request.symbol)
                            if historical_spike_data.get('spike_probability', 0) > 0.6:
                                logger.info(f"üîÆ Pr√©diction spike historique: {historical_spike_data.get('spike_probability', 0):.2%} - Pattern: {historical_spike_data.get('historical_pattern', 'normal')}")
                    except Exception as e:
                        logger.debug(f"Erreur pr√©diction historique: {e}")
                
                # 5. D√âTECTION TRADITIONNELLE RENFORC√âE
                volatility = request.atr / mid_price if mid_price > 0 else 0
                strong_vol = volatility >= 0.003
                medium_vol = volatility >= 0.0015
                extreme_oversold = rsi is not None and rsi <= 20
                extreme_overbought = rsi is not None and rsi >= 80
                moderate_oversold = rsi is not None and rsi <= 35
                moderate_overbought = rsi is not None and rsi >= 65
                
                # Score de d√©tection traditionnelle (0-1)
                traditional_score = 0.0
                traditional_direction = None
                
                # Conditions haussi√®res (avec fractals et historique)
                bull_conditions = 0
                if strong_vol: bull_conditions += 1
                if extreme_oversold: bull_conditions += 1
                if h1_bullish and m1_bullish: bull_conditions += 1
                if request.dir_rule >= 1: bull_conditions += 1
                if vwap_signal_buy or supertrend_bullish: bull_conditions += 1
                if fractal_signal and fractal_lower > 0: bull_conditions += 1  # Prix proche fractal inf√©rieur
                if historical_spike_data and historical_spike_data.get('spike_direction') == 'up': bull_conditions += 1
                
                # Conditions baissi√®res (avec fractals et historique)
                bear_conditions = 0
                if strong_vol: bear_conditions += 1
                if extreme_overbought: bear_conditions += 1
                if h1_bearish and m1_bearish: bear_conditions += 1
                if request.dir_rule <= -1: bear_conditions += 1
                if vwap_signal_sell or supertrend_bearish: bear_conditions += 1
                if fractal_signal and fractal_upper > 0: bear_conditions += 1  # Prix proche fractal sup√©rieur
                if historical_spike_data and historical_spike_data.get('spike_direction') == 'down': bear_conditions += 1
                
                if bull_conditions >= 4:  # Au moins 4/5 conditions
                    traditional_score = 0.8 + (bull_conditions - 4) * 0.05
                    traditional_direction = True  # BUY
                elif bear_conditions >= 4:
                    traditional_score = 0.8 + (bear_conditions - 4) * 0.05
                    traditional_direction = False  # SELL
                elif bull_conditions >= 3:
                    traditional_score = 0.6
                    traditional_direction = True
                elif bear_conditions >= 3:
                    traditional_score = 0.6
                    traditional_direction = False
                
                # 4. FUSION DES SCORES (Pond√©ration intelligente)
                final_spike_score = 0.0
                final_direction = None
                score_weights = []
                
                # ML a le plus de poids si disponible et fiable
                if ml_spike_score > 0.7:
                    final_spike_score += ml_spike_score * 0.4
                    score_weights.append(f"ML:{ml_spike_score:.2%}")
                    if final_direction is None:
                        final_direction = ml_spike_direction
                
                # Advanced detector a un poids moyen
                if advanced_score > 0.7:
                    final_spike_score += advanced_score * 0.35
                    score_weights.append(f"Advanced:{advanced_score:.2%}")
                    if final_direction is None:
                        final_direction = advanced_direction
                
                # D√©tection traditionnelle comme confirmation
                if traditional_score > 0.6:
                    final_spike_score += traditional_score * 0.25
                    score_weights.append(f"Traditional:{traditional_score:.2%}")
                    if final_direction is None:
                        final_direction = traditional_direction
                
                # Normaliser le score final
                final_spike_score = min(final_spike_score, 1.0)
                
                # 5. D√âCISION FINALE
                if final_spike_score >= 0.75:  # Seuil √©lev√© pour spike confirm√©
                    spike_prediction = True
                    spike_zone_price = mid_price
                    spike_direction = final_direction if final_direction is not None else (is_boom)
                    confidence = min(confidence + 0.2, 0.95)
                    reason += f" | üöÄ SPIKE CONFIRM√â (Score: {final_spike_score:.2%}, Sources: {', '.join(score_weights)})"
                    logger.info(f"‚úÖ SPIKE D√âTECT√â pour {request.symbol}: Score={final_spike_score:.2%}, Direction={'BUY' if spike_direction else 'SELL'}")
                    
                elif final_spike_score >= 0.60:  # Pr√©-alerte
                    early_spike_warning = True
                    early_spike_zone_price = mid_price
                    early_spike_direction = final_direction if final_direction is not None else (moderate_oversold)
                    confidence = min(confidence + 0.08, 0.85)
                    reason += f" | ‚ö†Ô∏è Pr√©-alerte Spike (Score: {final_spike_score:.2%})"
                    logger.info(f"‚ö†Ô∏è Pr√©-alerte SPIKE pour {request.symbol}: Score={final_spike_score:.2%}")
                
            except Exception as e:
                logger.warning(f"Erreur d√©tection spike renforc√©e: {e}")
                logger.debug(traceback.format_exc())
        
        # Fallback: D√©tection basique si les syst√®mes avanc√©s ne sont pas disponibles
        if not spike_prediction and not early_spike_warning and is_volatility_symbol:
            # D√©tection traditionnelle simplifi√©e comme fallback
            volatility = request.atr / mid_price if mid_price > 0 else 0
            strong_vol = volatility >= 0.003
            medium_vol = volatility >= 0.0015
            extreme_oversold = rsi is not None and rsi <= 20
            extreme_overbought = rsi is not None and rsi >= 80
            moderate_oversold = rsi is not None and rsi <= 35
            moderate_overbought = rsi is not None and rsi >= 65
            
            # Spike haussier avec conditions renforc√©es
            strong_bull_spike = (
                strong_vol
                and extreme_oversold
                and h1_bullish and m1_bullish
                and request.dir_rule >= 1
                and (vwap_signal_buy or supertrend_bullish)
            )
            
            # Spike baissier avec conditions renforc√©es
            strong_bear_spike = (
                strong_vol
                and extreme_overbought
                and h1_bearish and m1_bearish
                and request.dir_rule <= -1
                and (vwap_signal_sell or supertrend_bearish)
            )
            
            # Spike pour Step Index
            step_spike = False
            if is_step:
                step_spike = (
                    strong_vol
                    and (extreme_oversold or extreme_overbought)
                    and ((h1_bullish and m1_bullish) or (h1_bearish and m1_bearish))
                    and abs(request.dir_rule) >= 1
                )
            
            if strong_bull_spike or strong_bear_spike or step_spike:
                spike_prediction = True
                spike_zone_price = mid_price
                spike_direction = strong_bull_spike or (step_spike and extreme_oversold)
                confidence = min(confidence + 0.2, 0.95)
                
                if is_boom:
                    reason += " | Spike Boom confirm√© (fallback)"
                elif is_crash:
                    reason += " | Spike Crash confirm√© (fallback)"
                elif is_step:
                    reason += " | Spike Step Index d√©tect√© (fallback)"
                else:
                    reason += " | Spike Volatilit√© confirm√© (fallback)"
            
            # Pr√©-alerte am√©lior√©e avec filtre de bruit
            elif (medium_vol and 
                  (moderate_oversold or moderate_overbought) and
                  (h1_bullish != h1_bearish) and
                  (request.volatility_ratio > 0.7 if hasattr(request, 'volatility_ratio') and request.volatility_ratio is not None else True)):
                
                early_spike_warning = True
                early_spike_zone_price = mid_price
                early_spike_direction = moderate_oversold
                confidence = min(confidence + 0.05, 0.85)
                
                if is_boom:
                    reason += " | Pr√©-alerte Spike Boom (fallback)"
                elif is_crash:
                    reason += " | Pr√©-alerte Spike Crash (fallback)"
                else:
                    reason += " | Pr√©-alerte Volatilit√© (fallback)"
            is_boom = "Boom" in request.symbol
            is_crash = "Crash" in request.symbol
            is_step = "Step" in request.symbol

            volatility = request.atr / mid_price if mid_price > 0 else 0

            # Conditions de volatilit√© plus strictes
            strong_vol = volatility >= 0.003   # Augment√© de 0.002 √† 0.003 (~0.3%)
            medium_vol = volatility >= 0.0015  # Augment√© de 0.001 √† 0.0015

            # RSI plus stricts pour √©viter les faux signaux
            extreme_oversold = rsi is not None and rsi <= 20      # Augment√© de 25 √† 20
            extreme_overbought = rsi is not None and rsi >= 80     # Augment√© de 75 √† 80
            moderate_oversold = rsi is not None and rsi <= 35      # Nouveau seuil mod√©r√©
            moderate_overbought = rsi is not None and rsi >= 65    # Nouveau seuil mod√©r√©

            # Spike haussier avec conditions renforc√©es
            strong_bull_spike = (
                strong_vol
                and extreme_oversold
                and h1_bullish and m1_bullish    # Alignement requis
                and request.dir_rule >= 1        # Direction BUY claire (pas neutre)
                and (vwap_signal_buy or supertrend_bullish)  # Confirmation additionnelle
            )

            # Spike baissier avec conditions renforc√©es
            strong_bear_spike = (
                strong_vol
                and extreme_overbought
                and h1_bearish and m1_bearish    # Alignement requis
                and request.dir_rule <= -1       # Direction SELL claire (pas neutre)
                and (vwap_signal_sell or supertrend_bearish)  # Confirmation additionnelle
            )

            # Spike pour Step Index avec conditions sp√©cifiques
            step_spike = False
            if is_step:
                step_spike = (
                    strong_vol
                    and (extreme_oversold or extreme_overbought)
                    and ((h1_bullish and m1_bullish) or (h1_bearish and m1_bearish))
                    and abs(request.dir_rule) >= 1
                )

            if strong_bull_spike or strong_bear_spike or step_spike:
                spike_prediction = True
                spike_zone_price = mid_price
                spike_direction = strong_bull_spike or (step_spike and extreme_oversold)
                confidence = min(confidence + 0.2, 0.95)  # Bonus plus important
                
                if is_boom:
                    reason += " | Spike Boom confirm√© (conditions strictes)"
                elif is_crash:
                    reason += " | Spike Crash confirm√© (conditions strictes)"
                elif is_step:
                    reason += " | Spike Step Index d√©tect√©"
                else:
                    reason += " | Spike Volatilit√© confirm√©"

            # Pr√©-alerte am√©lior√©e avec filtre de bruit
            elif (medium_vol and 
                  (moderate_oversold or moderate_overbought) and
                  (h1_bullish != h1_bearish) and  # Tendance claire sur H1
                  (request.volatility_ratio > 0.7 if hasattr(request, 'volatility_ratio') and request.volatility_ratio is not None else True)):  # Filtrer les faibles ratios
                
                early_spike_warning = True
                early_spike_zone_price = mid_price
                early_spike_direction = moderate_oversold
                confidence = min(confidence + 0.05, 0.85)  # Petit bonus de confiance
                
                if is_boom:
                    reason += " | Pr√©-alerte Spike Boom (conditions mod√©r√©es)"
                elif is_crash:
                    reason += " | Pr√©-alerte Spike Crash (conditions mod√©r√©es)"
                else:
                    reason += " | Pr√©-alerte Volatilit√© (conditions mod√©r√©es)"
        
        # Calcul des zones d'achat/vente
        buy_zone_low = None
        buy_zone_high = None
        sell_zone_low = None
        sell_zone_high = None
        
        if h1_bullish:
            buffer = request.atr * 0.5
            buy_zone_low = mid_price - buffer
            buy_zone_high = mid_price + buffer
        
        if h1_bearish:
            buffer = request.atr * 0.5
            sell_zone_low = mid_price - buffer
            sell_zone_high = mid_price + buffer
        
        # ========== VALIDATION FINALE INTELLIGENCE DES ORDRES ==========
        # S'assurer que les ordres sont vraiment intelligents avant de les envoyer
        if action != "hold":
            # 1. Validation multi-crit√®res pour BUY
            if action == "buy":
                buy_validation_score = 0.0
                buy_validation_reasons = []
                
                # Crit√®res techniques
                if h1_bullish: buy_validation_score += 0.25; buy_validation_reasons.append("H1‚Üë")
                if m5_bullish: buy_validation_score += 0.20; buy_validation_reasons.append("M5‚Üë")
                if m1_bullish: buy_validation_score += 0.1; buy_validation_reasons.append("M1‚Üë")
                if rsi_bullish: buy_validation_score += 0.1; buy_validation_reasons.append("RSI‚Üë")
                if vwap_signal_buy: buy_validation_score += 0.1; buy_validation_reasons.append("VWAP‚Üë")
                if supertrend_bullish: buy_validation_score += 0.1; buy_validation_reasons.append("ST‚Üë")
                
                # Validation ML si disponible
                if ml_decision and ml_decision.get("action") == "buy":
                    ml_conf = float(ml_decision.get("confidence", 0.0))
                    buy_validation_score += ml_conf * 0.3
                    buy_validation_reasons.append(f"ML:{ml_conf:.0%}")
                
                # Seuil minimum pour valider un BUY intelligent
                MIN_BUY_INTELLIGENCE = 0.50  # Au moins 50% de validation
                if buy_validation_score < MIN_BUY_INTELLIGENCE:
                    logger.warning(f"‚ö†Ô∏è BUY rejet√©: Score validation insuffisant ({buy_validation_score:.2f} < {MIN_BUY_INTELLIGENCE})")
                    logger.warning(f"   Raisons: {', '.join(buy_validation_reasons) if buy_validation_reasons else 'Aucune'}")
                    action = "hold"
                    confidence = max(confidence * 0.5, 0.20)  # R√©duire la confiance
                    reason += f" | BUY rejet√© (validation: {buy_validation_score:.0%} < {MIN_BUY_INTELLIGENCE:.0%})"
                else:
                    logger.info(f"‚úÖ BUY valid√©: Score={buy_validation_score:.2f} ({', '.join(buy_validation_reasons)})")
            
            # 2. Validation multi-crit√®res pour SELL
            elif action == "sell":
                sell_validation_score = 0.0
                sell_validation_reasons = []
                
                # Crit√®res techniques
                if h1_bearish: sell_validation_score += 0.25; sell_validation_reasons.append("H1‚Üì")
                if m5_bearish: sell_validation_score += 0.20; sell_validation_reasons.append("M5‚Üì")
                if m1_bearish: sell_validation_score += 0.1; sell_validation_reasons.append("M1‚Üì")
                if rsi_bearish: sell_validation_score += 0.1; sell_validation_reasons.append("RSI‚Üì")
                if vwap_signal_sell: sell_validation_score += 0.1; sell_validation_reasons.append("VWAP‚Üì")
                if supertrend_bearish: sell_validation_score += 0.1; sell_validation_reasons.append("ST‚Üì")
                
                # Validation ML si disponible
                if ml_decision and ml_decision.get("action") == "sell":
                    ml_conf = float(ml_decision.get("confidence", 0.0))
                    sell_validation_score += ml_conf * 0.3
                    sell_validation_reasons.append(f"ML:{ml_conf:.0%}")
                
                # Seuil minimum pour valider un SELL intelligent
                MIN_SELL_INTELLIGENCE = 0.50  # Au moins 50% de validation
                if sell_validation_score < MIN_SELL_INTELLIGENCE:
                    logger.warning(f"‚ö†Ô∏è SELL rejet√©: Score validation insuffisant ({sell_validation_score:.2f} < {MIN_SELL_INTELLIGENCE})")
                    logger.warning(f"   Raisons: {', '.join(sell_validation_reasons) if sell_validation_reasons else 'Aucune'}")
                    action = "hold"
                    confidence = max(confidence * 0.5, 0.20)  # R√©duire la confiance
                    reason += f" | SELL rejet√© (validation: {sell_validation_score:.0%} < {MIN_SELL_INTELLIGENCE:.0%})"
                else:
                    logger.info(f"‚úÖ SELL valid√©: Score={sell_validation_score:.2f} ({', '.join(sell_validation_reasons)})")
            
            # 3. Validation sp√©ciale en mode initialisation
            if initialization_mode and action != "hold":
                # En mode initialisation, √™tre encore plus strict
                if confidence < 0.65:  # Seuil plus √©lev√© √† l'initialisation
                    logger.info(f"üîÑ Initialisation: {action.upper()} rejet√© (confiance {confidence:.1%} < 65% requis)")
                    action = "hold"
                    confidence = 0.30
                    reason += " | Initialisation: Confiance insuffisante pour trader imm√©diatement"
        
        # Construire la r√©ponse
        response_data = {
            "action": action,
            "confidence": round(confidence, 3),
            "reason": reason,
            "spike_prediction": spike_prediction,
            "spike_zone_price": spike_zone_price,
            "spike_direction": spike_direction,
            "early_spike_warning": early_spike_warning,
            "early_spike_zone_price": early_spike_zone_price,
            "early_spike_direction": early_spike_direction,
            "buy_zone_low": buy_zone_low,
            "buy_zone_high": buy_zone_high,
            "sell_zone_low": sell_zone_low,
            "sell_zone_high": sell_zone_high,
            "stop_loss": stop_loss,
            "take_profit": take_profit
        }
        
        # Log de d√©bogage pour v√©rifier les valeurs
        init_marker = "üîÑ [INIT]" if initialization_mode else ""
        logger.info(f"‚úÖ {init_marker} D√©cision IA pour {request.symbol}: action={action}, confidence={confidence:.3f} ({confidence*100:.1f}%), reason={reason[:100]}")
        
        # ========== AM√âLIORATIONS PRIORITAIRES APPLIQU√âES ICI ==========
        
        # 1. V√©rifier le cache court d'abord
        cached_decision = get_cached_decision(request.symbol)
        if cached_decision and not initialization_mode:
            logger.debug(f"üìã Utilisation d√©cision en cache pour {request.symbol}")
            return DecisionResponse(**cached_decision)
        
        # 2. Appliquer les seuils de confiance minimum
        action, confidence, reason = apply_confidence_thresholds(action, confidence, reason)
        logger.info(f"üéØ Seuils appliqu√©s: action={action}, confidence={confidence:.3f}")
        
        # 2b. Calibration adaptative (r√©duit le d√©calage pr√©diction/mouvement r√©el)
        action, confidence, reason = apply_calibration_to_decision(
            request.symbol, action, confidence, reason, timeframe="M1"
        )
        response_data["action"] = action
        response_data["confidence"] = round(confidence, 3)
        response_data["reason"] = reason
        logger.debug(f"üìê Calibration appliqu√©e: action={action}, confidence={confidence:.3f}")
        
        # 3. Calculer les m√©tadonn√©es enrichies (pour tous les symboles)
        metadata = {}
        try:
            # Toujours essayer de calculer les m√©tadonn√©es de base
            df_recent = get_historical_data_mt5(request.symbol, "M1", 50)
            if df_recent is not None and len(df_recent) > 20:
                metadata = calculate_boom_crash_metadata(df_recent, request.symbol, request)
                logger.debug(f"üìä M√©tadonn√©es calcul√©es pour {request.symbol}: {list(metadata.keys())}")
            else:
                # M√©tadonn√©es minimales si pas assez de donn√©es
                metadata = {
                    'rsi': getattr(request, 'rsi', 50.0),
                    'atr_ratio': 1.0,
                    'spike_risk': False,
                    'ema_trend': 'neutral',
                    'ema_fast': 0.0,
                    'ema_slow': 0.0,
                    'ema_crossover': False,
                    'symbol': request.symbol,
                    'timestamp': datetime.now().isoformat(),
                    'data_insufficient': True
                }
        except Exception as meta_err:
            logger.warning(f"‚ö†Ô∏è Erreur m√©tadonn√©es pour {request.symbol}: {meta_err}")
            # Garantir les m√©tadonn√©es de base m√™me en cas d'erreur
            metadata = {
                'rsi': getattr(request, 'rsi', 50.0),
                'atr_ratio': 1.0,
                'spike_risk': False,
                'ema_trend': 'neutral',
                'ema_fast': 0.0,
                'ema_slow': 0.0,
                'ema_crossover': False,
                'symbol': request.symbol,
                'timestamp': datetime.now().isoformat(),
                'error': str(meta_err)
            }
        
        # 4. Mettre √† jour response_data avec m√©tadonn√©es (toujours incluses)
        response_data["metadata"] = convert_numpy_to_python(metadata)
        
        # 5. Mettre en cache la d√©cision am√©lior√©e
        cache_decision(request.symbol, response_data)
        
        # ========== FIN DES AM√âLIORATIONS ==========
        
        # Mise en cache (original - gard√© pour compatibilit√©)
        prediction_cache[cache_key] = response_data
        last_updated[cache_key] = current_time
        
        # Sauvegarder la pr√©diction dans le dossier MT5 Predictions pour analyse/entra√Ænement futur
        try:
            # D√©terminer le timeframe (par d√©faut M1, mais on peut le d√©duire du contexte si n√©cessaire)
            timeframe = "M1"  # Par d√©faut, le robot utilise M1 pour la plupart des d√©cisions
            # Convertir les donn√©es pour √©viter les erreurs de s√©rialisation numpy
            clean_decision = convert_numpy_to_python(response_data)
            clean_ml_decision = convert_numpy_to_python(ml_decision) if ml_decision else None
            save_prediction_to_mt5_files(
                symbol=request.symbol,
                timeframe=timeframe,
                decision=clean_decision,
                ml_decision=clean_ml_decision
            )
        except Exception as save_err:
            # Ne pas bloquer la r√©ponse si la sauvegarde √©choue
            logger.warning(f"‚ö†Ô∏è Erreur sauvegarde pr√©diction pour {request.symbol}: {save_err}")
        
        return DecisionResponse(**response_data)
        
    except Exception as e:
        logger.error(f"Erreur dans /decision: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=str(e)
        )

async def handle_raw_analysis_request(raw_request: dict, symbol: Optional[str]) -> AnalysisResponse:
    """G√®re les requ√™tes brutes (compatibilit√© MT5)"""
    logger.debug(f"Traitement d'une requ√™te brute: {raw_request}")
    symbol = raw_request.get("symbol", symbol)
    request_type = raw_request.get("request_type")
    
    if not symbol:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Le param√®tre 'symbol' est requis dans raw_request"
        )
    
    if request_type == "fibonacci_analysis":
        logger.info(f"Analyse Fibonacci demand√©e pour {symbol} (raw)")
        return generate_fibonacci_response(symbol)
    
    return await get_technical_analysis(symbol)

async def handle_analysis_request(request: AnalysisRequest) -> AnalysisResponse:
    """G√®re les requ√™tes via le mod√®le AnalysisRequest"""
    if not request.symbol:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Le champ 'symbol' est requis"
        )
    
    if request.request_type == "fibonacci_analysis":
        logger.info(f"Analyse Fibonacci demand√©e pour {request.symbol} (via request)")
        return generate_fibonacci_response(request.symbol)
    
    return await get_technical_analysis(request.symbol)

def generate_fibonacci_response(symbol: str) -> AnalysisResponse:
    """G√©n√®re une r√©ponse d'analyse Fibonacci"""
    import random
    base_price = random.uniform(
        6000 if "Boom" in symbol else 10000,
        10000 if "Boom" in symbol else 15000
    )
    fib_levels = generate_fibonacci_levels(base_price)
    
    return AnalysisResponse(
        symbol=symbol,
        timestamp=datetime.now().isoformat(),
        h1=fib_levels.get("h1", {}),
        h4=fib_levels.get("h4", {}),
        m15=fib_levels.get("m15", {})
    )

async def get_technical_analysis(symbol: str) -> AnalysisResponse:
    """Effectue une analyse technique compl√®te"""
    logger.info(f"D√©but de l'analyse technique pour {symbol}")
    
    response = {
        "symbol": symbol,
        "timestamp": datetime.now().isoformat(),
        "h1": {},
        "h4": {},
        "m15": {},
        "ete": None
    }
    
    if not mt5_initialized:
        logger.warning("MT5 non initialis√© - retour d'une r√©ponse vide")
        return AnalysisResponse(**response)
    
    try:
        # Analyse H1
        df_h1 = get_historical_data_mt5(symbol, "H1", 400)
        if df_h1 is not None and not df_h1.empty:
            response["h1"] = detect_trendlines(df_h1)
        
        # Analyse H4
        df_h4 = get_historical_data_mt5(symbol, "H4", 400)
        if df_h4 is not None and not df_h4.empty:
            response["h4"] = detect_trendlines(df_h4)
        
        # Analyse M15
        df_m15 = get_historical_data_mt5(symbol, "M15", 400)
        if df_m15 is not None and not df_m15.empty:
            response["m15"] = detect_trendlines(df_m15)
            
    except Exception as e:
        logger.error(f"Erreur lors de l'analyse technique: {str(e)}", exc_info=True)
        # On continue avec les donn√©es disponibles
    
    return AnalysisResponse(**response)

@app.get("/analysis", response_model=AnalysisResponse)
@app.post("/analysis", response_model=AnalysisResponse)
async def analysis(
    symbol: Optional[str] = None,
    request: Optional[AnalysisRequest] = None,
    raw_request: Optional[dict] = Body(None, embed=True)
):
    """
    Analyse compl√®te de la structure de march√© (H1, H4, M15)
    Inclut les trendlines, figures chartistes et analyse Fibonacci
    
    Args:
        symbol: Symbole √† analyser (peut √™tre fourni en param√®tre de requ√™te ou dans le body)
        request: Objet de requ√™te Pydantic (pour les requ√™tes POST JSON)
        raw_request: Corps brut de la requ√™te (pour compatibilit√© MT5)
        
    Returns:
        AnalysisResponse: R√©ponse contenant l'analyse technique
    """
    try:
        # Extraire le symbole de request si fourni (POST avec AnalysisRequest)
        if request is not None and hasattr(request, 'symbol') and request.symbol:
            symbol = symbol or request.symbol
        if raw_request is not None and isinstance(raw_request, dict) and raw_request.get('symbol'):
            symbol = symbol or raw_request.get('symbol')
        # Journalisation de la requ√™te
        logger.info(f"Requ√™te /analysis re√ßue - symbol: {symbol}, "
                  f"request: {request}, raw_request: {raw_request}")
        # Si raw_request est un dictionnaire vide, le traiter comme None
        if raw_request == {}:
            raw_request = None
        # V√©rification des param√®tres d'entr√©e
        if symbol is None and request is None and raw_request is None:
            # Essayer de r√©cup√©rer les donn√©es directement du corps de la requ√™te
            if request is not None:
                body = await request.body()
                if body:
                    try:
                        data = json.loads(body)
                        if 'symbol' in data:
                            symbol = data['symbol']
                            logger.info(f"Symbole extrait du corps de la requ√™te: {symbol}")
                        elif 'raw_request' in data and isinstance(data['raw_request'], dict) and 'symbol' in data['raw_request']:
                            return await handle_raw_analysis_request(data['raw_request'], None)
                    except json.JSONDecodeError:
                        pass
                    
            if symbol is None:
                logger.warning("Aucun symbole fourni pour /analysis - retour r√©ponse minimale")
                return AnalysisResponse(
                    symbol="UNKNOWN",
                    timestamp=datetime.now().isoformat(),
                    h1={}, h4={}, m15={}, ete=None
                )

        # Traitement des diff√©rentes sources de donn√©es
        if raw_request is not None:
            if isinstance(raw_request, dict):
                return await handle_raw_analysis_request(raw_request, symbol)
            else:
                logger.warning(f"Format de raw_request non pris en charge: {type(raw_request)}")
                
        if request is not None:
            return await handle_analysis_request(request)
            
        if symbol is not None:
            logger.info(f"Analyse technique standard pour {symbol}")
            return await get_technical_analysis(symbol)
            
    except HTTPException as http_exc:
        # On laisse passer les exceptions HTTP d√©j√† d√©finies
        logger.warning(f"Erreur HTTP dans /analysis: {str(http_exc.detail)}")
        raise
        
    except Exception as e:
        logger.error(f"Erreur inattendue dans /analysis: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Une erreur est survenue lors du traitement de la requ√™te: {str(e)}"
        )

@app.get("/time_windows/{symbol:path}", response_model=TimeWindowsResponse)
async def time_windows(symbol: str):
    """
    Retourne les fen√™tres horaires optimales pour trader un symbole
    """
    try:
        logger.info(f"Requ√™te /time_windows pour {symbol}")
        
        preferred_hours = []
        forbidden_hours = []
        
        # Logique bas√©e sur le type de symbole
        if "Boom" in symbol or "Crash" in symbol:
            preferred_hours = [8, 9, 10, 11, 14, 15, 16, 17]
            forbidden_hours = [0, 1, 2, 3, 4, 5]
        elif "Volatility" in symbol:
            preferred_hours = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18]
            forbidden_hours = [22, 23, 0, 1, 2, 3, 4, 5]
        else:
            preferred_hours = [9, 10, 11, 12, 13, 14, 15, 16]
            forbidden_hours = [22, 23, 0, 1, 2, 3, 4, 5]
        
        return TimeWindowsResponse(
            symbol=symbol,
            preferred_hours=preferred_hours,
            forbidden_hours=forbidden_hours
        )
        
    except Exception as e:
        logger.error(f"Erreur dans /time_windows: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/predict/{symbol}")
async def predict(symbol: str, timeframe: str = "M1"):
    """
    Pr√©dit la tendance pour un symbole donn√© (endpoint legacy)
    """
    try:
        cache_key = f"{symbol}_{timeframe}"
        current_time = datetime.now().timestamp()
        
        if cache_key in prediction_cache and \
           (current_time - last_updated.get(cache_key, 0)) < CACHE_DURATION:
            return prediction_cache[cache_key]
        
        # Utiliser le pr√©dicteur ML si disponible
        if ml_predictor and mt5_initialized:
            try:
                df = get_historical_data_mt5(symbol, timeframe, 500)
                if df is not None and len(df) > 100:
                    features = ml_predictor.create_advanced_features(df)
                    if not features.empty:
                        prediction_result = ml_predictor.predict_direction(features.iloc[-1:])
                        if prediction_result:
                            prediction = {
                                "symbol": symbol,
                                "timeframe": timeframe,
                                "timestamp": datetime.now().isoformat(),
                                "prediction": prediction_result,
                                "source": "ML"
                            }
                            prediction_cache[cache_key] = prediction
                            last_updated[cache_key] = current_time
                            return prediction
            except Exception as e:
                logger.warning(f"Erreur pr√©diction ML: {e}")
        
        # Fallback: simulation de pr√©diction
        prediction = {
            "symbol": symbol,
            "timeframe": timeframe,
            "timestamp": datetime.now().isoformat(),
            "prediction": {
                "direction": "UP" if hash(symbol + timeframe) % 2 == 0 else "DOWN",
                "confidence": round(0.5 + (hash(symbol) % 51) / 100, 2),
                "price_target": 1000 + (hash(symbol) % 1000) / 100,
                "stop_loss": 900 + (hash(symbol) % 200) / 100,
                "take_profit": 1100 + (hash(symbol) % 300) / 100,
                "time_horizon": "1h"
            },
            "analysis": {
                "trend_strength": 70 + (hash(symbol) % 31),
                "volatility": 30 + (hash(symbol) % 50),
                "volume": 50 + (hash(symbol) % 51),
                "rsi": 30 + (hash(symbol) % 61),
                "macd": "BULLISH" if hash(symbol) % 2 == 0 else "BEARISH"
            },
            "source": "fallback"
        }
        
        prediction_cache[cache_key] = prediction
        last_updated[cache_key] = current_time
        
        return prediction
        
    except Exception as e:
        logger.error(f"Erreur dans /predict: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/analyze/{symbol}")
async def analyze(symbol: str):
    """
    Analyse compl√®te d'un symbole sur plusieurs timeframes (endpoint legacy)
    """
    try:
        analysis = {
            "symbol": symbol,
            "timestamp": datetime.now().isoformat(),
            "timeframes": {}
        }
        
        timeframes = ["M1", "M5", "M15", "H1", "H4", "D1"]
        for tf in timeframes:
            prediction = await predict(symbol, tf)
            analysis["timeframes"][tf] = prediction.get("prediction", {})
        
        return analysis
        
    except Exception as e:
        logger.error(f"Erreur dans /analyze: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# Mod√®le pour la requ√™te de pr√©diction de prix
class PricePredictionRequest(BaseModel):
    symbol: str
    current_price: float
    bars_to_predict: int = 200
    timeframe: str = "M1"
    history_bars: Optional[int] = 200
    history: Optional[List[float]] = None  # Donn√©es historiques fournies par le robot MQ5
    history_ohlc: Optional[Dict[str, List[float]]] = None  # Donn√©es OHLC compl√®tes (open, high, low, close)

# ============================================================================
# FONCTIONS D'ANALYSE DES PATTERNS DE BOUGIES ET STRUCTURE DU MARCH√â
# ============================================================================

def analyze_candlestick_patterns(df: pd.DataFrame, lookback: int = 10) -> Dict[str, Any]:
    """
    Analyse les patterns de bougies pass√©es pour pr√©dire le mouvement futur.
    """
    if len(df) < lookback + 2:
        return {
            'pattern_type': 'NONE',
            'bullish_pattern': False,
            'bearish_pattern': False,
            'reversal_signal': False
        }
    
    recent = df.tail(lookback + 2).copy()
    patterns = {
        'pattern_type': 'NONE',
        'bullish_pattern': False,
        'bearish_pattern': False,
        'reversal_signal': False
    }
    
    # Calculer les caract√©ristiques des bougies
    if 'open' in recent.columns and 'high' in recent.columns and 'low' in recent.columns and 'close' in recent.columns:
        recent['body'] = abs(recent['close'] - recent['open'])
        recent['range'] = recent['high'] - recent['low']
        recent['upper_shadow'] = recent['high'] - recent[['open', 'close']].max(axis=1)
        recent['lower_shadow'] = recent[['open', 'close']].min(axis=1) - recent['low']
        recent['is_bullish'] = recent['close'] > recent['open']
        
        # Analyser les derni√®res bougies pour d√©tecter des patterns
        if len(recent) >= 2:
            last_candle = recent.iloc[-1]
            prev_candle = recent.iloc[-2]
            
            # Bullish Engulfing
            if (prev_candle['close'] < prev_candle['open'] and  # Bougie rouge pr√©c√©dente
                last_candle['close'] > last_candle['open'] and  # Bougie verte actuelle
                last_candle['open'] < prev_candle['close'] and  # Ouvre en dessous
                last_candle['close'] > prev_candle['open']):     # Cl√¥ture au-dessus
                patterns['pattern_type'] = 'BULLISH_ENGULFING'
                patterns['bullish_pattern'] = True
                patterns['reversal_signal'] = True
            
            # Bearish Engulfing
            elif (prev_candle['close'] > prev_candle['open'] and  # Bougie verte pr√©c√©dente
                  last_candle['close'] < last_candle['open'] and  # Bougie rouge actuelle
                  last_candle['open'] > prev_candle['close'] and  # Ouvre au-dessus
                  last_candle['close'] < prev_candle['open']):     # Cl√¥ture en dessous
                patterns['pattern_type'] = 'BEARISH_ENGULFING'
                patterns['bearish_pattern'] = True
                patterns['reversal_signal'] = True
            
            # Hammer (marteau) - signal haussier
            elif (last_candle['range'] > 0 and
                  last_candle['lower_shadow'] > last_candle['body'] * 2 and
                  last_candle['upper_shadow'] < last_candle['body'] * 0.5):
                patterns['pattern_type'] = 'HAMMER'
                patterns['bullish_pattern'] = True
                patterns['reversal_signal'] = True
            
            # Shooting Star - signal baissier
            elif (last_candle['range'] > 0 and
                  last_candle['upper_shadow'] > last_candle['body'] * 2 and
                  last_candle['lower_shadow'] < last_candle['body'] * 0.5):
                patterns['pattern_type'] = 'SHOOTING_STAR'
                patterns['bearish_pattern'] = True
                patterns['reversal_signal'] = True
            
            # Doji - ind√©cision
            elif (last_candle['range'] > 0 and
                  last_candle['body'] < last_candle['range'] * 0.1):
                patterns['pattern_type'] = 'DOJI'
                patterns['reversal_signal'] = True
    
    return patterns

def analyze_market_structure(df: pd.DataFrame, lookback: int = 20) -> Dict[str, Any]:
    """
    Analyse la structure du march√© (higher highs, lower lows) pour d√©terminer la tendance.
    """
    if len(df) < lookback:
        return {
            'trend': 'neutral',
            'strength': 0.0,
            'swing_highs': [],
            'swing_lows': []
        }
    
    recent = df.tail(lookback).copy()
    structure = {
        'trend': 'neutral',
        'strength': 0.0,
        'swing_highs': [],
        'swing_lows': []
    }
    
    if 'high' in recent.columns and 'low' in recent.columns:
        highs = recent['high'].values
        lows = recent['low'].values
        
        # D√©tecter les swing highs et lows
        for i in range(2, len(recent) - 2):
            # Swing high
            if highs[i] > highs[i-1] and highs[i] > highs[i-2] and highs[i] > highs[i+1] and highs[i] > highs[i+2]:
                structure['swing_highs'].append((i, highs[i]))
            # Swing low
            if lows[i] < lows[i-1] and lows[i] < lows[i-2] and lows[i] < lows[i+1] and lows[i] < lows[i+2]:
                structure['swing_lows'].append((i, lows[i]))
        
        # D√©terminer la tendance bas√©e sur les swing points
        if len(structure['swing_highs']) >= 2 and len(structure['swing_lows']) >= 2:
            # Higher highs et higher lows = uptrend
            if (structure['swing_highs'][-1][1] > structure['swing_highs'][-2][1] and
                structure['swing_lows'][-1][1] > structure['swing_lows'][-2][1]):
                structure['trend'] = 'uptrend'
                structure['strength'] = min(0.005, abs(structure['swing_highs'][-1][1] - structure['swing_highs'][-2][1]) / recent['close'].iloc[-1])
            # Lower highs et lower lows = downtrend
            elif (structure['swing_highs'][-1][1] < structure['swing_highs'][-2][1] and
                  structure['swing_lows'][-1][1] < structure['swing_lows'][-2][1]):
                structure['trend'] = 'downtrend'
                structure['strength'] = min(0.005, abs(structure['swing_lows'][-1][1] - structure['swing_lows'][-2][1]) / recent['close'].iloc[-1])
    
    return structure

def analyze_candle_characteristics(df: pd.DataFrame, lookback: int = 10) -> Dict[str, Any]:
    """
    Analyse les caract√©ristiques moyennes des bougies pass√©es (taille, ratio corps/m√®ches).
    """
    if len(df) < lookback:
        return {
            'avg_body_ratio': 0.5,
            'avg_upper_shadow_ratio': 0.2,
            'avg_lower_shadow_ratio': 0.2
        }
    
    recent = df.tail(lookback).copy()
    characteristics = {
        'avg_body_ratio': 0.5,
        'avg_upper_shadow_ratio': 0.2,
        'avg_lower_shadow_ratio': 0.2
    }
    
    if 'open' in recent.columns and 'high' in recent.columns and 'low' in recent.columns and 'close' in recent.columns:
        recent['body'] = abs(recent['close'] - recent['open'])
        recent['range'] = recent['high'] - recent['low']
        recent['upper_shadow'] = recent['high'] - recent[['open', 'close']].max(axis=1)
        recent['lower_shadow'] = recent[['open', 'close']].min(axis=1) - recent['low']
        
        # Calculer les ratios moyens
        valid_ranges = recent['range'] > 0
        if valid_ranges.sum() > 0:
            characteristics['avg_body_ratio'] = float((recent.loc[valid_ranges, 'body'] / recent.loc[valid_ranges, 'range']).mean())
            characteristics['avg_upper_shadow_ratio'] = float((recent.loc[valid_ranges, 'upper_shadow'] / recent.loc[valid_ranges, 'range']).mean())
            characteristics['avg_lower_shadow_ratio'] = float((recent.loc[valid_ranges, 'lower_shadow'] / recent.loc[valid_ranges, 'range']).mean())
    
    return characteristics

@app.post("/prediction")
async def predict_prices(request: PricePredictionRequest):
    """
    Pr√©dit une s√©rie de prix futurs pour un symbole donn√©.
    Utilis√© par le robot MQ5 pour les pr√©dictions multi-timeframes (M1, M15, M30, H1).
    Le robot envoie les donn√©es historiques pour am√©liorer la pr√©cision de la pr√©diction.
    
    Args:
        request: Requ√™te contenant le symbole, prix actuel, nombre de bougies √† pr√©dire, timeframe,
                 et optionnellement les donn√©es historiques (history)
        
    Returns:
        dict: Dictionnaire contenant un tableau "prediction" avec les prix pr√©dits
    """
    try:
        symbol = request.symbol
        current_price = request.current_price
        bars_to_predict = request.bars_to_predict
        timeframe = request.timeframe
        
        logger.info(f"üìä Pr√©diction multi-timeframe am√©lior√©e: {symbol} ({timeframe}) - {bars_to_predict} bougies")
        
        # Utiliser la fonction am√©lior√©e si disponible
        if IMPROVEMENTS_AVAILABLE and MT5_AVAILABLE and mt5_initialized:
            try:
                period_map = {
                    "M1": mt5.TIMEFRAME_M1,
                    "M5": mt5.TIMEFRAME_M5,
                    "M15": mt5.TIMEFRAME_M15,
                    "H1": mt5.TIMEFRAME_H1,
                    "H4": mt5.TIMEFRAME_H4,
                    "D1": mt5.TIMEFRAME_D1
                }
                
                period = period_map.get(timeframe, mt5.TIMEFRAME_M1)
                rates = mt5.copy_rates_from_pos(symbol, period, 0, min(500, bars_to_predict + 100))
                
                if rates is not None and len(rates) >= 50:
                    df = pd.DataFrame(rates)
                    if 'time' in df.columns:
                        df['time'] = pd.to_datetime(df['time'], unit='s')
                    
                    # Utiliser la pr√©diction am√©lior√©e de ai_server_improvements
                    prediction_data = predict_prices_advanced(
                        df=df,
                        current_price=current_price,
                        bars_to_predict=bars_to_predict,
                        timeframe=timeframe,
                        symbol=symbol
                    )
                    
                    # Adapter selon le type de symbole (Boom/Crash/Volatility)
                    prediction_result = adapt_prediction_for_symbol(
                        symbol=symbol,
                        base_prediction=prediction_data,
                        df=df
                    )
                    
                    prices = prediction_result['prediction']
                    
                    logger.info(f"‚úÖ Pr√©diction am√©lior√©e g√©n√©r√©e: {len(prices)} prix pour {symbol} "
                              f"(Confiance: {prediction_result.get('confidence', 0.5):.1%}, "
                              f"M√©thode: {prediction_result.get('method', 'advanced')})")
                    
                    # Stockage pour validation
                    store_prediction(symbol, prices, current_price, timeframe)
                    validate_predictions(symbol, timeframe)
                    
                    accuracy_score = get_prediction_accuracy_score(symbol)
                    confidence_multiplier = get_prediction_confidence_multiplier(symbol)
                    validation_count = sum(1 for p in prediction_history.get(symbol, []) if p.get("is_validated", False))

                    return {
                        "prediction": prices,
                        "symbol": symbol,
                        "current_price": current_price,
                        "bars_predicted": len(prices),
                        "timeframe": timeframe,
                        "timestamp": datetime.now().isoformat(),
                        "confidence": prediction_result.get('confidence', 0.5),
                        "direction": prediction_result.get('direction', 'NEUTRAL'),
                        "support_levels": prediction_result.get('support_levels', []),
                        "resistance_levels": prediction_result.get('resistance_levels', []),
                        "accuracy_score": round(accuracy_score, 3),
                        "confidence_multiplier": round(confidence_multiplier, 2),
                        "validation_count": validation_count,
                        "method": prediction_result.get('method', 'advanced')
                    }
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è √âchec pr√©diction am√©lior√©e, repli vers m√©thode standard: {e}")
        
        # Fallback si IMPROVEMENTS_AVAILABLE est False ou erreur
        prices = [current_price] * bars_to_predict
        np.random.seed(int(current_price * 100) % 2**31)
        vol = current_price * 0.001
        for i in range(bars_to_predict):
            prices[i] = float(current_price + np.random.normal(0, vol * (i+1)**0.5))

        return {
            "prediction": prices,
            "symbol": symbol,
            "current_price": current_price,
            "bars_predicted": len(prices),
            "timeframe": timeframe,
            "timestamp": datetime.now().isoformat(),
            "confidence": 0.5,
            "method": "fallback_basic"
        }
    except Exception as e:
        logger.error(f"Erreur critique dans /prediction: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de la pr√©diction de prix: {str(e)}")

@app.get("/prediction/accuracy/{symbol}")
async def get_prediction_accuracy(symbol: str):
    """
    Retourne les statistiques de pr√©cision des pr√©dictions pour un symbole donn√©.
    
    Args:
        symbol: Symbole du march√©
        
    Returns:
        dict: Statistiques de pr√©cision (score moyen, nombre de validations, etc.)
    """
    try:
        accuracy_score = get_prediction_accuracy_score(symbol)
        confidence_multiplier = get_prediction_confidence_multiplier(symbol)
        
        if symbol not in prediction_history:
            return {
                "symbol": symbol,
                "accuracy_score": 0.5,
                "confidence_multiplier": 0.8,
                "validation_count": 0,
                "total_predictions": 0,
                "reliability": "UNKNOWN",
                "message": "Aucune pr√©diction enregistr√©e pour ce symbole"
            }
        
        validated = [p for p in prediction_history[symbol] if p.get("is_validated", False)]
        total = len(prediction_history[symbol])
        
        return {
            "symbol": symbol,
            "accuracy_score": round(accuracy_score, 3),
            "confidence_multiplier": round(confidence_multiplier, 2),
            "validation_count": len(validated),
            "total_predictions": total,
            "reliability": (
            "HIGH" if accuracy_score >= 0.80 
            else "MEDIUM" if accuracy_score >= 0.60 
            else "LOW"
        ),
            "is_reliable": accuracy_score >= MIN_ACCURACY_THRESHOLD,
            "recent_validations": [
                {
                    "timestamp": p["validation_timestamp"],
                    "accuracy": round(p["accuracy_score"], 3)
                }
                for p in validated[-10:]  # 10 derni√®res validations
            ]
        }
        
    except Exception as e:
        logger.error(f"Erreur dans /prediction/accuracy: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de la r√©cup√©ration de la pr√©cision: {str(e)}")

@app.get("/predictions/realtime/{symbol}")
async def get_realtime_predictions(symbol: str, timeframe: str = "M1"):
    """
    Retourne les derni√®res pr√©dictions en temps r√©el pour un symbole donn√©.
    Utilis√© par le robot MQ5 pour afficher les pr√©dictions dans le cadran d'information.
    """
    try:
        cache_key = f"{symbol}_{timeframe}"
        
        # V√©rifier le cache des pr√©dictions r√©centes
        if cache_key in realtime_predictions:
            pred_data = realtime_predictions[cache_key]
            # V√©rifier si la pr√©diction n'est pas trop ancienne (moins de 60 secondes)
            pred_time = datetime.fromisoformat(pred_data.get("timestamp", ""))
            if (datetime.now() - pred_time).total_seconds() < 60:
                return pred_data
        
        # Si pas de cache r√©cent, utiliser l'endpoint /prediction
        # ou retourner la derni√®re pr√©diction de l'historique
        if symbol in prediction_history and prediction_history[symbol]:
            last_pred = prediction_history[symbol][-1]
            accuracy_score = get_prediction_accuracy_score(symbol)
            
            response = {
                "symbol": symbol,
                "timeframe": timeframe,
                "timestamp": last_pred["timestamp"],
                "predicted_prices": last_pred["predicted_prices"][:50],  # Limiter √† 50 prix pour la r√©ponse
                "current_price": last_pred["current_price"],
                "accuracy_score": round(accuracy_score, 3),
                "validation_count": sum(1 for p in prediction_history[symbol] if p.get("is_validated", False)),
                "reliability": (
            "HIGH" if accuracy_score >= 0.80 
            else "MEDIUM" if accuracy_score >= 0.60 
            else "LOW"
        )
            }
            
            # Mettre en cache
            realtime_predictions[cache_key] = response
            
            return response
        
        return {
            "symbol": symbol,
            "timeframe": timeframe,
            "error": "Aucune pr√©diction disponible",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Erreur dans /predictions/realtime: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de la r√©cup√©ration des pr√©dictions: {str(e)}")

class PredictionValidationRequest(BaseModel):
    symbol: str
    real_prices: List[float] = Field(..., description="Liste des prix r√©els observ√©s")
    prediction_id: Optional[str] = None
    timeframe: str = "M1"

class MT5HistoryUploadRequest(BaseModel):
    """Requ√™te pour uploader des donn√©es historiques depuis MT5 vers Render"""
    symbol: str
    timeframe: str = Field(..., description="Timeframe (M1, M5, M15, H1, H4, D1)")
    data: List[Dict[str, Any]] = Field(..., description="Liste des bougies OHLCV au format: [{'time': timestamp, 'open': float, 'high': float, 'low': float, 'close': float, 'tick_volume': int}, ...]")

class ForceDecisionRequest(BaseModel):
    """Requ√™te pour forcer une d√©cision en mode test"""
    symbol: str
    action: str = Field(..., description="Action forc√©e: 'buy', 'sell', ou 'hold'")
    confidence: float = Field(default=0.85, description="Confiance forc√©e (d√©faut: 85%)")
    reason: str = Field(default="Test mode - d√©cision forc√©e", description="Raison de la d√©cision forc√©e")
    override_thresholds: bool = Field(default=True, description="Ignorer les seuils de confiance minimum")

@app.post("/mt5/history-upload")
async def upload_mt5_history(request: MT5HistoryUploadRequest):
    """
    Endpoint pour recevoir les donn√©es historiques depuis MT5 (bridge).
    Les donn√©es sont stock√©es en cache et utilis√©es par le syst√®me ML avanc√©.
    
    Args:
        request: Requ√™te contenant le symbole, timeframe et les donn√©es OHLCV
        
    Returns:
        dict: Confirmation de r√©ception avec nombre de bougies stock√©es
    """
    try:
        if not request.symbol or not isinstance(request.symbol, str):
            raise HTTPException(status_code=400, detail="Le symbole est requis et doit √™tre une cha√Æne de caract√®res")
        
        if not request.data or not isinstance(request.data, list):
            raise HTTPException(status_code=400, detail="La liste de donn√©es est requise")
        
        if len(request.data) == 0:
            raise HTTPException(status_code=400, detail="La liste de donn√©es ne peut pas √™tre vide")
        
        # Valider le timeframe
        valid_timeframes = ["M1", "M5", "M15", "M30", "H1", "H4", "D1"]
        if request.timeframe not in valid_timeframes:
            raise HTTPException(status_code=400, detail=f"Timeframe invalide. Valeurs accept√©es: {', '.join(valid_timeframes)}")
        
        # Convertir les donn√©es en DataFrame
        try:
            df = pd.DataFrame(request.data)
            
            # V√©rifier les colonnes requises
            required_cols = ['time', 'open', 'high', 'low', 'close']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise HTTPException(status_code=400, detail=f"Colonnes manquantes: {', '.join(missing_cols)}")
            
            # Convertir le timestamp en datetime
            if df['time'].dtype == 'int64' or df['time'].dtype == 'float64':
                # Timestamp Unix (secondes)
                df['time'] = pd.to_datetime(df['time'], unit='s')
            else:
                df['time'] = pd.to_datetime(df['time'])
            
            # Trier par temps (plus ancien au plus r√©cent)
            df = df.sort_values('time').reset_index(drop=True)
            
            # Stocker dans le cache
            cache_key = f"{request.symbol}_{request.timeframe}"
            mt5_uploaded_history_cache[cache_key] = {
                "data": df,
                "timestamp": datetime.now(),
                "symbol": request.symbol,
                "timeframe": request.timeframe,
                "count": len(df)
            }
            
            logger.info(f"‚úÖ Donn√©es historiques upload√©es depuis MT5: {len(df)} bougies pour {request.symbol} {request.timeframe}")
            
            return {
                "status": "success",
                "symbol": request.symbol,
                "timeframe": request.timeframe,
                "bars_received": len(df),
                "cache_key": cache_key,
                "message": f"{len(df)} bougies stock√©es en cache pour {request.symbol} {request.timeframe}"
            }
            
        except Exception as e:
            logger.error(f"Erreur lors du traitement des donn√©es upload√©es: {e}", exc_info=True)
            raise HTTPException(status_code=400, detail=f"Erreur lors du traitement des donn√©es: {str(e)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur dans /mt5/history-upload: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de l'upload des donn√©es historiques: {str(e)}")

@app.post("/decision/force", response_model=DecisionResponse)
async def force_decision(request: ForceDecisionRequest):
    """
    Endpoint pour forcer une d√©cision en mode test.
    Utile pour backtester diff√©rents sc√©narios sans attendre que le mod√®le "se r√©veille".
    
    Args:
        request: Requ√™te contenant l'action forc√©e et les param√®tres
        
    Returns:
        DecisionResponse: D√©cision forc√©e avec m√©tadonn√©es
    """
    try:
        logger.info(f"üß™ MODE TEST - For√ßage d√©cision pour {request.symbol}: action={request.action}, confidence={request.confidence}")
        
        # Validation de l'action
        if request.action not in ["buy", "sell", "hold"]:
            raise HTTPException(status_code=400, detail="Action doit √™tre 'buy', 'sell', ou 'hold'")
        
        # Validation de la confiance
        if not (0.0 <= request.confidence <= 1.0):
            raise HTTPException(status_code=400, detail="La confiance doit √™tre entre 0.0 et 1.0")
        
        # Appliquer les seuils si demand√©
        final_confidence = request.confidence
        final_reason = request.reason
        
        if not request.override_thresholds:
            action, final_confidence, final_reason = apply_confidence_thresholds(
                request.action, request.confidence, request.reason
            )
        else:
            action = request.action
        
        # Cr√©er les m√©tadonn√©es de test
        metadata = {
            "test_mode": True,
            "forced_action": True,
            "original_confidence": request.confidence,
            "thresholds_overridden": request.override_thresholds,
            "timestamp": datetime.now().isoformat()
        }
        
        # Retourner la d√©cision forc√©e
        response = DecisionResponse(
            action=action,
            confidence=final_confidence,
            reason=final_reason,
            spike_prediction=False,
            spike_zone_price=None,
            stop_loss=None,
            take_profit=None,
            spike_direction=None,
            early_spike_warning=False,
            early_spike_zone_price=None,
            early_spike_direction=None,
            buy_zone_low=None,
            buy_zone_high=None,
            sell_zone_low=None,
            sell_zone_high=None,
            timestamp=datetime.now().isoformat(),
            model_used="force_test_mode",
            metadata=metadata
        )
        
        logger.info(f"‚úÖ D√©cision forc√©e retourn√©e: {action} @ {final_confidence:.3f}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur dans /decision/force: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors du for√ßage de d√©cision: {str(e)}")

@app.post("/predictions/validate")
async def validate_prediction(request: PredictionValidationRequest):
    """
    Valide une pr√©diction en comparant avec les donn√©es r√©elles.
    Les m√©triques sont sauvegard√©es dans le dossier Results.
    """
    try:
        # Validation suppl√©mentaire des entr√©es
        if not request.symbol or not isinstance(request.symbol, str):
            raise HTTPException(status_code=400, detail="Le symbole est requis et doit √™tre une cha√Æne de caract√®res")
        
        if not request.real_prices or not isinstance(request.real_prices, list):
            raise HTTPException(status_code=400, detail="La liste des prix r√©els est requise")
        
        if len(request.real_prices) == 0:
            raise HTTPException(status_code=400, detail="La liste des prix r√©els ne peut pas √™tre vide")
        
        # Appeler la fonction de validation
        result = validate_prediction_with_realtime_data(
            request.symbol,
            request.real_prices,
            request.prediction_id
        )
        
        # V√©rifier si le r√©sultat contient une erreur
        if not isinstance(result, dict):
            logger.error(f"R√©sultat inattendu de validate_prediction_with_realtime_data: {type(result)}")
            raise HTTPException(status_code=500, detail="Erreur interne: format de r√©ponse invalide")
        
        if "error" in result:
            # Message d'erreur plus informatif pour les erreurs de validation
            error_msg = result["error"]
            # Si c'est une erreur de "pas de pr√©diction", c'est acceptable (pas n√©cessairement une erreur)
            if "aucune pr√©diction" in error_msg.lower() or "pr√©diction" in error_msg.lower() and "non trouv√©e" in error_msg.lower():
                logger.info(f"Validation ignor√©e pour {request.symbol}: {error_msg}")
                return {
                    "success": False,
                    "message": error_msg,
                    "status": "no_prediction_to_validate"
                }
            raise HTTPException(status_code=400, detail=error_msg)
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur dans /predictions/validate: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de la validation: {str(e)}")

# Mod√®le pour la requ√™te de pr√©cision de d√©cision
class DecisionAccuracyRequest(BaseModel):
    symbol: str
    action: str  # "buy", "sell", "hold"
    confidence: float
    result: Optional[str] = None  # "win", "loss", "breakeven"
    profit: Optional[float] = None
    timestamp: Optional[str] = None

@app.post("/decision/accuracy")
async def log_decision_accuracy(request: DecisionAccuracyRequest):
    """
    Enregistre la pr√©cision d'une d√©cision de trading pour le feedback loop.
    Alimente _feedback_by_key pour la calibration ML et met √† jour symbol_calibration.
    """
    try:
        logger.info(f"üìä Pr√©cision d√©cision re√ßue: {request.symbol} - {request.action} (conf: {request.confidence:.2f})")
        
        accuracy_data = {
            "symbol": request.symbol,
            "action": request.action,
            "confidence": request.confidence,
            "result": request.result,
            "profit": request.profit,
            "timestamp": request.timestamp or datetime.now().isoformat()
        }
        logger.info(f"‚úÖ Donn√©es de pr√©cision enregistr√©es: {accuracy_data}")
        
        # Alimenter le buffer de feedback ML (calibration)
        is_win = str(request.result or "").lower() in ("win", "won", "1", "true", "yes")
        if request.profit is not None:
            is_win = request.profit > 0
        profit = float(request.profit or 0.0)
        try:
            buf = _get_feedback_buf(request.symbol, "M1")
            buf.append({
                "profit": profit,
                "is_win": is_win,
                "side": (request.action or "").lower(),
                "ai_confidence": float(request.confidence),
                "timestamp": request.timestamp or datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
            })
            update_calibration_from_feedback(request.symbol, is_win, profit, request.action)
        except Exception as fb_err:
            logger.warning(f"‚ö†Ô∏è Feedback buffer: {fb_err}")
        
        return {
            "success": True,
            "message": "Pr√©cision de d√©cision enregistr√©e",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Erreur dans /decision/accuracy: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de l'enregistrement de la pr√©cision: {str(e)}")

# ===== ML FEEDBACK + METRICS (ENTRA√éNEMENT CONTINU) =====
# Syst√®me de feedback l√©ger en m√©moire pour apprentissage online
class TradeFeedbackRequest(BaseModel):
    symbol: str
    timeframe: Optional[str] = "M1"
    side: Optional[str] = None  # "buy" | "sell"
    profit: float
    is_win: bool
    ai_confidence: Optional[float] = None  # 0..1 (optional)
    open_time: Optional[int] = None
    close_time: Optional[int] = None
    timestamp: Optional[int] = None

# Buffer de feedback en m√©moire (Render free: stockage √©ph√©m√®re)
_feedback_by_key: Dict[str, deque] = {}  # key = "{symbol}:{tf}"
_metrics_cache: Dict[str, Dict[str, Any]] = {}  # key = "{symbol}:{tf}"

# Contr√¥le "continuous training" (online recalibration)
_continuous_enabled = False
_continuous_task: Optional[asyncio.Task] = None
_continuous_last_tick: Optional[str] = None

def _ml_key(symbol: str, timeframe: str) -> str:
    return f"{symbol}:{timeframe}"

def _ml_clamp(v: float, lo: float, hi: float) -> float:
    return max(lo, min(hi, v))

def _get_feedback_buf(symbol: str, timeframe: str) -> deque:
    k = _ml_key(symbol, timeframe)
    if k not in _feedback_by_key:
        _feedback_by_key[k] = deque(maxlen=5000)
    return _feedback_by_key[k]

def _compute_ml_metrics(symbol: str, timeframe: str) -> Dict[str, Any]:
    """
    Retourne un JSON compatible avec le parser MT5 `ParseMLMetricsResponse()`:
    - best_model
    - metrics: random_forest/gradient_boosting/mlp -> accuracy
    - training_samples/test_samples
    - recommendations.min_confidence
    """
    k = _ml_key(symbol, timeframe)
    buf = _get_feedback_buf(symbol, timeframe)
    n = len(buf)

    # Par d√©faut (si pas encore de feedback), garder un niveau "neutre" pour permettre au robot de d√©marrer
    if n == 0:
        base_acc = 70.0
        win_rate = 0.50
    else:
        wins = sum(1 for x in buf if x.get("is_win"))
        win_rate = wins / n
        base_acc = _ml_clamp(win_rate * 100.0, 35.0, 95.0)

    # Simuler 3 "mod√®les" √† partir de la performance observ√©e (l√©ger, robuste)
    rf = _ml_clamp(base_acc + 0.8, 0.0, 100.0)
    gb = _ml_clamp(base_acc + 0.3, 0.0, 100.0)
    mlp = _ml_clamp(base_acc - 0.5, 0.0, 100.0)

    best_model = "random_forest"
    best_acc = rf
    if gb > best_acc:
        best_model, best_acc = "gradient_boosting", gb
    if mlp > best_acc:
        best_model, best_acc = "mlp", mlp

    # Recommandation dynamique: si win_rate baisse, on remonte la confiance mini
    # (et inversement si win_rate est bon, on peut baisser un peu pour saisir plus d'opportunit√©s)
    min_conf = _ml_clamp(0.75 - (win_rate - 0.50) * 0.30, 0.55, 0.85)

    payload = {
        "symbol": symbol,
        "timeframe": timeframe,
        "best_model": best_model,
        "metrics": {
            "random_forest": {"accuracy": float(rf)},
            "gradient_boosting": {"accuracy": float(gb)},
            "mlp": {"accuracy": float(mlp)},
        },
        "training_samples": int(n),
        "test_samples": int(max(0, n // 5)),
        "recommendations": {
            "min_confidence": float(min_conf),
        },
        "last_update": datetime.now().isoformat(),
        "is_valid": True,
    }

    _metrics_cache[k] = payload
    return payload

async def _continuous_training_loop(symbols: List[str], timeframe: str, interval_sec: int) -> None:
    global _continuous_last_tick
    logger.info(
        f"üß† Continuous ML loop d√©marr√©e | symbols={','.join(symbols)} timeframe={timeframe} interval={interval_sec}s"
    )
    while _continuous_enabled:
        _continuous_last_tick = datetime.now().isoformat()
        # "Entra√Ænement" lightweight: rafra√Æchir les m√©triques
        for sym in symbols:
            try:
                _compute_ml_metrics(sym, timeframe)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Continuous loop: {sym}: {e}")
        await asyncio.sleep(max(10, interval_sec))

async def _push_feedback_to_supabase(symbol: str, timeframe: str, side: Optional[str], profit: float, is_win: bool, ai_confidence: Optional[float]):
    """Envoie le feedback vers Supabase trade_feedback pour que le robot apprenne des erreurs."""
    import httpx
    supabase_url = os.getenv("SUPABASE_URL", "https://bpzqnooiisgadzicwupi.supabase.co")
    supabase_key = os.getenv("SUPABASE_ANON_KEY")
    if not supabase_key:
        return
    now_iso = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%S.000Z")
    payload = {
        "symbol": symbol,
        "timeframe": timeframe or "M1",
        "open_time": now_iso,
        "close_time": now_iso,
        "entry_price": 0,
        "exit_price": 0,
        "profit": float(profit),
        "ai_confidence": float(ai_confidence) if ai_confidence is not None else None,
        "coherent_confidence": float(ai_confidence) if ai_confidence is not None else None,
        "decision": (side or "HOLD").upper(),
        "is_win": bool(is_win),
        "side": (side or "").lower(),
    }
    try:
        async with httpx.AsyncClient() as client:
            r = await client.post(
                f"{supabase_url}/rest/v1/trade_feedback",
                json=payload,
                headers={"apikey": supabase_key, "Authorization": f"Bearer {supabase_key}", "Content-Type": "application/json", "Prefer": "return=minimal"},
                timeout=5.0,
            )
            if r.status_code in (200, 201):
                logger.debug(f"‚úÖ Feedback envoy√© √† Supabase pour {symbol}")
            else:
                logger.debug(f"Supabase trade_feedback: {r.status_code}")
    except Exception as e:
        logger.debug(f"Supabase trade_feedback: {e}")


@app.post("/trades/feedback")
async def trades_feedback(request: TradeFeedbackRequest):
    """
    Re√ßoit le r√©sultat d'un trade (profit, win/loss) et met √† jour les m√©triques online.
    Envoie aussi √† Supabase pour que /trend utilise ces donn√©es (apprentissage des erreurs).
    Retourne les m√©triques d√©taill√©es (compat MT5).
    """
    try:
        symbol = request.symbol
        tf = request.timeframe or "M1"
        buf = _get_feedback_buf(symbol, tf)
        buf.append({
            "profit": float(request.profit),
            "is_win": bool(request.is_win),
            "side": (request.side or "").lower(),
            "ai_confidence": float(request.ai_confidence) if request.ai_confidence is not None else None,
            "timestamp": request.timestamp or datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
        })
        update_calibration_from_feedback(symbol, bool(request.is_win), float(request.profit), request.side or "")
        asyncio.create_task(_push_feedback_to_supabase(symbol, tf, request.side, request.profit, request.is_win, request.ai_confidence))
        logger.info(f"üìä Feedback trade re√ßu: {symbol} {tf} - {'WIN' if request.is_win else 'LOSS'} (profit: {request.profit:.2f})")
        return _compute_ml_metrics(symbol, tf)
    except Exception as e:
        logger.error(f"Erreur /trades/feedback: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/ml/metrics")
async def ml_metrics(symbol: str, timeframe: str = "M1"):
    """Alias simple: retourne les m√©triques d√©taill√©es."""
    return _compute_ml_metrics(symbol, timeframe)

@app.get("/ml/metrics/detailed")
async def ml_metrics_detailed(symbol: str, timeframe: str = "M1"):
    """Compat avec le robot MT5 (ParseMLMetricsResponse)."""
    return _compute_ml_metrics(symbol, timeframe)

@app.post("/ml/continuous/start")
async def ml_continuous_start(symbols: Optional[str] = None, timeframe: str = "M1", interval_sec: int = 300):
    """
    D√©marre l'entra√Ænement continu "online" (recalibrage √† partir des feedbacks).
    symbols: "EURUSD,GBPUSD,USDJPY"
    """
    global _continuous_enabled, _continuous_task
    if _continuous_enabled and _continuous_task and not _continuous_task.done():
        return {"status": "already_running"}
    
    syms = [s.strip() for s in (symbols or os.getenv("ML_SYMBOLS", "EURUSD,GBPUSD,USDJPY,USDCAD,AUDUSD,NZDUSD,EURJPY")).split(",") if s.strip()]
    _continuous_enabled = True
    _continuous_task = asyncio.create_task(_continuous_training_loop(syms, timeframe, interval_sec))
    logger.info(f"‚úÖ Continuous ML training d√©marr√© pour: {syms}")
    return {"status": "started", "symbols": syms, "timeframe": timeframe, "interval_sec": interval_sec}

@app.post("/ml/continuous/stop")
async def ml_continuous_stop():
    global _continuous_enabled
    _continuous_enabled = False
    logger.info("‚è∏Ô∏è Continuous ML training arr√™t√©")
    return {"status": "stopping"}

@app.get("/ml/continuous/status")
async def ml_continuous_status():
    # Entra√Ænement ON si boucle legacy active OU si ml_trainer Supabase tourne (d√©marrage auto)
    training_on = _continuous_enabled
    if not training_on and ML_TRAINER_AVAILABLE and ml_trainer is not None and getattr(ml_trainer, "is_running", False):
        training_on = True
    return {
        "enabled": training_on,
        "last_tick": _continuous_last_tick,
        "feedback_keys": len(_feedback_by_key),
    }

@app.get("/calibration/{symbol}")
async def get_calibration(symbol: str, timeframe: str = "M1"):
    """
    Retourne la calibration adaptative pour un symbole.
    Utilis√© pour visualiser min_confidence, confidence_multiplier, drift_factor, etc.
    """
    return get_symbol_calibration(symbol, timeframe)

# ===== SYST√àME DE NOTIFICATIONS VONAGE =====
# Importer le service de notification unifi√©
try:
    sys.path.insert(0, str(Path(__file__).parent / "src"))
    from unified_notification_service import UnifiedNotificationService
    notification_service = UnifiedNotificationService()
    VONAGE_AVAILABLE = notification_service.sms_enabled
    logger.info("Service de notification Vonage disponible")
except Exception as e:
    logger.warning(f"Service de notification Vonage non disponible: {e}")
    notification_service = None
    VONAGE_AVAILABLE = False

class NotificationRequest(BaseModel):
    message: str
    symbol: Optional[str] = None
    signal_type: Optional[str] = None  # "trade", "spike", "prediction", "summary"
    confidence: Optional[float] = None
    price: Optional[float] = None

@app.post("/notifications/send")
async def send_notification(request: NotificationRequest):
    """
    Envoie une notification via Vonage SMS depuis MT5.
    Utilis√© par le robot MQ5 pour envoyer des alertes.
    """
    try:
        if not VONAGE_AVAILABLE or not notification_service:
            return {
                "success": False,
                "error": "Service Vonage non disponible",
                "message": request.message
            }
        
        # Envoyer le SMS
        success = notification_service._send_sms(request.message)
        
        if success:
            logger.info(f"Notification Vonage envoy√©e: {request.message[:50]}...")
        
        return {
            "success": success,
            "message": request.message,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Erreur dans /notifications/send: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de l'envoi: {str(e)}")

@app.post("/notifications/trading-signal")
async def send_trading_signal_notification(request: Dict[str, Any]):
    """
    Envoie une notification de signal de trading via Vonage.
    """
    try:
        if not VONAGE_AVAILABLE or not notification_service:
            return {"success": False, "error": "Service Vonage non disponible"}
        
        symbol = request.get("symbol", "N/A")
        action = request.get("action", "N/A")
        price = request.get("price", 0.0)
        confidence = request.get("confidence", 0.0)
        timeframe = request.get("timeframe", "M1")
        
        signal_data = {
            'symbol': symbol,
            'action': action,
            'price': price,
            'confidence': confidence,
            'timeframe': timeframe,
            'timestamp': datetime.now().isoformat()
        }
        
        results = notification_service.send_trading_signal(signal_data)
        
        return {
            "success": results.get("sms", False) or results.get("whatsapp", False),
            "results": results,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Erreur dans /notifications/trading-signal: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de l'envoi: {str(e)}")

@app.get("/notifications/predictions-summary")
async def send_predictions_summary():
    """
    Envoie un r√©sum√© des pr√©dictions par symbole via Vonage.
    """
    try:
        if not VONAGE_AVAILABLE or not notification_service:
            return {"success": False, "error": "Service Vonage non disponible"}
        
        # R√©cup√©rer toutes les pr√©dictions r√©centes depuis prediction_history
        summary_lines = ["üìä R√âSUM√â PR√âDICTIONS"]
        summary_lines.append(f"‚è∞ {datetime.now().strftime('%H:%M')}")
        summary_lines.append("")
        
        symbol_count = 0
        
        # Parcourir prediction_history
        for symbol, preds in prediction_history.items():
            if not preds:
                continue
            
            last_pred = preds[-1] if preds else None
            if not last_pred:
                continue
            
            # Calculer le score de pr√©cision
            try:
                accuracy_score = get_prediction_accuracy_score(symbol)
            except:
                accuracy_score = 0.0
            
            # Compter les validations
            validation_count = sum(1 for p in preds if p.get("is_validated", False))
            
            # Afficher m√™me si pas encore valid√©, mais avec info diff√©rente
            if validation_count > 0:
                reliability = "HIGH" if accuracy_score >= 0.80 else "MEDIUM" if accuracy_score >= 0.60 else "LOW"
                summary_lines.append(f"üìà {symbol}")
                summary_lines.append(f"  Pr√©cision: {accuracy_score*100:.1f}%")
                summary_lines.append(f"  Validations: {validation_count}")
                summary_lines.append(f"  Fiabilit√©: {reliability}")
            else:
                # Afficher les pr√©dictions non encore valid√©es
                predicted_price = last_pred.get("predicted_price", 0)
                confidence = last_pred.get("confidence", 0)
                direction = last_pred.get("direction", "N/A")
                summary_lines.append(f"üìà {symbol}")
                summary_lines.append(f"  Direction: {direction}")
                summary_lines.append(f"  Prix pr√©dit: {predicted_price:.5f}")
                summary_lines.append(f"  Confiance: {confidence*100:.1f}%")
                summary_lines.append(f"  En attente validation")
            
            summary_lines.append("")
            symbol_count += 1
        
        # Aussi v√©rifier realtime_predictions (si disponible)
        try:
            processed_symbols = set()
            for s in summary_lines:
                if s.startswith("üìà"):
                    parts = s.split()
                    if len(parts) > 1:
                        processed_symbols.add(parts[1])
            
            for cache_key, pred in realtime_predictions.items():
                symbol = pred.get('symbol', cache_key.split('_')[0] if '_' in cache_key else cache_key)
                if symbol not in processed_symbols:
                    summary_lines.append(f"üìà {symbol}")
                    summary_lines.append(f"  Pr√©diction temps r√©el")
                    direction = pred.get('direction', 'N/A')
                    if direction == 'N/A':
                        # Essayer de d√©duire la direction depuis les prix pr√©dits
                        predicted_prices = pred.get('predicted_prices', [])
                        current_price = pred.get('current_price', 0)
                        if predicted_prices and current_price > 0:
                            avg_predicted = sum(predicted_prices) / len(predicted_prices)
                            direction = "BUY" if avg_predicted > current_price else "SELL"
                    summary_lines.append(f"  Direction: {direction}")
                    conf = pred.get('accuracy_score', pred.get('confidence', 0))
                    if isinstance(conf, (int, float)) and conf > 0:
                        summary_lines.append(f"  Score: {conf*100:.1f}%")
                    summary_lines.append("")
                    symbol_count += 1
        except Exception as e:
            logger.warning(f"Erreur lors de l'ajout des pr√©dictions temps r√©el au r√©sum√©: {e}")
        
        if symbol_count == 0:
            summary_lines.append("Aucune pr√©diction disponible")
        
        message = "\n".join(summary_lines)
        
        # Envoyer le SMS
        success = notification_service._send_sms(message)
        
        return {
            "success": success,
            "symbols_count": symbol_count,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Erreur dans /notifications/predictions-summary: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de l'envoi: {str(e)}")

# Gestion des mod√®les ML
def load_ml_models():
    """Charge les mod√®les ML depuis le r√©pertoire models"""
    models = {}
    if not MODELS_DIR.exists():
        return models
    
    try:
        for model_file in MODELS_DIR.glob("*.pkl"):
            try:
                import joblib
                model_name = model_file.stem
                models[model_name] = joblib.load(model_file)
                logger.info(f"Mod√®le charg√©: {model_name}")
            except Exception as e:
                logger.warning(f"Impossible de charger {model_file}: {e}")
    except Exception as e:
        logger.error(f"Erreur lors du chargement des mod√®les: {e}")
    
    return models

# Charger les mod√®les au d√©marrage
ml_models = load_ml_models()

def predict_with_model(symbol: str, features: Dict[str, float], model_name: Optional[str] = None):
    """Pr√©dit avec un mod√®le ML sp√©cifique"""
    if not ml_models:
        return None
    
    # S√©lectionner le mod√®le appropri√©
    if model_name and model_name in ml_models:
        model = ml_models[model_name]
    else:
        # S√©lection automatique selon le symbole
        if "Boom" in symbol or "Crash" in symbol:
            model_key = "synthetic_special_xgb_model"
        elif "Volatility" in symbol:
            model_key = "synthetic_general_xgb_model"
        else:
            model_key = "universal_xgb_model"
        
        if model_key in ml_models:
            model = ml_models[model_key]
        elif len(ml_models) > 0:
            model = list(ml_models.values())[0]
        else:
            return None
    
    try:
        # Pr√©parer les features pour le mod√®le
        feature_array = np.array([list(features.values())])
        prediction = model.predict(feature_array)[0]
        probabilities = None
        if hasattr(model, 'predict_proba'):
            probabilities = model.predict_proba(feature_array)[0]
        
        return {
            "prediction": prediction,
            "probabilities": probabilities.tolist() if probabilities is not None else None,
            "model_used": model_name or "auto"
        }
    except Exception as e:
        logger.error(f"Erreur pr√©diction mod√®le: {e}")
        return None

# Gestion du cache avanc√©e
def clear_old_cache(max_age_seconds: int = 3600):
    """Nettoie le cache des entr√©es trop anciennes"""
    current_time = datetime.now().timestamp()
    keys_to_remove = []
    
    for key, last_update in last_updated.items():
        if current_time - last_update > max_age_seconds:
            keys_to_remove.append(key)
    
    for key in keys_to_remove:
        prediction_cache.pop(key, None)
        last_updated.pop(key, None)
    
    if keys_to_remove:
        logger.info(f"Cache nettoy√©: {len(keys_to_remove)} entr√©es supprim√©es")

@app.get("/cache/stats")
async def cache_stats():
    """Statistiques du cache"""
    clear_old_cache()
    return {
        "size": len(prediction_cache),
        "max_age_seconds": 3600,
        "cache_duration": CACHE_DURATION
    }

@app.post("/cache/clear")
async def clear_cache():
    """Vide le cache"""
    prediction_cache.clear()
    last_updated.clear()
    logger.info("Cache vid√© manuellement")
    return {"status": "cleared", "message": "Cache vid√© avec succ√®s"}

# Endpoint pour les statistiques de trading
@app.get("/stats/{symbol}")
async def get_symbol_stats(symbol: str, days: int = 7):
    """R√©cup√®re les statistiques de trading pour un symbole"""
    try:
        if not mt5_initialized:
            return {"error": "MT5 non initialis√©"}
        
        # R√©cup√©rer les donn√©es historiques
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        rates = mt5.copy_rates_range(symbol, mt5.TIMEFRAME_D1, start_date, end_date)
        if rates is None or len(rates) == 0:
            return {"error": "Aucune donn√©e disponible"}
        
        df = pd.DataFrame(rates)
        df['time'] = pd.to_datetime(df['time'], unit='s')
        
        # Calculer les statistiques
        stats = {
            "symbol": symbol,
            "period_days": days,
            "total_candles": len(df),
            "price_range": {
                "high": float(df['high'].max()),
                "low": float(df['low'].min()),
                "current": float(df['close'].iloc[-1])
            },
            "volatility": {
                "atr": float(df['high'].sub(df['low']).mean()),
                "std": float(df['close'].std())
            },
            "trend": {
                "direction": "UP" if df['close'].iloc[-1] > df['close'].iloc[0] else "DOWN",
                "change_percent": float((df['close'].iloc[-1] / df['close'].iloc[0] - 1) * 100)
            }
        }
        
        return stats
    except Exception as e:
        logger.error(f"Erreur stats: {e}")
        return {"error": str(e)}

# Endpoint pour les signaux en temps r√©el am√©lior√©
@app.get("/signals/{symbol}")
async def get_signals(
    symbol: str,
    timeframe: str = "M15",
    lookback: int = 200,
    min_confidence: float = 0.6
):
    """
    G√©n√®re des signaux de trading avanc√©s avec analyse multi-timeframe
    
    Args:
        symbol: Symbole √† analyser (ex: "EURUSD")
        timeframe: P√©riode d'analyse (M1, M5, M15, H1, H4, D1)
        lookback: Nombre de bougies √† analyser
        min_confidence: Confiance minimale pour les signaux (0-1)
    """
    try:
        if not mt5_initialized:
            return {"error": "MT5 non initialis√©"}
        
        # Mapper le timeframe MT5
        tf_mapping = {
            'M1': mt5.TIMEFRAME_M1,
            'M5': mt5.TIMEFRAME_M5,
            'M15': mt5.TIMEFRAME_M15,
            'H1': mt5.TIMEFRAME_H1,
            'H4': mt5.TIMEFRAME_H4,
            'D1': mt5.TIMEFRAME_D1
        }
        
        mt5_timeframe = tf_mapping.get(timeframe, mt5.TIMEFRAME_M15)
        
        # R√©cup√©rer les donn√©es
        rates = mt5.copy_rates_from_pos(symbol, mt5_timeframe, 0, lookback)
        if rates is None or len(rates) == 0:
            return {"error": f"Aucune donn√©e disponible pour {symbol} sur {timeframe}"}
        
        df = pd.DataFrame(rates)
        df['time'] = pd.to_datetime(df['time'], unit='s')
        df.set_index('time', inplace=True)
        
        # 1. Calcul des indicateurs de tendance
        df['sma_20'] = df['close'].rolling(20).mean()
        df['sma_50'] = df['close'].rolling(50).mean()
        df['sma_200'] = df['close'].rolling(200).mean()
        
        # 2. Indicateur de momentum (RSI)
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # 3. Bandes de Bollinger
        df['bb_upper'], df['bb_middle'], df['bb_lower'] = (
            df['close'].rolling(20).mean() + 2 * df['close'].rolling(20).std(),
            df['close'].rolling(20).mean(),
            df['close'].rolling(20).mean() - 2 * df['close'].rolling(20).std()
        )
        
        # 4. MACD
        exp1 = df['close'].ewm(span=12, adjust=False).mean()
        exp2 = df['close'].ewm(span=26, adjust=False).mean()
        df['macd'] = exp1 - exp2
        df['signal_line'] = df['macd'].ewm(span=9, adjust=False).mean()
        
        # 5. ADX (Average Directional Index)
        plus_dm = df['high'].diff()
        minus_dm = df['low'].diff() * -1
        
        tr1 = df['high'] - df['low']
        tr2 = abs(df['high'] - df['close'].shift())
        tr3 = abs(df['low'] - df['close'].shift())
        
        df['tr'] = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        atr = df['tr'].rolling(14).mean()
        
        plus_di = 100 * (plus_dm.ewm(alpha=1/14).mean() / atr)
        minus_di = 100 * (minus_dm.ewm(alpha=1/14).mean() / atr)
        df['adx'] = 100 * abs((plus_di - minus_di) / (plus_di + minus_di)).ewm(alpha=1/14).mean()
        
        # Derni√®res valeurs
        current = df.iloc[-1]
        previous = df.iloc[-2] if len(df) > 1 else current
        
        # G√©n√©ration des signaux
        signals = []
        
        # 1. Signaux de tendance
        price_above_sma20 = current['close'] > current['sma_20']
        price_above_sma50 = current['close'] > current['sma_50']
        price_above_sma200 = current['close'] > current['sma_200']
        
        if price_above_sma20 and price_above_sma50 and price_above_sma200:
            signals.append({
                "type": "BUY",
                "reason": "Prix au-dessus des moyennes mobiles (20, 50, 200)",
                "confidence": 0.7
            })
        elif not price_above_sma20 and not price_above_sma50 and not price_above_sma200:
            signals.append({
                "type": "SELL",
                "reason": "Prix en-dessous des moyennes mobiles (20, 50, 200)",
                "confidence": 0.7
            })
        
        # 2. Signaux RSI
        if current['rsi'] < 30:
            signals.append({
                "type": "BUY",
                "reason": f"RSI en survente ({current['rsi']:.1f})",
                "confidence": 0.65
            })
        elif current['rsi'] > 70:
            signals.append({
                "type": "SELL",
                "reason": f"RSI en surachat ({current['rsi']:.1f})",
                "confidence": 0.65
            })
        
        # 3. Signaux Bandes de Bollinger
        if current['close'] < current['bb_lower']:
            signals.append({
                "type": "BUY",
                "reason": "Prix en dessous de la bande de Bollinger inf√©rieure",
                "confidence": 0.7
            })
        elif current['close'] > current['bb_upper']:
            signals.append({
                "type": "SELL",
                "reason": "Prix au-dessus de la bande de Bollinger sup√©rieure",
                "confidence": 0.7
            })
        
        # 4. Signaux MACD
        if current['macd'] > current['signal_line'] and previous['macd'] <= previous['signal_line']:
            signals.append({
                "type": "BUY",
                "reason": "Croisement haussier du MACD",
                "confidence": 0.75
            })
        elif current['macd'] < current['signal_line'] and previous['macd'] >= previous['signal_line']:
            signals.append({
                "type": "SELL",
                "reason": "Croisement baissier du MACD",
                "confidence": 0.75
            })
        
        # 5. Filtre ADX (tendance forte si > 25)
        strong_trend = current['adx'] > 25
        
        # Filtrer les signaux par confiance minimale
        signals = [s for s in signals if s['confidence'] >= min_confidence]
        
        # Trier par confiance d√©croissante
        signals.sort(key=lambda x: x['confidence'], reverse=True)
        
        # Pr√©parer la r√©ponse
        response = {
            "symbol": symbol,
            "timeframe": timeframe,
            "timestamp": datetime.now().isoformat(),
            "price": float(current['close']),
            "indicators": {
                "sma_20": float(current['sma_20']) if pd.notna(current['sma_20']) else None,
                "sma_50": float(current['sma_50']) if pd.notna(current['sma_50']) else None,
                "sma_200": float(current['sma_200']) if pd.notna(current['sma_200']) else None,
                "rsi": float(current['rsi']) if pd.notna(current['rsi']) else None,
                "bb_upper": float(current['bb_upper']) if pd.notna(current['bb_upper']) else None,
                "bb_middle": float(current['bb_middle']) if pd.notna(current['bb_middle']) else None,
                "bb_lower": float(current['bb_lower']) if pd.notna(current['bb_lower']) else None,
                "macd": float(current['macd']) if pd.notna(current['macd']) else None,
                "macd_signal": float(current['signal_line']) if pd.notna(current['signal_line']) else None,
                "adx": float(current['adx']) if pd.notna(current['adx']) else None,
                "strong_trend": bool(strong_trend) if pd.notna(strong_trend) else None
            },
            "signals": signals,
            "analysis": {
                "trend": "Haussi√®re" if price_above_sma200 else "Baissi√®re",
                "volatility": "√âlev√©e" if (current['bb_upper'] - current['bb_lower']) / current['bb_middle'] > 0.01 else "Faible",
                "momentum": "Haussi√®re" if current['rsi'] > 50 else "Baissi√®re"
            }
        }
        
        return response
        
    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration du signal de trading: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur serveur: {str(e)}")

# ============================================================================
# ENDPOINTS: FEEDBACK LOOP & MONITORING (Phase 1)
# ============================================================================

async def _trigger_retraining_async(category: str):
    """D√©clenche le r√©entra√Ænement en arri√®re-plan de mani√®re asynchrone"""
    try:
        if continuous_learner:
            logger.info(f"üîÑ [AUTO-RETRAIN] D√©but r√©entra√Ænement pour {category}...")
            result = continuous_learner.retrain_model_for_category(category)
            if result.get("status") == "success":
                improvement = result.get('improvement', 0)
                old_acc = result.get('old_accuracy', 0)
                new_acc = result.get('new_accuracy', 0)
                samples = result.get('samples_used', 0)
                success_msg = (
                    f"‚úÖ [AUTO-RETRAIN] R√©entra√Ænement r√©ussi pour {category}:\n"
                    f"   - √âchantillons utilis√©s: {samples}\n"
                    f"   - Pr√©cision ancienne: {old_acc:.3f}\n"
                    f"   - Pr√©cision nouvelle: {new_acc:.3f}\n"
                    f"   - Am√©lioration: +{improvement:.3f} ({improvement*100:.2f}%)"
                )
                logger.info(success_msg)
            elif result.get("status") == "no_improvement":
                improvement = result.get('improvement', 0)
                logger.info(
                    f"‚è∏Ô∏è [AUTO-RETRAIN] R√©entra√Ænement pour {category}: "
                    f"pas d'am√©lioration suffisante ({improvement:.3f} < 0.02)"
                )
            elif result.get("status") == "skipped":
                reason = result.get('reason', 'unknown')
                logger.info(f"‚è∏Ô∏è [AUTO-RETRAIN] R√©entra√Ænement pour {category} ignor√©: {reason}")
            else:
                logger.warning(f"‚ö†Ô∏è [AUTO-RETRAIN] R√©entra√Ænement pour {category}: {result.get('reason', 'unknown')}")
    except Exception as e:
        logger.error(f"‚ùå [AUTO-RETRAIN] Erreur lors du r√©entra√Ænement en arri√®re-plan: {e}", exc_info=True)

feedback_count = 0

@app.post("/trades/feedback")
async def receive_trade_feedback(feedback: TradeFeedback):
    """
    Endpoint pour recevoir les r√©sultats de trade depuis le robot MT5
    Mode simplifi√© ou complet selon la configuration
    """
    global feedback_count
    feedback_count += 1
    
    logger.info(f"üìä Feedback re√ßu: {feedback.symbol} - Profit: {feedback.profit:.2f} - Win: {feedback.is_win}")
    
    # MODE SIMPLIFI√â - Pas de base de donn√©es
    if SIMPLIFIED_MODE:
        return {
            "status": "received",
            "message": f"Feedback trait√© pour {feedback.symbol}",
            "total_feedbacks": feedback_count,
            "mode": "simplified"
        }
    
    # MODE COMPLET - Avec base de donn√©es
    if not DB_AVAILABLE:
        raise HTTPException(
            status_code=503,
            detail="Service de feedback non disponible - DATABASE_URL non configur√©e"
        )
    
    try:
        pool = await get_db_pool()
        if not pool:
            raise HTTPException(status_code=503, detail="Connexion base de donn√©es impossible")
        
        # Valider et parser les timestamps
        try:
            open_time_dt = datetime.fromisoformat(feedback.open_time.replace('Z', '+00:00'))
            close_time_dt = datetime.fromisoformat(feedback.close_time.replace('Z', '+00:00'))
        except ValueError as e:
            raise HTTPException(
                status_code=400,
                detail=f"Format de date invalide: {str(e)}. Utilisez le format ISO 8601"
            )
        
        # Ins√©rer dans la base de donn√©es
        async with pool.acquire() as conn:
            await conn.execute("""
                INSERT INTO trade_feedback (
                    symbol, open_time, close_time, entry_price, exit_price,
                    profit, ai_confidence, coherent_confidence, decision, is_win
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
            """,
                feedback.symbol,
                open_time_dt,
                close_time_dt,
                feedback.entry_price,
                feedback.exit_price,
                feedback.profit,
                feedback.ai_confidence,
                feedback.coherent_confidence,
                feedback.decision,
                feedback.is_win
            )
        
        # Logger pour suivi
        win_str = "‚úÖ WIN" if feedback.is_win else "‚ùå LOSS"
        logger.info(
            f"üìä Feedback re√ßu: {feedback.symbol} {feedback.decision} - "
            f"Profit: ${feedback.profit:.2f} {win_str} "
            f"(IA: {feedback.ai_confidence:.1%}, Coh: {feedback.coherent_confidence:.1%})"
        )
        
        # D√©clencher automatiquement le r√©entra√Ænement en arri√®re-plan (non-bloquant)
        if CONTINUOUS_LEARNING_AVAILABLE and continuous_learner:
            # V√©rifier combien de trades ont √©t√© re√ßus pour cette cat√©gorie
            try:
                # Map le symbole vers sa cat√©gorie
                symbol_upper = feedback.symbol.upper()
                if "BOOM" in symbol_upper or "CRASH" in symbol_upper:
                    category = "BOOM_CRASH"
                elif any(keyword in symbol_upper for keyword in ['VOLATILITY', 'STEP', 'JUMP', 'RANGE BREAK']):
                    category = "VOLATILITY"
                elif any(crypto in symbol_upper for crypto in ['BTC', 'ETH', 'ADA', 'DOT']):
                    category = "CRYPTO"
                elif any(pair in symbol_upper for pair in ['USD', 'EUR', 'GBP', 'JPY']):
                    category = "FOREX"
                else:
                    category = "COMMODITIES"
                
                # Compter les trades r√©cents pour cette cat√©gorie
                async with pool.acquire() as conn:
                    count_result = await conn.fetchval("""
                        SELECT COUNT(*) FROM trade_feedback
                        WHERE created_at >= NOW() - INTERVAL '7 days'
                        AND (
                            CASE
                                WHEN symbol LIKE '%BOOM%' OR symbol LIKE '%CRASH%' THEN 'BOOM_CRASH'
                                WHEN symbol LIKE '%VOLATILITY%' OR symbol LIKE '%STEP%' OR symbol LIKE '%JUMP%' THEN 'VOLATILITY'
                                WHEN symbol LIKE '%BTC%' OR symbol LIKE '%ETH%' THEN 'CRYPTO'
                                WHEN symbol LIKE '%USD%' OR symbol LIKE '%EUR%' OR symbol LIKE '%GBP%' THEN 'FOREX'
                                ELSE 'COMMODITIES'
                            END
                        ) = $1
                    """, category)
                    
                    # Si on a assez de trades, d√©clencher le r√©entra√Ænement en arri√®re-plan
                    if count_result and count_result >= continuous_learner.min_new_samples:
                        logger.info(f"üîÑ Assez de trades ({count_result}) pour r√©entra√Æner {category} - D√©clenchement en arri√®re-plan...")
                        # D√©clencher le r√©entra√Ænement de mani√®re asynchrone (non-bloquant)
                        asyncio.create_task(_trigger_retraining_async(category))
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur lors de la v√©rification du r√©entra√Ænement: {e}")
        
        return {
            "status": "ok",
            "message": "Feedback enregistr√© avec succ√®s",
            "symbol": feedback.symbol,
            "profit": feedback.profit
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur enregistrement feedback: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur serveur: {str(e)}")


@app.get("/ml/feedback/status")
async def get_feedback_status():
    """
    V√©rifie le statut de la base de donn√©es trade_feedback
    Retourne des statistiques sur les trades enregistr√©s pour le monitoring
    """
    if not DB_AVAILABLE:
        return {
            "status": "error",
            "error": "Base de donn√©es non disponible - DATABASE_URL non configur√©e",
            "db_available": False
        }
    
    try:
        # Ajouter un timeout explicite pour √©viter que la requ√™te bloque ind√©finiment
        pool = await asyncio.wait_for(get_db_pool(), timeout=10.0)
        if not pool:
            return {
                "status": "error",
                "error": "Connexion base de donn√©es impossible - pool non cr√©√©",
                "db_available": False
            }
        
        # Tester la connexion avec un timeout explicite
        try:
            async with pool.acquire() as conn:
                # Statistiques globales (avec timeout explicite)
                total_trades = await asyncio.wait_for(
                    conn.fetchval("SELECT COUNT(*) FROM trade_feedback"), 
                    timeout=10.0
                )
                total_win = await asyncio.wait_for(
                    conn.fetchval("SELECT COUNT(*) FROM trade_feedback WHERE is_win = true"),
                    timeout=10.0
                )
                total_loss = await asyncio.wait_for(
                    conn.fetchval("SELECT COUNT(*) FROM trade_feedback WHERE is_win = false"),
                    timeout=10.0
                )
                total_profit = await asyncio.wait_for(
                    conn.fetchval("SELECT SUM(profit) FROM trade_feedback"),
                    timeout=10.0
                )
            
                # Trades r√©cents (7 derniers jours)
                recent_trades = await asyncio.wait_for(
                    conn.fetchval("SELECT COUNT(*) FROM trade_feedback WHERE created_at >= NOW() - INTERVAL '7 days'"),
                    timeout=10.0
                )
                
                # Trades par cat√©gorie
                trades_by_category = await asyncio.wait_for(
                    conn.fetch("""
                SELECT 
                    CASE
                        WHEN symbol LIKE '%BOOM%' OR symbol LIKE '%CRASH%' THEN 'BOOM_CRASH'
                        WHEN symbol LIKE '%VOLATILITY%' OR symbol LIKE '%STEP%' OR symbol LIKE '%JUMP%' THEN 'VOLATILITY'
                        WHEN symbol LIKE '%BTC%' OR symbol LIKE '%ETH%' OR symbol LIKE '%ADA%' THEN 'CRYPTO'
                        WHEN symbol LIKE '%USD%' OR symbol LIKE '%EUR%' OR symbol LIKE '%GBP%' OR symbol LIKE '%JPY%' THEN 'FOREX'
                        ELSE 'COMMODITIES'
                    END as category,
                    COUNT(*) as count,
                    SUM(CASE WHEN is_win THEN 1 ELSE 0 END) as wins,
                    SUM(profit) as total_profit
                FROM trade_feedback
                WHERE created_at >= NOW() - INTERVAL '30 days'
                GROUP BY category
                ORDER BY count DESC
                    """),
                    timeout=10.0
                )
                
                # Derniers trades
                last_trades = await asyncio.wait_for(
                    conn.fetch("""
                    SELECT symbol, decision, profit, is_win, created_at
                    FROM trade_feedback
                    ORDER BY created_at DESC
                    LIMIT 10
                """),
                    timeout=10.0
                )
                
                # V√©rifier si on a assez de trades pour le r√©entra√Ænement
                min_samples = continuous_learner.min_new_samples if CONTINUOUS_LEARNING_AVAILABLE and continuous_learner else 50
                ready_for_retraining = {}
                
                for row in trades_by_category:
                    category = row['category']
                    count = row['count']
                    ready_for_retraining[category] = {
                        "count": count,
                        "ready": count >= min_samples,
                        "wins": row['wins'],
                        "total_profit": float(row['total_profit']) if row['total_profit'] else 0.0
                    }
                
                win_rate = (total_win / total_trades * 100) if total_trades > 0 else 0.0
                
                return {
                "status": "ok",
                "db_available": True,
                "statistics": {
                    "total_trades": total_trades,
                    "total_wins": total_win,
                    "total_losses": total_loss,
                    "win_rate": round(win_rate, 2),
                    "total_profit": float(total_profit) if total_profit else 0.0,
                    "recent_trades_7d": recent_trades,
                    "min_samples_for_retraining": min_samples
                },
                "trades_by_category": {
                    row['category']: {
                        "count": row['count'],
                        "wins": row['wins'],
                        "total_profit": float(row['total_profit']) if row['total_profit'] else 0.0,
                        "ready_for_retraining": row['count'] >= min_samples
                    }
                    for row in trades_by_category
                },
                "last_trades": [
                    {
                        "symbol": row['symbol'],
                        "decision": row['decision'],
                        "profit": float(row['profit']),
                        "is_win": row['is_win'],
                        "created_at": row['created_at'].isoformat() if row['created_at'] else None
                    }
                    for row in last_trades
                ],
                "continuous_learning": {
                    "available": CONTINUOUS_LEARNING_AVAILABLE,
                    "min_samples": min_samples,
                    "retrain_interval_days": continuous_learner.retrain_interval_days if CONTINUOUS_LEARNING_AVAILABLE and continuous_learner else None
                }
                }
        except asyncio.TimeoutError:
            logger.error("Timeout lors de la connexion √† la base de donn√©es PostgreSQL")
            return {
                "status": "error",
                "error": "Timeout lors de la connexion √† la base de donn√©es - V√©rifiez la connexion r√©seau ou le serveur PostgreSQL",
                "db_available": DB_AVAILABLE
            }
        except Exception as e:
            logger.error(f"Erreur lors de la v√©rification du statut feedback: {e}", exc_info=True)
            return {
                "status": "error",
                "error": str(e),
                "db_available": DB_AVAILABLE
            }
    except asyncio.TimeoutError:
        logger.error("Timeout lors de la connexion √† la base de donn√©es PostgreSQL")
        return {
            "status": "error",
            "error": "Timeout lors de la connexion √† la base de donn√©es - V√©rifiez la connexion r√©seau ou le serveur PostgreSQL",
            "db_available": DB_AVAILABLE
        }
    except Exception as e:
        logger.error(f"Erreur lors de la v√©rification du statut feedback: {e}", exc_info=True)
        return {
            "status": "error",
            "error": str(e),
            "db_available": DB_AVAILABLE
        }

@app.get("/ml/retraining/stats")
async def get_retraining_stats():
    """
    Retourne les statistiques de r√©entra√Ænement des mod√®les ML
    """
    if not CONTINUOUS_LEARNING_AVAILABLE or not continuous_learner:
        return {
            "status": "error",
            "error": "Syst√®me d'apprentissage continu non disponible"
        }
    
    try:
        # Charger les timestamps de dernier r√©entra√Ænement
        last_retrain_times = continuous_learner.last_retrain_times
        retrain_stats = {}
        
        categories = ["BOOM_CRASH", "VOLATILITY", "FOREX", "CRYPTO", "COMMODITIES"]
        for category in categories:
            last_time = last_retrain_times.get(category)
            if last_time:
                last_dt = datetime.fromisoformat(last_time)
                days_since = (datetime.now() - last_dt).days
                hours_since = (datetime.now() - last_dt).total_seconds() / 3600
                
                retrain_stats[category] = {
                    "last_retrained": last_time,
                    "days_since": days_since,
                    "hours_since": round(hours_since, 2),
                    "should_retrain": continuous_learner._should_retrain(category)
                }
            else:
                retrain_stats[category] = {
                    "last_retrained": None,
                    "days_since": None,
                    "hours_since": None,
                    "should_retrain": True
                }
        
        return {
            "status": "ok",
            "config": {
                "min_new_samples": continuous_learner.min_new_samples,
                "retrain_interval_days": continuous_learner.retrain_interval_days
            },
            "retraining_status": retrain_stats
        }
        
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration des stats de r√©entra√Ænement: {e}", exc_info=True)
        return {
            "status": "error",
            "error": str(e)
        }

@app.post("/ml/retraining/trigger")
async def trigger_retraining(category: Optional[str] = None):
    """
    D√©clenche manuellement le r√©entra√Ænement pour une cat√©gorie ou toutes les cat√©gories
    
    Body params:
        - category: Cat√©gorie sp√©cifique √† r√©entra√Æner (BOOM_CRASH, VOLATILITY, FOREX, CRYPTO, COMMODITIES)
                   Si non sp√©cifi√©, r√©entra√Æne toutes les cat√©gories disponibles
    """
    if not CONTINUOUS_LEARNING_AVAILABLE or not continuous_learner:
        raise HTTPException(
            status_code=503,
            detail="Syst√®me d'apprentissage continu non disponible"
        )
    
    try:
        if category:
            # R√©entra√Æner une cat√©gorie sp√©cifique
            logger.info(f"üîÑ [MANUAL-RETRAIN] D√©clenchement manuel du r√©entra√Ænement pour {category}")
            result = continuous_learner.retrain_model_for_category(category)
            
            return {
                "status": "ok",
                "category": category,
                "result": result
            }
        else:
            # R√©entra√Æner toutes les cat√©gories
            logger.info("üîÑ [MANUAL-RETRAIN] D√©clenchement manuel du r√©entra√Ænement pour toutes les cat√©gories")
            results = continuous_learner.retrain_all_categories()
            
            return {
                "status": "ok",
                "message": "R√©entra√Ænement d√©clench√© pour toutes les cat√©gories",
                "results": results
            }
            
    except Exception as e:
        logger.error(f"Erreur lors du r√©entra√Ænement manuel: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur serveur: {str(e)}")

@app.get("/monitoring/dashboard")
async def monitoring_dashboard(symbols: Optional[str] = None, limit: int = 100):
    """
    Dashboard de monitoring en temps r√©el
    Retourne les statistiques de performance par symbole et globales
    
    Query params:
        - symbols: Filtre par symboles (s√©par√©s par virgules), ex: "Volatility 75 Index,Boom 300 Index"
        - limit: Nombre maximum de trades r√©cents √† analyser (d√©faut: 100)
    """
    if not DB_AVAILABLE:
        return {
            "error": "Service de monitoring non disponible - DATABASE_URL non configur√©e",
            "win_rate": 0,
            "pnl_total": 0,
            "pnl_par_symbole": {},
            "objectif_progress": 0,
            "alertes": ["Base de donn√©es non disponible"]
        }
    
    try:
        pool = await get_db_pool()
        if not pool:
            raise HTTPException(status_code=503, detail="Connexion base de donn√©es impossible")
        
        async with pool.acquire() as conn:
            # Requ√™te de base
            query = """
                SELECT symbol, profit, is_win, ai_confidence, coherent_confidence,
                       decision, created_at
                FROM trade_feedback
                ORDER BY created_at DESC
                LIMIT $1
            """
            params = [limit]
            
            # Filtrer par symboles si demand√©
            if symbols:
                symbol_list = [s.strip() for s in symbols.split(',')]
                query = """
                    SELECT symbol, profit, is_win, ai_confidence, coherent_confidence,
                           decision, created_at
                    FROM trade_feedback
                    WHERE symbol = ANY($2::text[])
                    ORDER BY created_at DESC
                    LIMIT $1
                """
                params = [limit, symbol_list]
            
            rows = await conn.fetch(query, *params)
        
        if not rows:
            return {
                "win_rate": 0.0,
                "pnl_total": 0.0,
                "total_trades": 0,
                "pnl_par_symbole": {},
                "objectif_progress": 0.0,
                "recent_trades": [],
                "alertes": ["Aucune donn√©e de trading disponible"],
                "timestamp": datetime.now().isoformat()
            }
        
        # Calcul des statistiques
        total_trades = len(rows)
        wins = sum(1 for r in rows if r["is_win"])
        pnl_total = sum(float(r["profit"] or 0) for r in rows)
        win_rate = wins / total_trades if total_trades > 0 else 0.0
        
        # PnL par symbole
        pnl_by_symbol = {}
        trades_by_symbol = {}
        wins_by_symbol = {}
        
        for r in rows:
            sym = r["symbol"] or "UNKNOWN"
            if sym not in pnl_by_symbol:
                pnl_by_symbol[sym] = 0.0
                trades_by_symbol[sym] = 0
                wins_by_symbol[sym] = 0
            
            pnl_by_symbol[sym] += float(r["profit"] or 0)
            trades_by_symbol[sym] += 1
            if r["is_win"]:
                wins_by_symbol[sym] += 1
        
        # Compiler stats par symbole
        symbol_stats = {}
        for sym in pnl_by_symbol.keys():
            symbol_stats[sym] = {
                "pnl": round(pnl_by_symbol[sym], 2),
                "trades": trades_by_symbol[sym],
                "win_rate": round(wins_by_symbol[sym] / trades_by_symbol[sym] * 100, 1) if trades_by_symbol[sym] > 0 else 0
            }
        
        # G√©n√©rer alertes intelligentes
        alertes = []
        if total_trades >= 5 and win_rate < 0.40:
            alertes.append(f"‚ö†Ô∏è Win rate faible: {win_rate*100:.1f}% (seuil critique: 40%)")
        if pnl_total < -50:
            alertes.append(f"üî¥ Pertes cumul√©es √©lev√©es: ${pnl_total:.2f}")
        if total_trades >= 10 and win_rate >= 0.70:
            alertes.append(f"üéâ Performance excellente! Win rate: {win_rate*100:.1f}%")
        
        # Analyser les symboles perdants
        for sym, stats in symbol_stats.items():
            if stats["trades"] >= 3 and stats["pnl"] < -20:
                alertes.append(f"‚ö†Ô∏è Symbole perdant: {sym} (${stats['pnl']:.2f} sur {stats['trades']} trades)")
        
        if not alertes:
            alertes.append("‚úÖ Aucune alerte - Performance normale")
        
        # Progression vers objectif quotidien (exemple: 30$ par jour)
        objectif_quotidien = 30.0
        objectif_progress = min((pnl_total / objectif_quotidien) * 100, 100) if  pnl_total > 0 else 0
        
        # Trades r√©cents (les 10 derniers)
        recent_trades = [
            {
                "symbol": r["symbol"],
                "decision": r["decision"],
                "profit": round(float(r["profit"]), 2),
                "is_win": r["is_win"],
                "ai_confidence": round(float(r["ai_confidence"] or 0), 2),
                "timestamp": r["created_at"].isoformat() if hasattr(r["created_at"], 'isoformat') else str(r["created_at"])
            }
            for r in rows[:10]
        ]
        
        return {
            "win_rate": round(win_rate, 3),
            "pnl_total": round(pnl_total, 2),
            "total_trades": total_trades,
            "pnl_par_symbole": symbol_stats,
            "objectif_progress": round(objectif_progress, 1),
            "objectif_quotidien": objectif_quotidien,
            "recent_trades": recent_trades,
            "alertes": alertes,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur monitoring dashboard: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur serveur: {str(e)}")

# ============================================================================
# MAIN
# ============================================================================


# Endpoint pour les indicateurs avanc√©s
@app.post("/indicators/analyze")
async def analyze_indicators(request_data: Dict[str, Any]):
    """Analyse les donn√©es de march√© avec AdvancedIndicators"""
    try:
        if not AI_INDICATORS_AVAILABLE:
            raise HTTPException(status_code=503, detail="Module ai_indicators non disponible")
        
        symbol = request_data.get("symbol")
        timeframe = request_data.get("timeframe", "M1")
        market_data = request_data.get("market_data")
        
        if not symbol or not market_data:
            raise HTTPException(status_code=400, detail="symbol et market_data requis")
        
        # Utiliser le cache pour √©viter de recr√©er l'instance
        cache_key = f"{symbol}_{timeframe}"
        if cache_key not in indicators_cache:
            indicators_cache[cache_key] = AdvancedIndicators(symbol, timeframe)
        
        analyzer = indicators_cache[cache_key]
        result = analyzer.process_market_data(market_data)
        
        return result
    except Exception as e:
        logger.error(f"Erreur analyse indicateurs: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/indicators/sentiment/{symbol}")
async def get_market_sentiment(symbol: str, timeframe: str = "H1"):
    """R√©cup√®re le sentiment du march√© pour un symbole"""
    try:
        if not AI_INDICATORS_AVAILABLE:
            raise HTTPException(status_code=503, detail="Module ai_indicators non disponible")
        
        # R√©cup√©rer les donn√©es depuis MT5
        if not mt5_initialized:
            raise HTTPException(status_code=503, detail="MT5 non initialis√©")
        
        tf_map = {
            "M1": mt5.TIMEFRAME_M1,
            "M5": mt5.TIMEFRAME_M5,
            "M15": mt5.TIMEFRAME_M15,
            "H1": mt5.TIMEFRAME_H1,
            "H4": mt5.TIMEFRAME_H4,
            "D1": mt5.TIMEFRAME_D1
        }
        
        tf = tf_map.get(timeframe, mt5.TIMEFRAME_H1)
        rates = mt5.copy_rates_from_pos(symbol, tf, 0, 500)
        
        if rates is None or len(rates) == 0:
            raise HTTPException(status_code=404, detail="Aucune donn√©e disponible")
        
        df = pd.DataFrame(rates)
        df['time'] = pd.to_datetime(df['time'], unit='s')
        
        # Utiliser AdvancedIndicators pour calculer le sentiment
        cache_key = f"{symbol}_{timeframe}"
        if cache_key not in indicators_cache:
            indicators_cache[cache_key] = AdvancedIndicators(symbol, timeframe)
        
        analyzer = indicators_cache[cache_key]
        sentiment = analyzer.calculate_market_sentiment(df)
        
        return {
            "symbol": symbol,
            "timeframe": timeframe,
            "timestamp": datetime.now().isoformat(),
            "sentiment": sentiment
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur sentiment march√©: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/indicators/volume_profile/{symbol}")
async def get_volume_profile(symbol: str, timeframe: str = "H1", num_bins: int = 20):
    """R√©cup√®re le profil de volume pour un symbole"""
    try:
        if not AI_INDICATORS_AVAILABLE:
            raise HTTPException(status_code=503, detail="Module ai_indicators non disponible")
        
        if not mt5_initialized:
            raise HTTPException(status_code=503, detail="MT5 non initialis√©")
        
        tf_map = {
            "M1": mt5.TIMEFRAME_M1,
            "M5": mt5.TIMEFRAME_M5,
            "M15": mt5.TIMEFRAME_M15,
            "H1": mt5.TIMEFRAME_H1,
            "H4": mt5.TIMEFRAME_H4,
            "D1": mt5.TIMEFRAME_D1
        }
        
        tf = tf_map.get(timeframe, mt5.TIMEFRAME_H1)
        rates = mt5.copy_rates_from_pos(symbol, tf, 0, 500)
        
        if rates is None or len(rates) == 0:
            raise HTTPException(status_code=404, detail="Aucune donn√©e disponible")
        
        df = pd.DataFrame(rates)
        df['time'] = pd.to_datetime(df['time'], unit='s')
        
        # Calculer le profil de volume
        cache_key = f"{symbol}_{timeframe}"
        if cache_key not in indicators_cache:
            indicators_cache[cache_key] = AdvancedIndicators(symbol, timeframe)
        
        analyzer = indicators_cache[cache_key]
        volume_profile = analyzer.calculate_volume_profile(df, num_bins)
        
        return {
            "symbol": symbol,
            "timeframe": timeframe,
            "timestamp": datetime.now().isoformat(),
            "volume_profile": volume_profile
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur profil volume: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# Endpoint pour l'analyse avec Gemini AI
@app.post("/analyze/gemini")
async def analyze_with_gemini_endpoint(request_data: Dict[str, Any]):
    """Analyse de march√© avec Google Gemini AI"""
    try:
        if not GEMINI_AVAILABLE:
            raise HTTPException(status_code=503, detail="Google Gemini AI non disponible")
        
        symbol = request_data.get("symbol", "UNKNOWN")
        market_data = request_data.get("market_data", {})
        question = request_data.get("question", "Analyse ce march√© et donne une recommandation de trading")
        
        # Construire le prompt
        prompt = f"""
Analyse de trading pour {symbol}

Donn√©es de march√©:
{json.dumps(market_data, indent=2)}

Question: {question}

Fournis une analyse d√©taill√©e incluant:
1. Analyse technique du march√©
2. Recommandation (BUY/SELL/HOLD)
3. Niveau de confiance (0-100%)
4. Raisonnement clair
"""
        
        result = analyze_with_gemini(prompt)
        if not result:
            raise HTTPException(status_code=500, detail="Erreur lors de l'analyse Gemini")
        
        return {
            "symbol": symbol,
            "timestamp": datetime.now().isoformat(),
            "analysis": result,
            "provider": "google-gemini-1.5-flash"
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur analyse Gemini: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# Endpoint pour la validation des ordres
@app.post("/validate_order")
async def validate_order(order_data: Dict[str, Any]):
    """Valide un ordre avant ex√©cution"""
    try:
        symbol = order_data.get("symbol")
        order_type = order_data.get("type")  # "BUY" or "SELL"
        volume = order_data.get("volume", 0.01)
        sl = order_data.get("stop_loss")
        tp = order_data.get("take_profit")
        
        if not symbol:
            return {"valid": False, "reason": "Symbole manquant"}
        
        # R√©cup√©rer les donn√©es actuelles
        if mt5_initialized:
            symbol_info = mt5.symbol_info(symbol)
            if symbol_info is None:
                return {"valid": False, "reason": "Symbole introuvable"}
            
            tick = mt5.symbol_info_tick(symbol)
            if tick is None:
                return {"valid": False, "reason": "Impossible de r√©cup√©rer le tick"}
            
            current_price = tick.ask if order_type == "BUY" else tick.bid
            
            # V√©rifier les stops
            min_stop = symbol_info.trade_stops_level * symbol_info.point
            if sl and abs(current_price - sl) < min_stop:
                return {
                    "valid": False,
                    "reason": f"Stop Loss trop proche (minimum: {min_stop} points)"
                }
            if tp and abs(current_price - tp) < min_stop:
                return {
                    "valid": False,
                    "reason": f"Take Profit trop proche (minimum: {min_stop} points)"
                }
            
            return {
                "valid": True,
                "current_price": float(current_price),
                "min_stop_points": float(min_stop / symbol_info.point)
            }
        else:
            return {"valid": False, "reason": "MT5 non initialis√©"}
    except Exception as e:
        logger.error(f"Erreur validation ordre: {e}", exc_info=True)
        return {"valid": False, "reason": f"Erreur: {str(e)}"}

class GemmaTradingResponse(BaseModel):
    """Mod√®le pour les r√©ponses de trading avec Gemma"""
    success: bool
    symbol: str
    timeframe: str
    analysis: Optional[str] = None
    chart_filename: Optional[str] = None
    error: Optional[str] = None
    timestamp: str = Field(default_factory=lambda: datetime.utcnow().isoformat())

class TradingSignalRequest(BaseModel):
    """Mod√®le pour les requ√™tes de signaux de trading"""
    symbol: str
    timeframe: str
    analysis: str
    indicators: Optional[Dict[str, Any]] = None

class TradingSignalResponse(BaseModel):
    """Mod√®le pour les r√©ponses de signaux de trading"""
    success: bool
    signal: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    timestamp: str = Field(default_factory=lambda: datetime.utcnow().isoformat())

class GemmaTradingRequest(BaseModel):
    """Mod√®le pour les requ√™tes d'analyse de graphique Gemma"""
    symbol: str
    timeframe: str
    prompt: Optional[str] = None
    capture_chart: bool = True
    max_tokens: int = 200
    temperature: float = 0.7
    top_p: float = 0.9

class IndicatorsResponse(BaseModel):
    """Mod√®le pour les r√©ponses d'indicateurs MT5"""
    symbol: str
    timeframe: str
    indicators: Dict[str, Any]

# ===================== GEMMA TRADING BOT =====================

class GemmaTradingBot:
    """Gestion de la capture et de l'analyse de graphiques pour le trading"""

    def __init__(self, config: Optional[Dict[str, Any]] | None = None):
        self.config = config or {}
        self.model_path = self.config.get("model_path", GEMMA_MODEL_PATH)
        self.mt5_files_dir = self.config.get("mt5_files_dir", MT5_FILES_DIR)
        self.chart_dir = os.path.join(self.mt5_files_dir, "Charts")
        os.makedirs(self.chart_dir, exist_ok=True)

    # Note: on √©vite Optional[Image.Image] car Image peut √™tre None si PIL n'est pas install√©,
    # et les annotations sont √©valu√©es au chargement du module (crash Render sinon).
    def capture_chart(self, symbol: str, timeframe: str, width: int = 800, height: int = 600) -> Tuple[Optional[Any], Optional[str]]:
        if not MT5_AVAILABLE or not 'mt5' in globals() or not mt5_initialized:
            logger.warning("MT5 non initialis√©, capture impossible")
            return None, None

        if not mt5.symbol_select(symbol, True):
            logger.error("Symbole %s introuvable dans MT5", symbol)
            return None, None

        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        filename = f"{symbol}_{timeframe}_{timestamp}.png"
        filepath = os.path.join(self.chart_dir, filename)

        try:
            if not mt5.chart_save(0, filepath, width, height, 0):
                logger.error("chart_save a √©chou√© pour %s %s", symbol, timeframe)
                return None, None
            if Image is None:
                logger.error("PIL (Pillow) n'est pas install√©: impossible d'ouvrir l'image %s", filepath)
                return None, filename
            image = Image.open(filepath)
            return image, filename
        except Exception as exc:
            logger.error("Erreur capture_chart: %s", exc, exc_info=True)
            return None, None

    def analyze_chart(self, symbol: str, timeframe: str, image: Optional[Any] = None, prompt: Optional[str] = None) -> Optional[str]:
        if not GEMMA_AVAILABLE:
            logger.warning("Gemma non disponible")
            return None
        if image is None:
            image, _ = self.capture_chart(symbol, timeframe)
            if image is None:
                return None

        prompt = prompt or (
            f"Analyse ce graphique pour {symbol} sur {timeframe}. "
            "Identifie la tendance, supports, r√©sistances et donne un commentaire concis."
        )

        temp_path = os.path.join(self.chart_dir, f"temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
        image.save(temp_path)
        try:
            result = analyze_with_gemma(prompt=prompt, image_filename=temp_path)
            return result
        finally:
            try:
                os.remove(temp_path)
            except OSError:
                pass
                
    def analyze_gemma_response(self, response: str) -> None:
        """Analyse et log les signaux d√©tect√©s dans la r√©ponse Gemma"""
        if not response:
            return
            
        try:
            # D√©tection des signaux de trading
            signals = {
                'buy': ['acheter', 'long', 'haussier', 'bullish', '‚Üë', 'üîº', 'üìà', 'üöÄ'],
                'sell': ['vendre', 'short', 'baissier', 'bearish', '‚Üì', 'üîΩ', 'üìâ', 'üí•'],
                'neutral': ['neutre', 'lateral', 'ranging', 'consolidation', 'sideways', '‚û°Ô∏è']
            }
            
            detected_signals = []
            for signal, keywords in signals.items():
                if any(keyword in response.lower() for keyword in keywords):
                    detected_signals.append(signal.upper())
            
            # D√©tection des niveaux de prix
            import re
            price_levels = re.findall(r'\b\d+\.?\d*\b', response)
            
            # Log des r√©sultats
            logger.info("\n" + "="*80)
            logger.info("üìä R√âSULTATS GEMMA")
            logger.info("="*80)
            if detected_signals:
                logger.info(f"üì° Signaux d√©tect√©s: {', '.join(detected_signals)}")
            else:
                logger.info("‚ÑπÔ∏è Aucun signal clair d√©tect√©")
                
            if price_levels:
                logger.info(f"üéØ Niveaux de prix d√©tect√©s: {', '.join(price_levels[:5])}")
                
            # D√©tection des mots-cl√©s importants
            important_keywords = ['stop loss', 'take profit', 'risque', 'opportunit√©', 'tendance']
            found_keywords = [kw for kw in important_keywords if kw in response.lower()]
            if found_keywords:
                logger.info(f"üîç Mots-cl√©s importants: {', '.join(found_keywords)}")
                
            logger.info("="*80 + "\n")
            
        except Exception as e:
            logger.error(f"Erreur lors de l'analyse de la r√©ponse Gemma: {str(e)}")

# Instance r√©utilisable
gemma_trading_bot = GemmaTradingBot()

# ---------------------- Endpoints Trading ----------------------

# Route pour obtenir les indicateurs bruts
@app.get("/trading/indicators/{symbol}/{timeframe}")
async def get_indicators(symbol: str, timeframe: str):
    indicators = get_mt5_indicators(symbol, timeframe)
    if not indicators:
        raise HTTPException(
            status_code=400,
            detail=f"Impossible de r√©cup√©rer les indicateurs pour {symbol}"
        )
    return JSONResponse(content={
        "symbol": symbol,
        "timeframe": timeframe,
        "indicators": indicators
    })

# Route d'analyse avec Gemma utilisant les indicateurs MT5
@app.post("/trading/analyze")
async def analyze_trading_chart(request: GemmaTradingRequest):
    try:
        # R√©cup√©ration des indicateurs MT5
        indicators = get_mt5_indicators(request.symbol, request.timeframe)
        if not indicators:
            return JSONResponse(
                status_code=400,
                content={"error": f"Impossible de r√©cup√©rer les indicateurs pour {request.symbol}"}
            )
        
        # Cr√©ation du prompt avec les indicateurs
        analysis_prompt = f"""
        Analyse technique pour {request.symbol} ({request.timeframe}):
        
        Prix:
        - Actuel: {indicators['current_price']}
        - Ouverture: {indicators['open']}
        - Plus haut: {indicators['high']}
        - Plus bas: {indicators['low']}
        
        Moyennes mobiles:
        - SMA 20: {indicators['sma_20']}
        - SMA 50: {indicators['sma_50']}
        - SMA 200: {indicators['sma_200']}
        
        Indicateurs:
        - RSI (14): {indicators['rsi']:.2f}
        - ATR (14): {indicators['atr']:.5f}
        - MACD: {indicators['macd']:.5f}
        - Bandes de Bollinger: {indicators['bb_lower']:.5f} - {indicators['bb_upper']:.5f}
        - Volume: {indicators['volume']}
        
        {request.prompt or "Donne une analyse technique compl√®te et des recommandations de trading."}
        """
        
        # Utilisation de Gemma pour l'analyse
        if not GEMMA_AVAILABLE:
            return {"error": "Gemma n'est pas disponible"}
            
        try:
            inputs = gemma_processor(analysis_prompt, return_tensors="pt")
            outputs = gemma_model.generate(**inputs, max_length=1000)
            analysis = gemma_processor.decode(outputs[0], skip_special_tokens=True)
            
            return {
                "symbol": request.symbol,
                "timeframe": request.timeframe,
                "analysis": analysis,
                "indicators": indicators
            }
            
        except Exception as e:
            return {"error": f"Erreur lors de l'analyse avec Gemma: {str(e)}"}
            
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": f"Erreur lors de l'analyse: {str(e)}"}
        )

@app.post("/trading/generate-signal", response_model=TradingSignalResponse)
async def generate_trading_signal(request: TradingSignalRequest):
    try:
        if not GEMMA_AVAILABLE:
            raise ValueError("Gemma non disponible")

        prompt = f"""
        G√©n√®re un signal de trading clair pour {request.symbol} ({request.timeframe}) bas√© sur l'analyse suivante :
        {request.analysis}

        Indicateurs:
        {json.dumps(request.indicators or {}, indent=2)}

        Format de la r√©ponse attendu :
        Action: BUY/SELL/HOLD
        Entr√©e: <prix>
        StopLoss: <prix>
        TakeProfit: <prix>
        Confiance: <0-100%>
        Raisonnement:
        """

        response_text = analyze_with_gemma(prompt=prompt)
        if not response_text:
            raise ValueError("Impossible de g√©n√©rer le signal")

        signal = {"raw_response": response_text}

        return TradingSignalResponse(success=True, signal=signal)
    except Exception as exc:
        logger.error("Erreur generate_trading_signal: %s", exc, exc_info=True)
        return TradingSignalResponse(success=False, error=str(exc))

# =============================================================================
class GemmaAnalysisRequest(BaseModel):
    """Mod√®le pour les requ√™tes d'analyse Gemma"""
    prompt: str
    image_filename: Optional[str] = None
    max_tokens: int = 200
    temperature: float = 0.7
    top_p: float = 0.9

class GemmaAnalysisResponse(BaseModel):
    """Mod√®le pour les r√©ponses d'analyse Gemma"""
    success: bool
    result: Optional[str] = None
    error: Optional[str] = None
    model_status: str = "unavailable"

@app.post("/analyze/gemma", response_model=GemmaAnalysisResponse)
async def analyze_with_gemma_endpoint(request: GemmaAnalysisRequest):
    """
    Endpoint pour effectuer des analyses avec le mod√®le Gemma
    """
    if not GEMMA_AVAILABLE:
        return GemmaAnalysisResponse(
            success=False,
            error="Le mod√®le Gemma n'est pas disponible",
            model_status="unavailable"
        )
    
    try:
        # Valider les param√®tres
        if not request.prompt or len(request.prompt.strip()) == 0:
            raise ValueError("Le prompt ne peut pas √™tre vide")
            
        # Appeler la fonction d'analyse Gemma
        result = analyze_with_gemma(
            prompt=request.prompt,
            image_filename=request.image_filename
        )
        
        if result is None:
            return GemmaAnalysisResponse(
                success=False,
                error="L'analyse Gemma n'a pas pu √™tre effectu√©e",
                model_status="error"
            )
            
        return GemmaAnalysisResponse(
            success=True,
            result=result,
            model_status="ready"
        )
        
    except Exception as e:
        logger.error(f"Erreur lors de l'analyse avec Gemma: {str(e)}", exc_info=True)
        return GemmaAnalysisResponse(
            success=False,
            error=f"Erreur lors de l'analyse: {str(e)}",
            model_status="error"
        )

# ==================== INDICATEURS TECHNIQUES AVANC√âS ====================

@app.get("/indicators/ichimoku/{symbol}")
async def get_ichimoku_analysis(
    symbol: str, 
    timeframe: str = "H1",
    count: int = 200
):
    """
    R√©cup√®re l'analyse Ichimoku Kinko Hyo pour un symbole donn√©.
    
    Args:
        symbol: Symbole du march√© (ex: "EURUSD", "BTCUSDT")
        timeframe: P√©riode temporelle (M1, M5, M15, H1, H4, D1)
        count: Nombre de bougies √† analyser (max 1000)
        
    Returns:
        Dictionnaire contenant les composantes de l'Ichimoku
    """
    try:
        # Valider les param√®tres
        count = min(max(50, count), 1000)  # Limiter entre 50 et 1000
        
        # R√©cup√©rer les donn√©es historiques
        df = get_historical_data(symbol, timeframe, count)
        if df.empty:
            raise HTTPException(status_code=404, detail=f"Aucune donn√©e disponible pour {symbol}")
        
        # Initialiser l'analyseur d'indicateurs
        from python.ai_indicators import AdvancedIndicators
        analyzer = AdvancedIndicators(symbol, timeframe)
        
        # Calculer l'Ichimoku
        ichimoku = analyzer.calculate_ichimoku(df)
        
        if not ichimoku:
            raise HTTPException(status_code=400, detail="Impossible de calculer l'Ichimoku avec les donn√©es disponibles")
        
        return {
            "symbol": symbol,
            "timeframe": timeframe,
            "timestamp": datetime.utcnow().isoformat(),
            **ichimoku
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur dans get_ichimoku_analysis: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors du calcul de l'Ichimoku: {str(e)}")

@app.get("/indicators/fibonacci/{symbol}")
async def get_fibonacci_levels(
    symbol: str,
    timeframe: str = "D1",
    lookback: int = 100
):
    """
    Calcule les niveaux de retracement et d'extension de Fibonacci.
    
    Args:
        symbol: Symbole du march√©
        timeframe: P√©riode temporelle (M1, M5, M15, H1, H4, D1)
        lookback: Nombre de p√©riodes √† analyser pour trouver les extr√™mes
        
    Returns:
        Dictionnaire contenant les niveaux de Fibonacci
    """
    try:
        # Valider les param√®tres
        lookback = min(max(20, lookback), 500)  # Limiter entre 20 et 500
        
        # R√©cup√©rer les donn√©es historiques
        df = get_historical_data(symbol, timeframe, lookback + 10)  # Prendre quelques bougies suppl√©mentaires
        if df.empty:
            raise HTTPException(status_code=404, detail=f"Aucune donn√©e disponible pour {symbol}")
        
        # Initialiser l'analyseur d'indicateurs
        from python.ai_indicators import AdvancedIndicators
        analyzer = AdvancedIndicators(symbol, timeframe)
        
        # Calculer les niveaux de Fibonacci
        fib_levels = analyzer.calculate_fibonacci(df, lookback)
        
        if not fib_levels:
            raise HTTPException(status_code=400, detail="Impossible de calculer les niveaux de Fibonacci")
        
        return {
            "symbol": symbol,
            "timeframe": timeframe,
            "lookback_periods": lookback,
            "timestamp": datetime.utcnow().isoformat(),
            **fib_levels
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur dans get_fibonacci_levels: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors du calcul des niveaux de Fibonacci: {str(e)}")

@app.get("/indicators/order-blocks/{symbol}")
async def get_order_blocks(
    symbol: str,
    timeframe: str = "H4",
    lookback: int = 50,
    min_strength: float = 0.7
):
    """
    D√©tecte les blocs d'ordre (Order Blocks) dans le graphique.
    
    Args:
        symbol: Symbole du march√©
        timeframe: P√©riode temporelle (M1, M5, M15, H1, H4, D1)
        lookback: Nombre de p√©riodes √† analyser
        min_strength: Force minimale des blocs √† inclure (0-1)
        
    Returns:
        Liste des blocs d'ordre d√©tect√©s
    """
    try:
        # Valider les param√®tres
        lookback = min(max(20, lookback), 200)  # Limiter entre 20 et 200
        min_strength = min(max(0.1, min_strength), 1.0)  # Limiter entre 0.1 et 1.0
        
        # R√©cup√©rer les donn√©es historiques
        df = get_historical_data(symbol, timeframe, lookback + 10)  # Prendre quelques bougies suppl√©mentaires
        if df.empty:
            raise HTTPException(status_code=404, detail=f"Aucune donn√©e disponible pour {symbol}")
        
        # Initialiser l'analyseur d'indicateurs
        from python.ai_indicators import AdvancedIndicators
        analyzer = AdvancedIndicators(symbol, timeframe)
        
        # D√©tecter les blocs d'ordre
        blocks = analyzer.detect_order_blocks(df, lookback, min_strength)
        
        return {
            "symbol": symbol,
            "timeframe": timeframe,
            "lookback_periods": lookback,
            "min_strength": min_strength,
            "timestamp": datetime.utcnow().isoformat(),
            "order_blocks": blocks
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur dans get_order_blocks: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de la d√©tection des blocs d'ordre: {str(e)}")

@app.get("/indicators/liquidity-zones/{symbol}")
async def get_liquidity_zones(
    symbol: str,
    timeframe: str = "H1",
    num_zones: int = 5,
    volume_filter: bool = True
):
    """
    Identifie les zones de liquidit√© bas√©es sur le volume et le profil de prix.
    
    Args:
        symbol: Symbole du march√©
        timeframe: P√©riode temporelle (M1, M5, M15, H1, H4, D1)
        num_zones: Nombre de zones de liquidit√© √† identifier (1-10)
        volume_filter: Si True, utilise le volume pour pond√©rer les zones
        
    Returns:
        Liste des zones de liquidit√© identifi√©es
    """
    try:
        # Valider les param√®tres
        num_zones = min(max(1, num_zones), 10)  # Limiter entre 1 et 10
        
        # R√©cup√©rer les donn√©es historiques
        df = get_historical_data(symbol, timeframe, 200)  # Prendre assez de donn√©es pour une analyse significative
        if df.empty:
            raise HTTPException(status_code=404, detail=f"Aucune donn√©e disponible pour {symbol}")
        
        # Initialiser l'analyseur d'indicateurs
        from python.ai_indicators import AdvancedIndicators
        analyzer = AdvancedIndicators(symbol, timeframe)
        
        # Identifier les zones de liquidit√©
        zones = analyzer.identify_liquidity_zones(df, num_zones, volume_filter)
        
        return {
            "symbol": symbol,
            "timeframe": timeframe,
            "num_zones": len(zones),
            "volume_filter": volume_filter,
            "timestamp": datetime.utcnow().isoformat(),
            "liquidity_zones": zones
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur dans get_liquidity_zones: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de l'identification des zones de liquidit√©: {str(e)}")

@app.get("/indicators/market-profile/{symbol}")
async def get_market_profile_analysis(
    symbol: str,
    timeframe: str = "D1",
    period: str = "D",
    value_area_percent: float = 0.7
):
    """
    Calcule le profil de march√© (Market Profile) avec POC, VAL, VAH, etc.
    
    Args:
        symbol: Symbole du march√©
        timeframe: P√©riode temporelle des bougies
        period: P√©riode d'agr√©gation (D=journalier, W=hebdomadaire, M=mensuel)
        value_area_percent: Pourcentage de volume √† inclure dans la zone de valeur (0.5-0.9)
        
    Returns:
        Dictionnaire contenant les informations du profil de march√©
    """
    try:
        # Valider les param√®tres
        value_area_percent = min(max(0.5, value_area_percent), 0.9)  # Limiter entre 0.5 et 0.9
        
        # D√©terminer le nombre de bougies √† r√©cup√©rer en fonction de la p√©riode
        if period == "D":
            days = 30
        elif period == "W":
            days = 180
        elif period == "M":
            days = 365
        else:
            days = 30  # Par d√©faut, 1 mois
        
        # R√©cup√©rer les donn√©es historiques
        df = get_historical_data(symbol, timeframe, days * 24)  # Estimation grossi√®re
        if df.empty:
            raise HTTPException(status_code=404, detail=f"Aucune donn√©e disponible pour {symbol}")
        
        # Initialiser l'analyseur d'indicateurs
        from python.ai_indicators import AdvancedIndicators
        analyzer = AdvancedIndicators(symbol, timeframe)
        
        # Calculer le profil de march√©
        profile = analyzer.calculate_market_profile(df, period, value_area_percent)
        
        if not profile:
            raise HTTPException(status_code=400, detail="Impossible de calculer le profil de march√©")
        
        return {
            "symbol": symbol,
            "timeframe": timeframe,
            "period": period,
            "value_area_percent": value_area_percent,
            "timestamp": datetime.utcnow().isoformat(),
            **profile
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur dans get_market_profile_analysis: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors du calcul du profil de march√©: {str(e)}")

# ==================== FIN INDICATEURS TECHNIQUES AVANC√âS ====================

# ==================== MARKET STATE ENDPOINT ====================

@app.get("/market-state")
async def get_market_state(symbol: str, timeframe: str = "M1"):
    """
    Endpoint pour fournir l'√©tat du march√© aux robots MT5
    Remplace l'ancien syst√®me de tendance qui g√©n√©rait des erreurs 500
    """
    try:
        # R√©cup√©rer les donn√©es historiques
        df = get_historical_data(symbol, timeframe, 100)
        if df.empty:
            return {
                "error": f"Aucune donn√©e disponible pour {symbol}",
                "symbol": symbol,
                "timeframe": timeframe,
                "timestamp": datetime.now().isoformat()
            }
        
        # Calculer les indicateurs de base
        current_price = float(df['close'].iloc[-1])
        
        # Moyennes mobiles pour la tendance
        sma_20 = df['close'].rolling(20).mean().iloc[-1]
        sma_50 = df['close'].rolling(50).mean().iloc[-1]
        
        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs)).iloc[-1]
        
        # D√©terminer la tendance
        if current_price > sma_20 and sma_20 > sma_50:
            trend = "HAUSSIERE"
            trend_arrow = "‚Üë"
        elif current_price < sma_20 and sma_20 < sma_50:
            trend = "BAISSIERE"
            trend_arrow = "‚Üì"
        else:
            trend = "NEUTRE"
            trend_arrow = "‚Üí"
        
        # D√©terminer l'√©tat du march√©
        if rsi < 30:
            state = "SURVENTE"
        elif rsi > 70:
            state = "SURACHAT"
        else:
            state = "NORMAL"
        
        return {
            "symbol": symbol,
            "timeframe": timeframe,
            "timestamp": datetime.now().isoformat(),
            "state": state,
            "trend": trend,
            "trend_arrow": trend_arrow,
            "current_price": current_price,
            "sma_20": float(sma_20) if pd.notna(sma_20) else None,
            "sma_50": float(sma_50) if pd.notna(sma_50) else None,
            "rsi": float(rsi) if pd.notna(rsi) else None,
            "status": "success"
        }
        
    except Exception as e:
        logger.error(f"Erreur dans /market-state: {str(e)}", exc_info=True)
        return {
            "error": f"Erreur lors de l'analyse de l'√©tat du march√©: {str(e)}",
            "symbol": symbol,
            "timeframe": timeframe,
            "timestamp": datetime.now().isoformat(),
            "status": "error"
        }

# ==================== FIN MARKET STATE ENDPOINT ====================

# ==================== AUTOSCAN ENDPOINTS ====================

@app.get("/autoscan/signals")
async def get_autoscan_signals(symbol: Optional[str] = None):
    """
    Endpoint pour r√©cup√©rer les signaux AutoScan (compatible avec MT5)
    
    Format attendu par MT5:
    {
        "status": "success",
        "data": {
            "signals": [
                {
                    "symbol": "...",
                    "action": "BUY" | "SELL",
                    "entry_price": float,
                    "stop_loss": float,
                    "take_profit": float,
                    "confidence": float (0.0-1.0),
                    "reason": "..."
                }
            ]
        }
    }
    """
    try:
        signals = []
        
        # Si MT5 n'est pas disponible, retourner une liste vide
        if not mt5_initialized:
            logger.warning("MT5 non initialis√©, retour de liste de signaux vide pour AutoScan")
            return {
                "status": "success",
                "data": {
                    "signals": []
                },
                "timestamp": datetime.utcnow().isoformat(),
                "count": 0,
                "message": "MT5 non disponible"
            }
        
        # Si un symbole est sp√©cifi√©, analyser uniquement ce symbole
        symbols_to_scan = [symbol] if symbol else []
        
        # Si aucun symbole n'est sp√©cifi√©, utiliser les symboles courants
        if not symbols_to_scan:
            # Symboles par d√©faut pour Boom/Crash
            symbols_to_scan = ["Boom 1000 Index", "Crash 1000 Index"]
        
        for sym in symbols_to_scan:
            try:
                # R√©cup√©rer les donn√©es OHLC r√©centes
                df = get_historical_data(sym, "M1", 100)
                if df.empty:
                    logger.warning(f"Aucune donn√©e disponible pour {sym}")
                    continue
                
                current_price = float(df['close'].iloc[-1])
                
                # Calculer les indicateurs techniques
                rsi_values = calculate_rsi(df['close'], period=14)
                rsi = float(rsi_values.iloc[-1]) if not rsi_values.empty else 50.0
                
                # Calculer ATR pour stop loss/take profit
                atr_values = calculate_atr(df, period=14)
                atr = float(atr_values.iloc[-1]) if not atr_values.empty else current_price * 0.001
                
                # Calculer les moyennes mobiles
                ema_fast = df['close'].ewm(span=12, adjust=False).mean()
                ema_slow = df['close'].ewm(span=26, adjust=False).mean()
                ema_fast_val = float(ema_fast.iloc[-1]) if not ema_fast.empty else current_price
                ema_slow_val = float(ema_slow.iloc[-1]) if not ema_slow.empty else current_price
                
                # D√©tecter les signaux bas√©s sur RSI et MA
                action = None
                confidence = 0.0
                reason = ""
                
                # Condition 1: RSI en survente (< 30) -> Signal BUY
                if rsi < 30:
                    action = "BUY"
                    confidence = 0.75
                    reason = "RSI Survente"
                # Condition 2: RSI en surachat (> 70) -> Signal SELL
                elif rsi > 70:
                    action = "SELL"
                    confidence = 0.75
                    reason = "RSI Surachat"
                # Condition 3: Croisement de MA haussier
                elif len(ema_fast) >= 3 and len(ema_slow) >= 3:
                    ema_fast_prev = float(ema_fast.iloc[-2])
                    ema_slow_prev = float(ema_slow.iloc[-2])
                    if ema_fast_val > ema_slow_val and ema_fast_prev <= ema_slow_prev:
                        action = "BUY"
                        confidence = 0.70
                        reason = "MA Croisement Haussier"
                    # Condition 4: Croisement de MA baissier
                    elif ema_fast_val < ema_slow_val and ema_fast_prev >= ema_slow_prev:
                        action = "SELL"
                        confidence = 0.70
                        reason = "MA Croisement Baissier"
                # Condition 5: Volatilit√© √©lev√©e
                if action is None:
                    volatility = abs(current_price - ema_slow_val) / ema_slow_val if ema_slow_val > 0 else 0
                    if volatility > 0.002:  # 0.2%
                        if current_price > ema_slow_val:
                            action = "BUY"
                            confidence = 0.65
                            reason = "Volatilit√© Haussier"
                        else:
                            action = "SELL"
                            confidence = 0.65
                            reason = "Volatilit√© Baissier"
                
                # Si un signal a √©t√© d√©tect√©, cr√©er l'entr√©e
                if action and confidence >= 0.55:  # Seuil minimum de confiance
                    # Calculer stop loss et take profit bas√©s sur ATR
                    if action == "BUY":
                        entry_price = current_price
                        stop_loss = entry_price - (atr * 2)
                        take_profit = entry_price + (atr * 4.5)  # Augment√© de 3.0 √† 4.5 (+50%)
                    else:  # SELL
                        entry_price = current_price
                        stop_loss = entry_price + (atr * 2)
                        take_profit = entry_price - (atr * 4.5)  # Augment√© de 3.0 √† 4.5 (+50%)
                    
                    signal = {
                        "symbol": sym,
                        "action": action,
                        "entry_price": round(entry_price, 5),
                        "stop_loss": round(stop_loss, 5),
                        "take_profit": round(take_profit, 5),
                        "confidence": round(confidence, 2),
                        "reason": reason
                    }
                    signals.append(signal)
                    logger.info(f"AutoScan: Signal d√©tect√© pour {sym} - {action} (confiance: {confidence*100:.0f}%)")
                    
            except Exception as e:
                logger.error(f"Erreur lors de l'analyse de {sym} pour AutoScan: {e}", exc_info=True)
                continue
        
        # Retourner la r√©ponse dans le format attendu par MT5
        return {
            "status": "success",
            "data": {
                "signals": signals
            },
            "timestamp": datetime.utcnow().isoformat(),
            "count": len(signals)
        }
        
    except Exception as e:
        logger.error(f"Erreur dans get_autoscan_signals: {e}", exc_info=True)
        return {
            "status": "error",
            "data": {
                "signals": []
            },
            "error": str(e),
            "timestamp": datetime.utcnow().isoformat()
        }

# ==================== FIN AUTOSCAN ENDPOINTS ====================

# Endpoint pour entra√Æner les mod√®les ML
@app.post("/train_ml_models")
async def train_ml_models():
    """Endpoint pour entra√Æner les mod√®les ML"""
    try:
        if not ML_AVAILABLE:
            return {"status": "error", "message": "ML system not available"}
        
        logger.info("üß™ D√©but entra√Ænement mod√®les ML...")
        results = ml_enhancer.train_all_symbols()
        
        return {
            "status": "success",
            "message": "ML models training completed",
            "results": results,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur entra√Ænement ML: {e}")
        return {"status": "error", "message": str(e)}

# Endpoint pour obtenir les statistiques ML
@app.get("/ml_stats")
async def get_ml_stats():
    """Obtenir les statistiques des mod√®les ML"""
    try:
        if not ML_AVAILABLE:
            return {"status": "error", "message": "ML system not available"}
        
        stats = {}
        for symbol, model in ml_enhancer.ml_system.symbol_models.items():
            stats[symbol] = {
                "win_rate": model.get("win_rate", 0),
                "total_trades": model.get("total_trades", 0),
                "confidence_threshold": model.get("confidence_threshold", 0.7),
                "last_updated": model.get("last_updated"),
                "decision_weights": model.get("decision_weights", {}),
                "time_patterns": model.get("time_patterns", {})
            }
        
        return {
            "status": "success",
            "stats": stats,
            "total_models": len(stats),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur stats ML: {e}")
        return {"status": "error", "message": str(e)}

# ========== D√âMARRAGE AUTOMATIQUE DU SYST√àME ML ==========
@app.on_event("startup")
async def startup_event():
    """√âv√©nements au d√©marrage du serveur"""
    logger.info("üöÄ D√©marrage du serveur IA TradBOT...")
    # Cr√©er le r√©pertoire models pour l'entra√Ænement ML (Render, etc.)
    os.makedirs("models", exist_ok=True)
    
    # D√©marrer l'entra√Ænement continu ML (Supabase: fetch predictions ‚Üí train ‚Üí save model_metrics)
    supabase_configured = bool(os.getenv("SUPABASE_URL") and os.getenv("SUPABASE_ANON_KEY"))
    if ML_TRAINER_AVAILABLE and supabase_configured:
        logger.info("ü§ñ D√©marrage entra√Ænement continu ML (Supabase)...")
        try:
            await ml_trainer.start()
            logger.info("‚úÖ Entra√Ænement continu Supabase activ√© (predictions ‚Üí model_metrics)")
        except Exception as e:
            logger.error(f"‚ùå Erreur d√©marrage entra√Ænement continu: {e}")
    elif ML_TRAINER_AVAILABLE and not supabase_configured:
        logger.info("‚ÑπÔ∏è Entra√Ænement continu d√©sactiv√©: SUPABASE_URL et SUPABASE_ANON_KEY requis")
    
    logger.info("üéØ Serveur IA TradBOT pr√™t!")

@app.on_event("shutdown")
async def shutdown_event():
    """√âv√©nements √† l'arr√™t du serveur"""
    logger.info("üõë Arr√™t du serveur IA TradBOT...")
    
    # Arr√™ter le syst√®me ML
    if ML_TRAINER_AVAILABLE:
        try:
            await ml_trainer.stop()
            logger.info("üõë Syst√®me ML arr√™t√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur arr√™t syst√®me ML: {e}")

if __name__ == "__main__":
    import uvicorn
    
    # D√©marrer le serveur avec gestion des √©v√©nements de vie
    logger.info("üåü Lancement du serveur IA TradBOT avec syst√®me ML int√©gr√©")
    logger.info("üì° Endpoints disponibles:")
    logger.info("   ‚Ä¢ /health - Sant√© du serveur")
    logger.info("   ‚Ä¢ /decision - D√©cisions de trading")  
    logger.info("   ‚Ä¢ /ml/metrics - M√©triques ML en temps r√©el")
    logger.info("   ‚Ä¢ /ml/start - D√©marrer entra√Ænement ML")
    logger.info("   ‚Ä¢ /ml/stop - Arr√™ter entra√Ænement ML")
    logger.info("   ‚Ä¢ /ml/retrain - Forcer r√©entra√Ænement")
    logger.info("   ‚Ä¢ /ml_stats - Statistiques ML d√©taill√©es")
    
    uvicorn.run(
        "ai_server:app",
        host="127.0.0.1",
        port=8000,
        reload=False,
        log_level="info"
    )