#!/usr/bin/env python3
"""
Syst√®me d'entra√Ænement continu avec m√©triques en temps r√©el
Utilise les mod√®les existants et les am√©liore avec les donn√©es Supabase
"""

import os
import json
import time
import asyncio
import logging
import joblib
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import httpx
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, classification_report
from dotenv import load_dotenv
import warnings
warnings.filterwarnings('ignore')

# Charger les variables d'environnement
load_dotenv('.env.supabase')

# Configuration
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ContinuousMLTrainer:
    """Syst√®me d'entra√Ænement continu avec m√©triques en temps r√©el"""
    
    def __init__(self):
        self.models_dir = "models"
        self.supabase_url = os.getenv("SUPABASE_URL", "https://bpzqnooiisgadzicwupi.supabase.co")
        self.supabase_key = os.getenv("SUPABASE_ANON_KEY")
        self.training_interval = 300  # 5 minutes
        self.min_samples_for_retraining = 100  # √âchantillons minimums
        
        # M√©triques en temps r√©el
        self.current_metrics = {}
        self.training_history = []
        
    def load_existing_models(self) -> Dict[str, Any]:
        """Charge tous les mod√®les existants"""
        models = {}
        
        if not os.path.exists(self.models_dir):
            logger.warning(f"R√©pertoire {self.models_dir} non trouv√©")
            return models
            
        for file in os.listdir(self.models_dir):
            if file.endswith('_rf.joblib'):
                # Extraire symbole et timeframe
                parts = file.replace('_rf.joblib', '').split('_')
                if len(parts) >= 2:
                    symbol = '_'.join(parts[:-1])
                    timeframe = parts[-1]
                    key = f"{symbol}_{timeframe}"
                    
                    try:
                        model_path = os.path.join(self.models_dir, file)
                        scaler_path = os.path.join(self.models_dir, file.replace('_rf.joblib', '_scaler.joblib'))
                        metrics_path = os.path.join(self.models_dir, file.replace('_rf.joblib', '_metrics.json'))
                        
                        models[key] = {
                            'model': joblib.load(model_path),
                            'scaler': joblib.load(scaler_path) if os.path.exists(scaler_path) else None,
                            'metrics': json.load(open(metrics_path)) if os.path.exists(metrics_path) else {},
                            'symbol': symbol,
                            'timeframe': timeframe,
                            'last_training': datetime.now()
                        }
                        logger.info(f"‚úÖ Mod√®le charg√©: {key}")
                    except Exception as e:
                        logger.error(f"‚ùå Erreur chargement mod√®le {file}: {e}")
                        
        return models
    
    async def fetch_training_data(self, symbol: str, timeframe: str = "M1", limit: int = 10000) -> Optional[pd.DataFrame]:
        """R√©cup√®re les donn√©es d'entra√Ænement depuis Supabase"""
        headers = {
            "apikey": self.supabase_key,
            "Authorization": f"Bearer {self.supabase_key}",
            "Content-Type": "application/json"
        }
        
        try:
            async with httpx.AsyncClient() as client:
                # R√©cup√©rer les pr√©dictions r√©centes
                predictions_url = f"{self.supabase_url}/rest/v1/predictions"
                predictions_params = {
                    "symbol": f"eq.{symbol}",
                    "timeframe": timeframe,
                    "order": "created_at.desc",
                    "limit": limit
                }
                
                pred_resp = await client.get(predictions_url, params=predictions_params, headers=headers)
                if pred_resp.status_code != 200:
                    logger.error(f"‚ùå Erreur r√©cup√©ration pr√©dictions: {pred_resp.status_code}")
                    return None
                
                predictions_data = pred_resp.json()
                
                # R√©cup√©rer le feedback de trading
                feedback_url = f"{self.supabase_url}/rest/v1/trade_feedback"
                feedback_params = {
                    "symbol": f"eq.{symbol}",
                    "order": "created_at.desc",
                    "limit": limit
                }
                
                feedback_resp = await client.get(feedback_url, params=feedback_params, headers=headers)
                feedback_data = feedback_resp.json() if feedback_resp.status_code == 200 else []
                
                # Combiner les donn√©es
                df = self.prepare_training_data(predictions_data, feedback_data)
                logger.info(f"üìä {len(df)} √©chantillons r√©cup√©r√©s pour {symbol} {timeframe}")
                return df
                
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration donn√©es {symbol}: {e}")
            return None
    
    def prepare_training_data(self, predictions: List[Dict], feedback: List[Dict]) -> pd.DataFrame:
        """Pr√©pare les donn√©es d'entra√Ænement"""
        training_data = []
        
        # Cr√©er un dictionnaire des feedback pour recherche rapide
        feedback_dict = {f.get('prediction_id', ''): f for f in feedback}
        
        for pred in predictions:
            # Cr√©er les features techniques
            try:
                metadata = pred.get('metadata', {})
                request_data = metadata.get('request_data', {})
                
                features = {
                    'price_vs_sma20': request_data.get('price_vs_sma20', 0),
                    'price_vs_sma50': request_data.get('price_vs_sma50', 0),
                    'rsi': request_data.get('rsi', 50),
                    'rsi_normalized': request_data.get('rsi', 50) / 100,
                    'macd': request_data.get('macd', 0),
                    'macd_signal': request_data.get('macd_signal', 0),
                    'macd_histogram': request_data.get('macd_histogram', 0),
                    'atr': request_data.get('atr', 0.001),
                    'atr_normalized': request_data.get('atr', 0.001) * 1000,
                    'atr_ma_ratio': request_data.get('atr_ma_ratio', 1.0),
                    'bb_width': request_data.get('bb_width', 0.02),
                    'bb_position': request_data.get('bb_position', 0.5),
                    'volume_ratio': request_data.get('volume_ratio', 1.0),
                    'volume_trend': request_data.get('volume_trend', 0),
                    'high_low_range': request_data.get('high_low_range', 0.001),
                    'open_close_range': request_data.get('open_close_range', 0.0005),
                    'body_size': request_data.get('body_size', 0.0005),
                    'momentum_5': request_data.get('momentum_5', 0),
                    'momentum_10': request_data.get('momentum_10', 0),
                    'momentum_20': request_data.get('momentum_20', 0),
                    'distance_to_high': request_data.get('distance_to_high', 0),
                    'distance_to_low': request_data.get('distance_to_low', 0)
                }
                
                # D√©terminer le label √† partir du feedback
                pred_id = pred.get('id', '')
                feedback_entry = feedback_dict.get(pred_id)
                
                if feedback_entry:
                    # Utiliser le r√©sultat r√©el du trade
                    is_profitable = feedback_entry.get('is_profitable', False)
                    label = 1 if is_profitable else 0
                else:
                    # Si pas de feedback, utiliser la pr√©diction comme label approximatif
                    prediction = pred.get('prediction', 'hold')
                    if prediction == 'buy':
                        label = 1
                    elif prediction == 'sell':
                        label = 0
                    else:
                        label = 2  # hold
                
                features['target'] = label
                features['prediction_id'] = pred_id
                features['timestamp'] = pred.get('created_at', datetime.now().isoformat())
                
                training_data.append(features)
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur pr√©paration feature: {e}")
                continue
        
        return pd.DataFrame(training_data)
    
    def train_model(self, df: pd.DataFrame, symbol: str, timeframe: str) -> Dict[str, Any]:
        """Entra√Æne un mod√®le avec les nouvelles donn√©es"""
        if len(df) < self.min_samples_for_retraining:
            logger.warning(f"‚ö†Ô∏è Pas assez de donn√©es pour {symbol} {timeframe}: {len(df)} < {self.min_samples_for_retraining}")
            return None
        
        # Pr√©parer les features
        feature_columns = [col for col in df.columns if col not in ['target', 'prediction_id', 'timestamp']]
        X = df[feature_columns].fillna(0)
        y = df['target']
        
        # Normaliser
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Entra√Æner Random Forest
        rf_model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42
        )
        
        rf_model.fit(X_scaled, y)
        
        # Calculer les m√©triques
        y_pred = rf_model.predict(X_scaled)
        accuracy = accuracy_score(y, y_pred)
        f1 = f1_score(y, y_pred, average='weighted')
        
        # Importance des features
        feature_importance = dict(zip(feature_columns, rf_model.feature_importances_))
        
        # Sauvegarder le mod√®le
        model_key = f"{symbol}_{timeframe}"
        model_path = os.path.join(self.models_dir, f"{model_key}_rf.joblib")
        scaler_path = os.path.join(self.models_dir, f"{model_key}_scaler.joblib")
        
        joblib.dump(rf_model, model_path)
        joblib.dump(scaler, scaler_path)
        
        # M√©triques
        metrics = {
            "symbol": symbol,
            "timeframe": timeframe,
            "training_date": datetime.now().isoformat(),
            "metrics": {
                "random_forest": {
                    "accuracy": float(accuracy),
                    "f1_score": float(f1),
                    "feature_importance": feature_importance
                }
            },
            "best_model": "random_forest",
            "features_used": feature_columns,
            "training_samples": len(df),
            "test_samples": int(len(df) * 0.2)
        }
        
        # Sauvegarder les m√©triques
        metrics_path = os.path.join(self.models_dir, f"{model_key}_metrics.json")
        with open(metrics_path, 'w') as f:
            json.dump(metrics, f, indent=2)
        
        logger.info(f"‚úÖ Mod√®le entra√Æn√©: {model_key} | Accuracy: {accuracy:.4f} | F1: {f1:.4f}")
        
        return metrics
    
    async def save_metrics_to_supabase(self, metrics: Dict[str, Any]):
        """Sauvegarde les m√©triques dans Supabase"""
        headers = {
            "apikey": self.supabase_key,
            "Authorization": f"Bearer {self.supabase_key}",
            "Content-Type": "application/json",
            "Prefer": "return=representation"
        }
        
        try:
            metric_data = {
                "symbol": metrics["symbol"],
                "timeframe": metrics["timeframe"],
                "model_type": "random_forest",
                "accuracy": metrics["metrics"]["random_forest"]["accuracy"],
                "f1_score": metrics["metrics"]["random_forest"]["f1_score"],
                "training_samples": metrics["training_samples"],
                "training_date": metrics["training_date"],
                "feature_importance": json.dumps(metrics["metrics"]["random_forest"]["feature_importance"]),
                "metadata": json.dumps(metrics)
            }
            
            async with httpx.AsyncClient() as client:
                resp = await client.post(
                    f"{self.supabase_url}/rest/v1/model_metrics",
                    json=metric_data,
                    headers=headers,
                    timeout=10.0
                )
                
                if resp.status_code == 201:
                    logger.info(f"‚úÖ M√©triques sauvegard√©es pour {metrics['symbol']} {metrics['timeframe']}")
                else:
                    logger.error(f"‚ùå Erreur sauvegarde m√©triques: {resp.status_code} - {resp.text}")
                    
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde m√©triques Supabase: {e}")
    
    def display_metrics_dashboard(self):
        """Affiche le dashboard des m√©triques en temps r√©el"""
        print("\n" + "="*80)
        print("ü§ñ DASHBOARD M√âTRIQUES MOD√àLES ML")
        print("="*80)
        
        for model_key, metrics in self.current_metrics.items():
            symbol = metrics.get('symbol', 'Unknown')
            timeframe = metrics.get('timeframe', 'M1')
            rf_metrics = metrics.get('metrics', {}).get('random_forest', {})
            
            accuracy = rf_metrics.get('accuracy', 0)
            f1_score = rf_metrics.get('f1_score', 0)
            training_samples = metrics.get('training_samples', 0)
            training_date = metrics.get('training_date', 'Unknown')
            
            print(f"\nüìä {symbol} [{timeframe}]")
            print(f"   Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
            print(f"   F1 Score: {f1_score:.4f}")
            print(f"   Samples: {training_samples}")
            print(f"   Last Training: {training_date[:19] if len(training_date) > 19 else training_date}")
            
            # Top 5 features
            feature_importance = rf_metrics.get('feature_importance', {})
            if feature_importance:
                top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:5]
                print(f"   Top Features: {', '.join([f'{feat}({imp:.3f})' for feat, imp in top_features])}")
        
        print("\n" + "="*80)
        print(f"üîÑ Prochain entra√Ænement dans: {self.training_interval//60} minutes")
        print("="*80 + "\n")
    
    async def continuous_training_loop(self):
        """Boucle d'entra√Ænement continu"""
        logger.info("üöÄ D√©marrage du syst√®me d'entra√Ænement continu")
        
        # Charger les mod√®les existants
        models = self.load_existing_models()
        logger.info(f"üì¶ {len(models)} mod√®les charg√©s")
        
        while True:
            try:
                logger.info(f"üîÑ D√©but cycle d'entra√Ænement - {datetime.now()}")
                
                # Pour chaque mod√®le, r√©cup√©rer les nouvelles donn√©es et r√©entra√Æner
                for model_key, model_info in models.items():
                    symbol = model_info['symbol']
                    timeframe = model_info['timeframe']
                    
                    # R√©cup√©rer les donn√©es
                    df = await self.fetch_training_data(symbol, timeframe)
                    if df is not None and len(df) >= self.min_samples_for_retraining:
                        # Entra√Æner le mod√®le
                        new_metrics = self.train_model(df, symbol, timeframe)
                        if new_metrics:
                            self.current_metrics[model_key] = new_metrics
                            
                            # Sauvegarder les m√©triques dans Supabase
                            await self.save_metrics_to_supabase(new_metrics)
                            
                            # Mettre √† jour le mod√®le en m√©moire
                            models[model_key].update(new_metrics)
                
                # Afficher le dashboard
                self.display_metrics_dashboard()
                
                # Attendre le prochain cycle
                logger.info(f"üò¥ Attente {self.training_interval//60} minutes avant prochain entra√Ænement...")
                await asyncio.sleep(self.training_interval)
                
            except KeyboardInterrupt:
                logger.info("üõë Arr√™t du syst√®me d'entra√Ænement")
                break
            except Exception as e:
                logger.error(f"‚ùå Erreur dans le cycle d'entra√Ænement: {e}")
                await asyncio.sleep(60)  # Attendre 1 minute en cas d'erreur

async def main():
    """Point d'entr√©e principal"""
    trainer = ContinuousMLTrainer()
    await trainer.continuous_training_loop()

if __name__ == "__main__":
    asyncio.run(main())
