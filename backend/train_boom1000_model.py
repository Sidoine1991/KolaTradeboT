#!/usr/bin/env python3
"""
Script d'entraÃ®nement du modÃ¨le XGBoost pour Boom 1000 Index
PrÃ©dit la direction (hausse/baisse) sur la prochaine bougie M1
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Ajouter le chemin du projet pour les imports
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

try:
    from mt5_connector import connect, get_ohlc, is_connected
    print("âœ… Imports backend rÃ©ussis")
except ImportError as e:
    print(f"âŒ Erreur import backend: {e}")
    sys.exit(1)

# Imports pour le ML
try:
    import xgboost as xgb
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
    from sklearn.preprocessing import StandardScaler
    import joblib
    print("âœ… Imports ML rÃ©ussis")
except ImportError as e:
    print(f"âŒ Erreur import ML: {e}")
    print("ğŸ’¡ Installez les dÃ©pendances: pip install xgboost scikit-learn joblib")
    sys.exit(1)

def create_features(df):
    """
    CrÃ©e les features techniques pour la prÃ©diction
    """
    print("ğŸ”§ CrÃ©ation des features techniques...")
    
    # Copie du DataFrame
    df_features = df.copy()
    
    # 1. RENDEMENTS (Returns)
    df_features['return'] = df_features['close'].pct_change()
    df_features['return_1'] = df_features['return'].shift(1)
    df_features['return_2'] = df_features['return'].shift(2)
    df_features['return_3'] = df_features['return'].shift(3)
    
    # 2. VOLATILITÃ‰
    df_features['volatility'] = df_features['return'].rolling(window=20).std()
    df_features['volatility_5'] = df_features['return'].rolling(window=5).std()
    df_features['volatility_10'] = df_features['return'].rolling(window=10).std()
    
    # 3. MOYENNES MOBILES
    df_features['ma_5'] = df_features['close'].rolling(window=5).mean()
    df_features['ma_10'] = df_features['close'].rolling(window=10).mean()
    df_features['ma_20'] = df_features['close'].rolling(window=20).mean()
    df_features['ma_50'] = df_features['close'].rolling(window=50).mean()
    
    # 4. RATIOS DE MOYENNES MOBILES
    df_features['ma_ratio_5_20'] = df_features['ma_5'] / df_features['ma_20']
    df_features['ma_ratio_10_50'] = df_features['ma_10'] / df_features['ma_50']
    
    # 5. RSI
    delta = df_features['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df_features['rsi'] = 100 - (100 / (1 + rs))
    
    # 6. MACD
    ema_12 = df_features['close'].ewm(span=12).mean()
    ema_26 = df_features['close'].ewm(span=26).mean()
    df_features['macd'] = ema_12 - ema_26
    df_features['macd_signal'] = df_features['macd'].ewm(span=9).mean()
    df_features['macd_histogram'] = df_features['macd'] - df_features['macd_signal']
    
    # 7. BANDES DE BOLLINGER
    df_features['bb_middle'] = df_features['close'].rolling(window=20).mean()
    bb_std = df_features['close'].rolling(window=20).std()
    df_features['bb_upper'] = df_features['bb_middle'] + (bb_std * 2)
    df_features['bb_lower'] = df_features['bb_middle'] - (bb_std * 2)
    df_features['bb_position'] = (df_features['close'] - df_features['bb_lower']) / (df_features['bb_upper'] - df_features['bb_lower'])
    
    # 8. ATR (Average True Range)
    high_low = df_features['high'] - df_features['low']
    high_close = np.abs(df_features['high'] - df_features['close'].shift())
    low_close = np.abs(df_features['low'] - df_features['close'].shift())
    true_range = np.maximum(high_low, np.maximum(high_close, low_close))
    df_features['atr'] = true_range.rolling(window=14).mean()
    
    # 9. VOLUME (si disponible)
    if 'tick_volume' in df_features.columns:
        df_features['volume_ma'] = df_features['tick_volume'].rolling(window=20).mean()
        df_features['volume_ratio'] = df_features['tick_volume'] / df_features['volume_ma']
    else:
        df_features['volume_ma'] = 1000  # Valeur par dÃ©faut
        df_features['volume_ratio'] = 1.0
    
    # 10. FEATURES DE PRIX
    df_features['price_range'] = (df_features['high'] - df_features['low']) / df_features['close']
    df_features['body_size'] = abs(df_features['close'] - df_features['open']) / df_features['close']
    df_features['upper_shadow'] = (df_features['high'] - np.maximum(df_features['open'], df_features['close'])) / df_features['close']
    df_features['lower_shadow'] = (np.minimum(df_features['open'], df_features['close']) - df_features['low']) / df_features['close']
    
    # 11. FEATURES TEMPORELLES
    df_features['hour'] = df_features['timestamp'].dt.hour
    df_features['minute'] = df_features['timestamp'].dt.minute
    df_features['day_of_week'] = df_features['timestamp'].dt.dayofweek
    
    # 12. MOMENTUM
    df_features['momentum_5'] = df_features['close'] / df_features['close'].shift(5) - 1
    df_features['momentum_10'] = df_features['close'] / df_features['close'].shift(10) - 1
    df_features['momentum_20'] = df_features['close'] / df_features['close'].shift(20) - 1
    
    print(f"âœ… {len(df_features.columns)} features crÃ©Ã©es")
    return df_features

def create_target(df):
    """
    CrÃ©e la variable cible : 1 si le prix monte Ã  la prochaine bougie, 0 sinon
    """
    print("ğŸ¯ CrÃ©ation de la variable cible...")
    
    # PrÃ©dire la direction sur la prochaine bougie
    df['target'] = (df['close'].shift(-1) > df['close']).astype(int)
    
    # Supprimer la derniÃ¨re ligne (pas de target disponible)
    df = df[:-1]
    
    print(f"âœ… Target crÃ©Ã©e - Distribution: {df['target'].value_counts().to_dict()}")
    return df

def prepare_data(df):
    """
    PrÃ©pare les donnÃ©es pour l'entraÃ®nement
    """
    print("ğŸ“Š PrÃ©paration des donnÃ©es...")
    
    # Features Ã  utiliser pour l'entraÃ®nement
    feature_columns = [
        'return', 'return_1', 'return_2', 'return_3',
        'volatility', 'volatility_5', 'volatility_10',
        'ma_5', 'ma_10', 'ma_20', 'ma_50',
        'ma_ratio_5_20', 'ma_ratio_10_50',
        'rsi', 'macd', 'macd_signal', 'macd_histogram',
        'bb_position', 'atr', 'volume_ratio',
        'price_range', 'body_size', 'upper_shadow', 'lower_shadow',
        'hour', 'minute', 'day_of_week',
        'momentum_5', 'momentum_10', 'momentum_20'
    ]
    
    # VÃ©rifier que toutes les features existent
    missing_features = [col for col in feature_columns if col not in df.columns]
    if missing_features:
        print(f"âš ï¸ Features manquantes: {missing_features}")
        # Supprimer les features manquantes
        feature_columns = [col for col in feature_columns if col in df.columns]
    
    # SÃ©lectionner les features et la target
    X = df[feature_columns].copy()
    y = df['target'].copy()
    
    # Supprimer les lignes avec des valeurs manquantes
    mask = ~(X.isnull().any(axis=1) | y.isnull())
    X = X[mask]
    y = y[mask]
    
    print(f"âœ… DonnÃ©es prÃ©parÃ©es: {X.shape[0]} Ã©chantillons, {X.shape[1]} features")
    print(f"ğŸ“ˆ Distribution target: {y.value_counts().to_dict()}")
    
    return X, y

def train_xgboost_model(X, y):
    """
    EntraÃ®ne le modÃ¨le XGBoost
    """
    print("ğŸ¤– EntraÃ®nement du modÃ¨le XGBoost...")
    
    # Division train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Standardisation des features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # ParamÃ¨tres XGBoost optimisÃ©s pour la classification binaire
    params = {
        'objective': 'binary:logistic',
        'eval_metric': 'logloss',
        'max_depth': 6,
        'learning_rate': 0.1,
        'n_estimators': 200,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'random_state': 42,
        'n_jobs': -1
    }
    
    # EntraÃ®nement
    model = xgb.XGBClassifier(**params)
    model.fit(X_train_scaled, y_train)
    
    # Ã‰valuation
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
    
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"âœ… ModÃ¨le entraÃ®nÃ© - Accuracy: {accuracy:.4f}")
    print("\nğŸ“Š Rapport de classification:")
    print(classification_report(y_test, y_pred))
    
    # Cross-validation
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')
    print(f"\nğŸ”„ Cross-validation scores: {cv_scores}")
    print(f"ğŸ“Š CV Mean: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
    
    # Importance des features
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nğŸ† Top 10 features importantes:")
    print(feature_importance.head(10))
    
    return model, scaler, feature_importance

def save_model(model, scaler, feature_importance, model_path):
    """
    Sauvegarde le modÃ¨le et les mÃ©tadonnÃ©es
    """
    print(f"ğŸ’¾ Sauvegarde du modÃ¨le dans {model_path}...")
    
    # CrÃ©er le dossier si nÃ©cessaire
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    
    # Sauvegarder le modÃ¨le
    joblib.dump(model, model_path)
    
    # Sauvegarder le scaler
    scaler_path = model_path.replace('.pkl', '_scaler.pkl')
    joblib.dump(scaler, scaler_path)
    
    # Sauvegarder les mÃ©tadonnÃ©es
    metadata = {
        'model_type': 'XGBoost',
        'target': 'direction_next_candle',
        'features': list(feature_importance['feature']),
        'feature_importance': feature_importance.to_dict('records'),
        'training_date': datetime.now().isoformat(),
        'model_path': model_path,
        'scaler_path': scaler_path
    }
    
    metadata_path = model_path.replace('.pkl', '_metadata.json')
    import json
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"âœ… ModÃ¨le sauvegardÃ©: {model_path}")
    print(f"âœ… Scaler sauvegardÃ©: {scaler_path}")
    print(f"âœ… MÃ©tadonnÃ©es sauvegardÃ©es: {metadata_path}")

def main():
    """
    Fonction principale
    """
    print("ğŸš€ DÃ©marrage de l'entraÃ®nement du modÃ¨le Boom 1000 XGBoost")
    print("=" * 60)
    
    # 1. Connexion MT5
    print("\nğŸ”Œ Connexion Ã  MT5...")
    try:
        if not is_connected():
            connect()
        if is_connected():
            print("âœ… MT5 connectÃ©")
        else:
            print("âŒ Impossible de se connecter Ã  MT5")
            return
    except Exception as e:
        print(f"âŒ Erreur de connexion MT5: {e}")
        return
    
    # 2. TÃ©lÃ©chargement des donnÃ©es
    print("\nğŸ“¥ TÃ©lÃ©chargement des donnÃ©es Boom 1000...")
    symbol = "Boom 1000 Index"
    timeframe = "1m"
    count = 10000  # 10 000 bougies M1
    
    try:
        df = get_ohlc(symbol, timeframe, count)
        if df is None or df.empty:
            print("âŒ Aucune donnÃ©e rÃ©cupÃ©rÃ©e")
            return
        
        print(f"âœ… {len(df)} bougies rÃ©cupÃ©rÃ©es pour {symbol}")
        print(f"ğŸ“… PÃ©riode: {df['timestamp'].min()} Ã  {df['timestamp'].max()}")
        
    except Exception as e:
        print(f"âŒ Erreur lors du tÃ©lÃ©chargement: {e}")
        return
    
    # 3. CrÃ©ation des features
    print("\nğŸ”§ CrÃ©ation des features...")
    try:
        df_features = create_features(df)
    except Exception as e:
        print(f"âŒ Erreur lors de la crÃ©ation des features: {e}")
        return
    
    # 4. CrÃ©ation de la target
    print("\nğŸ¯ CrÃ©ation de la target...")
    try:
        df_target = create_target(df_features)
    except Exception as e:
        print(f"âŒ Erreur lors de la crÃ©ation de la target: {e}")
        return
    
    # 5. PrÃ©paration des donnÃ©es
    print("\nğŸ“Š PrÃ©paration des donnÃ©es...")
    try:
        X, y = prepare_data(df_target)
        if len(X) < 1000:
            print("âš ï¸ Peu de donnÃ©es disponibles pour l'entraÃ®nement")
            return
    except Exception as e:
        print(f"âŒ Erreur lors de la prÃ©paration des donnÃ©es: {e}")
        return
    
    # 6. EntraÃ®nement du modÃ¨le
    print("\nğŸ¤– EntraÃ®nement du modÃ¨le...")
    try:
        model, scaler, feature_importance = train_xgboost_model(X, y)
    except Exception as e:
        print(f"âŒ Erreur lors de l'entraÃ®nement: {e}")
        return
    
    # 7. Sauvegarde du modÃ¨le
    print("\nğŸ’¾ Sauvegarde du modÃ¨le...")
    model_path = os.path.join(os.path.dirname(__file__), 'boom1000_xgb_model.pkl')
    try:
        save_model(model, scaler, feature_importance, model_path)
    except Exception as e:
        print(f"âŒ Erreur lors de la sauvegarde: {e}")
        return
    
    print("\nğŸ‰ EntraÃ®nement terminÃ© avec succÃ¨s!")
    print("=" * 60)
    print(f"ğŸ“ ModÃ¨le sauvegardÃ©: {model_path}")
    print("ğŸ’¡ Vous pouvez maintenant utiliser le modÃ¨le dans l'application Streamlit")

if __name__ == "__main__":
    main() 